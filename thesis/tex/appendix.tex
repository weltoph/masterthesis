\chapter{Proof of Theorem \ref{thm:StratPOSG}}
\label{app:POSG}
In the following we consider \acp{POSG} in more detail. Initially, we 
modularise some notions by de-coupling an arena and the objective and initial 
state of the game. Also we generalize our definition by allowing \eve{} and 
\adam{} to be differently informed (by $\sim_{E}$ and $\sim_{A}$ respectively):
We consider an arena
\begin{equation*}
  G = \tuple{S, E, A, \tuple{\tau_{e,a}}_{e\in E, a\in A}, \sim_{E}, \sim_{A}}.
\end{equation*}
A \ac{POSG} $\mathcal{G}$ forms by fixing an initial state $s_{0}\in S$ and an 
objective $\Acc$ and setting $\mathcal{G} = \tuple{G, s_{0}, \Acc}$.  
Additionally, we introduce the notion of games with multiple initial locations 
as $\mathcal{G} = \tuple{G, B, \Acc}$ for $B\subseteq S$ such that in an 
initial step \adam{} may choose any $b\in B$ and subsequently \eve{} and 
\adam{} compete in the game $\mathcal{G}_{b} = \tuple{G, b, \Acc}$. Naturally, 
\eve{} has an almost-surely (positively) winning strategy in $\mathcal{G}_{B}$ 
if and only if she has an almost-surely (positively) winning strategy in 
$\mathcal{G}_{b}$. In the following we also consider conditions which are 
evaluated within finitely many steps (in contrast to Muller-, Rabin-, Parity-
or BÃ¼chi-conditions), namely
\begin{description}
  \item [Reachability-condition:] for a set $R\subseteq S$ define
    \begin{equation*}
      \Acc_{\reach}(R) = \tuple{S\setminus R}^{*}RS^{\omega},
    \end{equation*}
  \item [Safety-condition:] for a set $Z\subseteq S$ we define
    \begin{equation*}
      \Acc_{\safety}(Z) = Z^{\omega}.
    \end{equation*}
\end{description}

\section{Finite Steps to Reachability}
We introduce an observation about winning games with associated 
Reachability-condition:
\begin{proposition}
  Given $B\subseteq S$ and $R\subseteq S$ such that \eve{} has a positively
  winning strategy $f$ in the Reachability-game $\mathcal{G}=\tuple{G, B, R}$.
  Then, there is an $N\in\mathbb{N}$ and some probability $\epsilon_{B} > 0$ 
  that bounds from below the probability of the event that a state in $R$ is 
  visited in $\mathcal{G}_{B}$ if \eve{} plays $f$.
  \label{prop:FiniteSteps}
\end{proposition}
\begin{proof}
  We fix the notion $p_{N}^{g_{N}, s}$ as the probability of reaching $R$ in 
  less than $N$ steps if \adam{} initially chose $s$ and plays according to 
  $g_{N}$. From this we derive $p_{N}^{g_{N}} = 
  \min_{s\in B}\set{p_{N}^{g_{N}, s}}$ and claim that there is one 
  $N_{0} > 0$ that renders $p_{N}^{g_{N}} > 0$ for all possible $g_{N}$. For 
  the sake of contradiction we assume this is not the case, i.e. for all $N$ 
  there is one strategy $g_{N}$ rendering $p_{N}^{g_{N}} = 0$. Since there 
  are infinitely many considered $N$ but only finitely many $s\in B$ 
  infinitely often $p_{N}^{g_{N}}$ becomes $0$ from starting in one 
  particular $b\in B$. Thus, we fix such a $b$ and obtain that for more and 
  more increasing values for $N$ there is always a strategy $g_{N}$ to obtain 
  $p_{N}^{g_{N}, b} = 0$. Moreover, we can claim this for every $N$ (since 
  the Reachability-condition can never be undone once it is achieved and 
  there is always a higher $N' > N$ for which \adam{} can avoid $R$ which 
  also holds in turn for $N$).

  Since there are only finitely possible decisions in $A$ for the game 
  $\mathcal{G}_{b}$ but we consider infinitely many strategies (for all $N>0$ 
  there is $g_{N})$) infinitely many must agree what to do in the initial 
  situation; say all these strategies make decision $c\in A$. For any 
  possible subsequent game situation, i.e. the game moved from $b$ to 
  one $s_{1},\dots, s_{n}\in S$ with $\tau_{f(\epsilon), c}(b, s_{i}) > 0$ 
  for all $1\leq i\leq n$, we know that $s_{1},\dots, s_{n}\not\in R$ since
  $p_{N}^{g_{N}, b} = 0$ for all these $g_{N}$. For every $1\leq i\leq n$ we 
  consider again infinitely many strategies (all $g_{N}$ with $N>1$ which 
  initially chose $c$; by choice of $c$ this is indeed an infinite collection
  of strategies). Since there are again only finitely many possible choices 
  we obtain by the same argument one choice $c'$ on which infinitely many 
  $g_{N}$ agree on. This argument can be iterated countably many times and we 
  may construct with the choices the strategies agree upon one particular 
  strategy, say $g$, which avoids $R$ all together. But for this one $g$ we
  can argue that $p_{N, b}^{g} = 0$ for all $N>0$. Naturally, playing $g$ 
  with an additional initial choice of $b$ renders $g$ winning against $f$ in
  the positive Reachability-game $\mathcal{G}_{B}$ contradicting the 
  prerequisite that $f$ is positively winning.

  Hence, we can assured the existence of $N_{0} > 0$ which bounds the number
  rounds any counter strategy may avoid $R$ in $\mathcal{G}_{B}$. Since there
  are only finitely many choices in a game up to $N_{0}$ rounds starting in
  any $s\in B$ we may fix these choices as (partial) strategies of \adam{} in a
  set $G_{s,N_{0}}$. Setting 
  $\epsilon_{B} = \min\set{p^{g}_{N_{0}}:g\in G_{s, N_{0}}}$ yields the desired 
  result.
\end{proof}

\section{Perfectly Informed \adam{}}
We consider a restricted Reachability-condition in $n$-steps, i.e.
\begin{equation*}
  \Acc_{\reach}^{n}(R) = \bigcup_{0\leq i\leq n}S^{i}RS^{\omega}.
\end{equation*}
We show
\begin{proposition}
  For a $K\subseteq S$ such that $K\subseteq\interval{s}_{\sim_{E}}$ for one 
  $s\in S$ and $n>0$ \eve{} positively wins $\tuple{G, K, 
  \Acc_{\reach}^{n}(R)}$ if and only if there exists an action $e\in E$ and 
  $K'\subseteq S$ such that
  \begin{itemize}
    \item \eve{} positively wins $\tuple{G, K', \Acc_{\reach}^{n-1}(R)}$,
    \item for every $s\in K\setminus R$ and $a\in A$ there is $s'\in K'$ such 
      that $\tau_{a, e}(s, s') > 0$.
  \end{itemize}
  \label{prop:PerfInfAdamInd}
\end{proposition}
\begin{proof}
  For the implication consider \eve{}'s positive winning strategy $f$ in 
  \begin{equation*}
    \tuple{G, K, \Acc_{\reach}^{n}(R)}.
  \end{equation*}
  Regardless of the initial choice $b\in K\setminus R$ of \adam{}, \eve{} 
  consistently chooses the same $e = f(\interval{b}_{\sim_{E}})$ since 
  $\interval{b}_{\sim_{E}} = \interval{b}_{\sim_{E}}$ for all $b,b'\in K$. 
  Naturally, since $f$ is positively winning then there is for every $a\in A$ 
  one $s_{b}^{a}\in\supp(\tau_{e, a}(b, \cdot))$ such that \eve{} positively 
  wins $\tuple{G, s_{b}^{a}, \Acc_{\reach}^{n-1}(R)}$ (otherwise \adam{} may 
  win by choosing $b$, playing $a$ and then the winning riposte in 
  $\tuple{G, s_{b}^{a}, \Acc_{\reach}^{n-1}(R)}$). We gather
  \begin{equation*}
    K' = \bigcup_{a\in A, b\in K}s_{b}^{a}
  \end{equation*}
  and obtain the claimed properties for $K'$ and $e$ as above.

  Consider the properties on $K'$ and $e\in E$ satisfied. Hence, for every 
  initial choice $b\in K$ and $a\in A$ there is a positive probability to move
  to $K'$. Playing the corresponding winning strategy from $\tuple{G, K', 
  \Acc_{\reach}^{n-1}(R)}$ after the initial decision $e$ yields a positively
  winning strategy in the original game.
\end{proof}
We use this proposition to prove the following
\begin{theorem}
  For a given arena $G$ \eve{} construct
  \begin{equation*}
    \mathcal{W}_{0} = \Pot(R)
  \end{equation*}
  and
  \begin{align*}
    \mathcal{W}_{i + 1} = \{
      K\in\Pot(S)\mid&\text{for all }k\in K \text{ exists }e\in E, 
      K'\in\mathcal{W}_{i}\text{ s.t. }\\
      &\text{ for all }s\in\tuple{\interval{k}_{\sim_{E}}\setminus R}, a\in A
      \text{ exists }t\in K'\text{ with }\tau_{e, a}(s, t) > 0
    \},
  \end{align*}
  and their limit $\mathcal{W}$. For every non-empty $K\in\Pot(S)$ holds that
  \eve{} has a positively winning strategy $f$ in the Reachability-game 
  $\tuple{G, K, R}$ if and only if $K\in\mathcal{W}$. Moreover, it can be 
  decided in time exponential in $\size{S}$ if such an $f$ exists and if so
  it can be constructed using $\Pot(S)$ states and reaching $R$ with a positive
  probability in $\size{\Pot(S)}$ moves.
  \label{thm:PerfInfAdamReach}
\end{theorem}
\begin{proof}
  Using Proposition \ref{prop:PerfInfAdamInd} we obtain by induction to $n$ 
  that every non-empty $K\in\Pot(S)$ is part of $\mathcal{W}_{n}$ if and only
  if \eve{} positively wins $\tuple{G, K, \Acc_{\reach}^{n}(R)}$.

  Conversely, assuming $K\in\mathcal{W}$ we construct a strategy for \eve{} as
  follows: \eve{} stores $K$ and firstly, identifies the level $n_{K}$ where 
  $K$ became part of $\mathcal{W}$ and secondly, for every equivalence class in
  $K$ the set $K'$ which witnessed that $K$ belongs to $\mathcal{W}_{n_{K}}$.
  Notably, for all these $K'$ holds $n_{K'} < n_{K}$. \eve{} plays the 
  associated action $e_{K'}$ and updates the memory to $K'$. This strategy 
  enforces by definition of $K$ and $K'$ a positive probability to move to one 
  of these $K'$ (depending on the initially observed equivalence class). 
  Repeating this argument eventually leads to sets $T\in\mathcal{W}_{0}$ since 
  we decreasingly move through the stages of $\mathcal{W}$. Therefore, the 
  corresponding strategy enforces a positive probability to end up in $R$ from 
  where \eve{} may play on arbitrarily.
\end{proof}

\section{Automaton-compatible strategies}
We introduce the notion of \emph{automaton-compatible} strategies. We define
\begin{equation*}
  \mathcal{T} = \tuple{Q, \Sigma_{E}\times \interval{S}_{\sim_{E}}, q_{0}, 
  q_{s}, \delta, \lambda}
\end{equation*}
where $\Sigma_{E}\times \interval{S}_{\sim_{E}}$ is the input alphabet, 
$q_{0}, q_{s}\in Q$ a start and a sink state respectively, 
$\delta:Q\times \Sigma_{E}\times \interval{S}_{\sim_{E}}\rightarrow Q$ a 
deterministic transition function and $\lambda:Q\rightarrow\Pot(\Sigma_{E})$ a
labelling of the states of $\mathcal{T}$. Additionally, we enforce
\begin{itemize}
  \item $\lambda(q) = \emptyset$ if and only if $q = q_{s}$,
  \item $\delta(q, \tuple{\sigma, x}) = q_{s}$ if and only if 
    $\sigma\not\in\delta(q)$ for all $q\in Q$, $\sigma\in\Sigma_{E}$ and 
    $x\in\interval{S}_{\sim_{E}}$.
\end{itemize}
This automaton $\mathcal{T}$ associates with any play $u\in S^{*}$ in 
$\mathcal{G}$ precisely one $q\in Q$ and moreover, a labelling $\lambda(q)$. 
Any strategy $f$ of \eve{} is considered compatible with $\mathcal{T}$ if for 
any play $u\in S^{*}$ \eve{} plays an action from the associated labelling. One
important automaton is associated with \eve{}'s knowledge of the current 
situation of the game, i.e. the states she consideres possible given her 
observations. In general, this knowledge expands beyond the observed 
equivalence class since the history might render certain states within the 
current equivalence class impossible to be the current state.
This induces one special automaton structure $\mathcal{K}$: Knowledge is 
encoded as sets of states \eve{} considers possible. Fix an initial knowledge 
$K_{0}\subseteq S$ such that $K_{0}\subseteq\interval{s}_{\sim_{E}}$ for one 
$s\in S$. Inductively, we construct for any sequence 
$u\in \interval{S}_{\sim_{E}}^{*}$ the current knowledge of \eve{} 
$\currK^{K_{0}}_{E}$. Initially holds 
$\currK^{K_{0}}_{E}(\interval{s_{0}}_{\sim_{E}}) = K_{0}$ 
and at every step the knowledge is updated by $\upK_{E}$ which computes all
possible results considering the available information: 
\begin{align*}
  \upK_{E}&(K, e, \interval{s}_{\sim_{E}})\\
  &= \set{
    t\in\interval{s}_{\sim_{E}}\mid \text{there is }o\in K\text{ and }a\in A
    \text{ s. t. }\tau_{e,a}(o, t) > 0
  }
\end{align*}
for the current knowledge $K$, the chosen action $e\in E$ of \eve{} and the 
following observation $\interval{s}_{\sim_{E}}$. Hence, we obtain inductively
\begin{equation*}
  \currK(u\cdot s) = \upK(\currK(u), e, \interval{s}_{\sim_{E}})
\end{equation*} 
where $e = f(u)$ is the choice of \eve{}'s strategy $f$. We define an 
associated (unlabelled) knowledge-automaton for \eve{} for a fixed initial 
knowledge $K_{0}$ and loosing knowledge $K_{s}$
\begin{equation*}
  \mathcal{T}_{\mathcal{K}} = \tuple{
    \Pot(S), E\times\interval{S}_{\sim_{E}}, K_{0}, K_{s}, \upK
  }.
\end{equation*}

\subsection{Automaton-Game Product}
For a given automaton
\begin{equation*}
  \mathcal{T} = \tuple{Q, \Sigma_{E}\times \interval{S}_{\sim_{E}}, q_{0}, 
  q_{s}, \delta, \lambda}
\end{equation*}
and arena 
\begin{equation*}
  G = \tuple{S, E, A, \tuple{\tau_{e, a}}_{e\in E, a\in A}, \sim_{E}, \sim_{A}}
\end{equation*}
we define a product
\begin{definition}
  Given $G$ and $\mathcal{T}$ as above, we define
  \begin{equation*}
    G\otimes\mathcal{T} = \tuple{S\times Q, E, A, 
    \tuple{\tau'_{e, a}}_{e\in E, a\in A}, \sim'_{E}, \sim'_{A}}
  \end{equation*}
  with
  \begin{equation*}
    \tau'_{e, a}(\tuple{s,q}, \tuple{z,p}) = \begin{cases}
      \tau_{e, a}(s, z)&\text{if }p = \delta(q, (e,\interval{z}_{\sim_{E}})),\\
      0&\text{otherwise},
    \end{cases}
  \end{equation*}
  and
  \begin{center}
    \begin{tabular}{lll}
      $\tuple{s, q}\sim'_{E}\tuple{z, p}$& if and only if & $s\sim_{A} z$ and 
        $q = p$,\\
      $\tuple{s, q}\sim'_{A}\tuple{z, p}$& if and only if & $s = z, q = p$.
    \end{tabular}
  \end{center}
  Note that $\sim'_{A}$ is the equality relation and therefore \adam{} is not
  restricted in his observations whatsoever. We say \adam{} is 
  \emph{perfectly informed}.
\end{definition}
We observe the following result:
\begin{lemma}
  \eve{} has a $\mathcal{T}$-compatible strategy in the Safety-game
  $\tuple{G, B, Z}$ if and only if she has a surely winning
  strategy in the Safety-game 
  $\tuple{G\otimes\mathcal{T}, B\times\set{q_{0}}, 
    S\times\tuple{Q\setminus\set{q_{s}}}}$.
  \label{lem:TembeddedG}
\end{lemma}
\begin{proof}
  By the definition of $\mathcal{T}$ any action that is not compatible with 
  $\lambda$ yields $q_{s}$ as a result. Moreover, $\mathcal{T}$ is a
  deterministic automaton, hence any strategy of \eve{} in $\tuple{G, B, Z}$ 
  that is $\mathcal{T}$-compatible can be used equally in 
  $\tuple{G\otimes\mathcal{T}, B\times\set{q_{0}}, 
    S\times\tuple{Q\setminus\set{q_{s}}}}$ since by compatibility with 
  $\mathcal{T}$ a movement to $q_{s}$ is not possible. On the other hand, we 
  may translate any strategy in $\tuple{G\otimes\mathcal{T}, 
  B\times\set{q_{0}}, S\times\tuple{Q\setminus\set{q_{s}}}}$ to 
  $\tuple{G, B, Z}$. Since $S\times\set{q_{s}}$ is avoided this strategy 
  clearly is $\mathcal{T}$-compatible.
\end{proof}

This allows us to deduce for a fixed $\mathcal{T}$
\begin{theorem}
  When \adam{} is perfectly informed, one can decide in time polynomial in 
  $2^{\size{S}}$ and polynomial in $Q$ whether \eve{} has a 
  $\mathcal{T}$-compatible strategy that is positively winning in the 
  Reachability-game $\tuple{G, B, R}$. If such a strategy exists, one can 
  construct one that uses memory of size polynomial in $\size{Q}$ and 
  exponential in $\size{S}$.
  \label{thm:PerfInfAdamStrat}
\end{theorem}
\begin{proof}
  We consider the knowledges (in the sense of $\mathcal{K}$) of \eve{} in the
  arena $G\otimes\mathcal{T}$. We observe that the associated 
  observation-relation $\sim'_{E}$ in $G\otimes\mathcal{T}$ makes the current
  state transparent to \eve{}. Therefore, it is sufficient to capture the set
  of states of $G$ that \eve{} considers possible and the unique current state
  of $\mathcal{T}$. Hence, knowledges can be encoded as elements in 
  $\Pot(S)\times Q$. We fix the largest subset $\mathbb{K}$ of these knowledges 
  of \eve{} and an associated mapping $\lambda:\mathbb{K}\rightarrow\Pot(E)$ 
  such that:
  \begin{itemize}
    \item for all $K\in\mathbb{K}$ holds that $K\cap S\times\set{q_{s}} = 
      \emptyset$, i.e. \eve{} avoids states beyond her Safety-region in 
      $G\otimes\mathcal{T}$ and
    \item for all $K\in\mathbb{K}$ it holds that
      \begin{equation*}
        \upK_{E}(K, e, \interval{s}_{\sim_{E}})\in
          \mathbb{K}\setminus\set{\emptyset}
      \end{equation*}
      for every $e\in\lambda(K)$, i.e. actions of \eve{} may not move her 
      outwards these \enquote{safe} knowledges.
  \end{itemize}
  Merging all elements of $\tuple{\Pot(S)\times Q}\setminus\mathbb{K}$ in 
  $K_{s}$ allows to obtain the associated automaton $\mathcal{T}_{\mathbb{K}}$
  with labelling $\lambda$. Considering the knowledge structures is sufficient
  for Reachability-conditions (cp. \cite{AlgorithmsForPOSG}). Again, we embed 
  $\mathcal{T}_{\mathbb{K}}$ into the arena and obtain
  \begin{lemma}
    \eve{} has a $\mathcal{T}$ compatible positively winning strategy in the
    Reachability-game $\mathcal{G} = \tuple{G, B, R}$ if and only if she has a
    positively winning strategy in the Reachability-game $\mathcal{G'} = 
    \tuple{G\otimes\mathcal{T}_{\mathbb{K}}, B\times\set{K_{0}}, R\times 
    \tuple{\mathbb{K}\setminus K_{0}}}$. 

    This positively winning strategy in 
    $\mathcal{G'}$ can be translated to a positively winning strategy in 
    $\tuple{G, B, R}$ with memory of size 
    $\mathcal{O}(N\cdot\size{\Pot(S)}\cdot\size{Q})$ where $N$ is the memory
    size of the positively winning strategy in $\mathcal{G'}$.
    \label{lem:AutoCompStrat}
  \end{lemma}
  \begin{proof}
    Positively winning in $\mathcal{G'}$ can be restricted to those that 
    respect the actions given in $\lambda$ regarding the $\mathbb{K}$-component 
    of the current position. Otherwise this component becomes $K_{s}$ which 
    traps the play and does not allow to play for the Reachability target 
    anymore, but by definition of $\mathbb{K}$ and $\lambda$ even loosing plays
    may respect $\lambda$. By Lemma \ref{lem:TembeddedG} we obtain the 
    $\mathcal{T}$-compability of the strategy. Simulating 
    $\mathcal{T}_{\mathbb{K}}$ allows to translate this strategy to the 
    original game. Conversely, any positively winning $\mathcal{T}$-compatible 
    strategy in $\tuple{G, B, R}$ induce a corresponding strategy in 
    $\mathcal{G'}$.
  \end{proof}
  We may use Theorem \ref{thm:PerfInfAdamReach} to obtain a strategy for \eve{}
  in the game $\mathcal{G'}$ from Lemma \ref{lem:AutoCompStrat} since \adam{}
  is perfectly informed there to obtain the desired result.
\end{proof}

\section{Better Informed \adam{}}
Consider an automaton $\mathcal{T}$ as before and an arena $G$ as before but we
additionally consider $\sim_{A} \subseteq \sim_{E}$, i.e. if \adam{} considers
two states equal so does \eve{} but not necessarily the other way around. 
\adam{} is considered \emph{better informed} than \eve{} in such a game. 
Naturally, this case includes equally informed players, i.e. 
$\sim_{A} = \sim_{E}$. Assuming \adam{} is better informed that \eve{} allows
to argue that knowledge of \adam{} is always at least as good as knowledge of
\eve{}. This leads to
\begin{theorem}
  When \adam{} is more informed than \eve{}, one can decide in time polynomial
  in $2^{2^{\size{S}}}$ and polynomialn in $\size{Q}$ whether \eve{} has a 
  $\mathcal{T}$-compatible strategy that is positively winning in the 
  reachability game $\tuple{G, B, R}$. If such a strategy exists, we can 
  construct one with memory polynomial in $\size{Q}$ and doubly exponential in
  $\size{S}$.
  \label{thm:MoreInfAdamStrat}
\end{theorem}
\begin{proof}
  We fix 
  \begin{equation*}
    \mathcal{H} = \set{
      A\in\Pot{S}\mid\text{there exists }s\in S\text{ s.t. }
       A\subseteq\interval{s}_{\sim_{A}}
    }
  \end{equation*}
  and an associated operator
  $h: \mathcal{H}\times E\times A\rightarrow\Pot(\mathcal{H})$
  with 
  \begin{equation*}
    h(H, a, e) = \set{
      H'\cap\interval{s}_{\sim_{A}}:\text{for all }H' = 
        \bigcup_{s\in H}\supp(\tau_{e,a}(s, \cdot))\text{ and }s\in S
    }.
  \end{equation*}
  From which we define a new arena $G' = \tuple{\mathcal{H}, E, A, 
  \tuple{\tau'_{e,a}}_{e\in E,a\in A}, \sim'_{E}, \sim'_{A}}$ with
  \begin{equation*}
    \tau'_{e,a}(H, H') = \begin{cases}
      \frac{1}{\size{h(H, e, a)}}&\text{if }H'\in h(H, e, a),\\
      0&\text{otherwise},
    \end{cases}
  \end{equation*}
  and
  \begin{center}
    \begin{tabular}{llll}
      $H_{1}\sim'_{E} H_{2}$ & if and only if & $s_{1}\sim_{E} s_{2}$ & 
        for all $s_{1}\in H_{1}, s_{2}\in H_{2}$,\\
      $H_{1}\sim'_{A} H_{2}$ & if and only if & $H_{1} = H_{2}$. & \\
    \end{tabular}
  \end{center}
  Note that \adam{} is perfectly informed and the equivalence classes of 
  $\sim'_{E}$ can be identified with equivalence classes of $\sim_{E}$ 
  since \eve{} is less informed than \adam{} and therefore all elements in any
  $H\in\mathcal{H}$ are indistinguishable for \eve{}. We define 
  $\nu(K) = \set{\set{s}:s\in K}$ and obtain
  \begin{proposition}
    \eve{} has a positively winning $\mathcal{T}$-compatible strategy in the 
    Reachability-game $\mathcal{G} = \tuple{G, B, R}$ if and only if she has a 
    positively winning $\mathcal{T}$-compatible strategy in the 
    Reachability-game $\mathcal{G'} = \tuple{G', \nu(B), R'}$ with 
    $R' = \set{H\in\mathcal{H}\mid H\cap R\neq\emptyset}$.
  \end{proposition}
  \begin{proof}
    First, by the observation that we idenfity $H\in\mathcal{H}$ for \eve{} as
    their associated equivalence classes we conclude that 
    $\mathcal{T}$-compatibility translates for strategy in both games.

    Consider any positively winning $\mathcal{T}$-compatible strategy $f$ in
    $\mathcal{G}$. By Proposition \ref{prop:FiniteSteps} we obtain a bound 
    $N$ and a positive probability $\epsilon_{N}$ such that \eve{} visits $R$
    in $N$ steps with probability at least $\epsilon_{N}$. We observe that
    given $f$ \adam{} is informed of \eve{}'s actions and may compute very at
    every moment $h(H, e, a)$. Moreover, given any strategy of \adam{} for the
    first $N$ steps in $\mathcal{G'}$ computes precisely the states reachable
    with positive probability in $\mathcal{G}$ given \eve{} translates $f$ and 
    \adam{} his strategy. Naturally, one of these states contains a state in
    $R'$ by the choice of $N$.

    On the other hand, assume $f$ is $\mathcal{T}$-compatible and positively
    winning in $\mathcal{G'}$. Assuming that there is $g$ in $\mathcal{G}$ to
    avoid $R$ indefinitely, This strategy may be equally be played in 
    $\mathcal{G'}$. Here it must not cause a situation where $R'$ is avoided
    indefinitely since $f$ is assumed to be winning. Nevertheless, the elements 
    of the states in $\mathcal{G'}$ that are reached with positive probability 
    coincide with those states in $\mathcal{G}$ that are reached with positive 
    probability. This contradicts either $f$ positively winning in 
    $\mathcal{G'}$ or the existence of $g$ in $\mathcal{G}$.
  \end{proof}
  Applying Theorem \ref{thm:PerfInfAdamStrat} to this $\mathcal{G'}$ gives the
  desired results.
\end{proof}

\section{Almost-Surely Winning for BÃ¼chi-Conditions}
We move from Reachability-conditions to BÃ¼chi-conditions, hence we fix an arena
\begin{equation*}
  G = \tuple{S, E, A, \tuple{\tau_{e,a}}_{e\in E,a\in A}, \sim_{E}, \sim_{A}}
\end{equation*}
and an associated BÃ¼chi-set $F\subseteq S$. For this game we define 
\emph{almost-surely winning knowledges} for \eve{} $\mathcal{K}^{\top}$, which
is a collection of subsets $K\subseteq S$ such that every 
$K\subseteq\interval{s}_{\sim}$ for one $s\in S$ and \eve{} almost-surely wins
the BÃ¼chi-game $\tuple{G, K, F}$. We characterize $\mathcal{K}^{\top}$ as a
fixpoint of the operator $\Xi:\Pot(\Pot(S))\rightarrow\Pot(\Pot(S))$ where for
one $\mathcal{K}\subseteq\Pot(S)$ and $K\in\mathcal{K}$ we consider 
$K\in\Xi(\mathcal{K})$ if \eve{} has a positively winning strategy in the
\emph{Reachability-}game $\tuple{A, K, F}$ such that her knowledge does never
leave $\mathcal{K}$. We claim $\mathcal{K}^{\top}$ is the greatest fixpoint of
$\Xi$ and substantiate this claim with
\begin{lemma}
  $\mathcal{K}^{\top}$ indeed is the greatest fixpoint of $\Xi$.
\end{lemma}
\begin{proof}
  For any set of knowledges $\mathcal{K}\subseteq\Pot(S)$ we say some 
  $K\in\mathcal{K}$ is $\mathcal{K}$-\emph{good} if \eve{} has a positively
  winning strategy in the Reachability-game $\tuple{G, K, F}$ which constantly
  produces knowledges of \eve{} which are in $\mathcal{K}$. We proceed in 
  showing that any $K\in\mathcal{K}^{\top}$ is $\mathcal{K}^{\top}$-good 
  implying that $\mathcal{K}^{\top}$ is a fixpoint of $\Xi$.
  \begin{lemma}
    Fix any $K\in\mathcal{K}^{\top}$ and the associated almost-surely winning
    strategy $f_{K}$ of \eve{} in the BÃ¼chi-game $\tuple{G, K, F}$ with 
    $e = f_{K}(\interval{k}_{\sim_{E}})$ for any $k\in K$ (by definition of 
    $\mathcal{K}^{\top}$ all $k\in K$ are of the same equivalence class). Then,
    for every $a\in A$ and all 
    $z\in \cup_{o\in K}\supp(\tau_{e,a}(o,\cdot))$ holds
    \begin{equation*}
      \upK(K, e, \interval{z}_{\sim_{E}})\in\mathcal{K}^{\top}.
    \end{equation*}
  \end{lemma}
  \begin{proof}
    Consider one $a\in A$ and $z\in \cup_{o\in K}\supp(\tau_{e,a}(o,\cdot))$
    as above. Fix $K' = \upK(K, e, \interval{z}_{\sim_{E}})$. Notably, there is
    a strategy for \adam{} to force the play into $z$ with positive 
    probability. If \eve{} did not have a almost-surely winning strategy in the
    BÃ¼chi-game $\tuple{G, z, F}$ with initial knowledge $K'$ she would not have
    an almost-surely winning strategy in $\tuple{G, K, F}$ to begin with. Hence
    $K'\in\mathcal{K}^{\top}$ and inductively we get that $K$ is 
    $\mathcal{K}^{\top}$-good since there are only finitely many steps until a 
    state in $F$ is visited (by Proposition \ref{prop:FiniteSteps}) and all 
    these steps ensure to stay in $\mathcal{K}^{\top}$ by the argument above.
  \end{proof}
  Hence, we established $\mathcal{K}^{\top}$ as fixpoint of $\Xi$ only missing
  that it is the greatest fixpoint. Fix any other $\mathcal{K}$ with 
  $\Xi(\mathcal{K}) = \mathcal{K}$ and by definition of $\Xi$ every 
  $K\in\mathcal{K}$ is $\mathcal{K}$-good and by Proposition 
  \ref{prop:FiniteSteps} comes with associated $N_{K}$, $\epsilon_{K}$. Set
  $N = \max\set{N_{K}:K\in\mathcal{K}}$ and 
  $\epsilon = \min\set{\epsilon_{K}:K\in\mathcal{K}}$. Separating the game into
  sequences of length $N$ where \eve{} considers her initial knowledge $H$ and
  plays for $N$ steps with strategy $f_{H}$, then she re-considers her initial
  knowledge $H'$ and plays for $N$ steps with strategy $f_{H'}$ and so on. This
  gives a strategy $f$ and we claim $f$ is almost-surely winning in the 
  BÃ¼chi-game $\tuple{G, K, F}$. By definition of $f$ there is a probability of
  at least $\epsilon$ to visit a state in $F$ all $N$ steps. That states in $F$
  are almost-surely visited infinitely often is a direct consequence of 
  Theorem \ref{thm:BorelCantelli}. This entails that $K\in\mathcal{K}^{\top}$
  concluding the proof.
\end{proof}
By obvious monotonicity of $\Xi$ and $\mathcal{K}^{\top}\subseteq\Pot(S)$ we
reach a fixpoint after at most $2^{\size{S}}$ applications of $\Xi$. Expressing
that \eve{}'s knowledge consistently agrees with some $\mathcal{K}$ can be done
by defining an appropiate automaton $\mathcal{T}_{\mathcal{K}}$ with states
exponential in $S$. Theorem \ref{thm:StratPOSG} follows by using Theorem 
\ref{thm:MoreInfAdamStrat} to compute all steps of $\Xi$.
