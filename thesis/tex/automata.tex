\chapter{On words and trees}
It is well established to rely on finite automata to recognize languages of
infinite objects, e.g. trees or words \cite{LangAutoLog}. In this chapter we
recall some known results for languages of infinite words and infinite trees.
Furthermore, building upon the work in \cite{RandAutoInfTrees}, we introduce
and examine a new class of tree automata, called \aclp{WDTA}. In Chapter
\ref{chapter:synthesis} we use these class of automata to (re-)prove some
synthesis results in the context of probabilistic environments.

\section{$\omega$-regular Languages}
\label{sec:wordautomata}
Following \cite{LangAutoLog} (resp. \cite[Chapter 1]{AutoLogInfGames} for the
Parity-condition below) we introduce word automata with the following
structural definition
\begin{definition}[Word Automaton]
  We define a word automaton as
  $\mathcal{A} = \tuple{Q, \Sigma, q_{0}, \Delta}$ where
  $Q$ is a set of states, $\Sigma$ a finite alphabet, $q_{0}\in Q$ is the
  initial state and $\Delta\subseteq Q\times\Sigma\times Q$ is the transition
  relation. We define some associated notions as follows:
  \begin{description}
    \item [Run]
      For a word $\alpha = \alpha_{0}\alpha_{1}\dots\in\Sigma^{\omega}$ we call
      a sequence $\pi = \pi_{0}\pi_{1}\dots \in Q^{\omega}$ a run of
      $\mathcal{A}$ on $\alpha$ if $\pi_{0} = q_{0}$ and for every
      $i\in\mathbb{N}$ holds that
      $\tuple{\pi_{i}, \alpha_{i}, \pi_{i+1}}\in\Delta$
    \item [Determinism]
      We call $\mathcal{A}$ deterministic if for every pair $q\in Q$ and
      $\sigma\in\Sigma$ the set
      $\set{p\in Q\mid\tuple{q,\sigma,p}\in\Delta}$ has at most one
      element.
  \end{description}
\end{definition}
This allows for automata to yield for an input word a corresponding run, i.e.
attach onto the input word a word of states that is consistent with the
structure of the automaton. These attached words of states are runs of word
automata on words and are categorized as accepting or non-accepting by the
following conditions:
\begin{definition}[Acceptance Conditions]
  For a word automaton $\mathcal{A} = \tuple{Q, \Sigma, q_{0}, \Delta}$ we
  define different acceptance conditions. For this we define for a run
  $\pi = \pi_{0}\pi_{1}\dots\in Q^{\omega}$ the operator
  $\Inf$ as the set of states that occur infinitely in a run, i.e.
  \begin{equation*}
    \Inf(\pi) = \set{q\in Q\middle| \text{ there are infinitely many }
    i\in\mathbb{N} \text{ s.t. } \pi_{i} = q}.
  \end{equation*}
  With this notion we define the following acceptance conditions:
  \begin{description}
    \item [Büchi] A Büchi condition is defined by a set of final states
      $F\subseteq Q$ and we call a run $\pi$ accepting if
      $\Inf(\pi)\cap F\neq\emptyset$.
    \item [Muller] Muller conditions are given as a family of state sets, i.e.
      $\mathcal{F}\subseteq 2^{F}$. A run $\pi$ is called accepting if
      $\Inf(\pi)\in\mathcal{F}$.
    \item [Rabin] This acceptance condition is represented by a set of pairs\\
      $\Omega = \set{\tuple{E_{0}, F_{0}}, \dots, \tuple{F_{n}, E_{n}}}$ and we
      call a run $\pi$ accepting if there is an $i$ s.t.
      $\Inf(\pi)\cap F_{i}\neq\emptyset$ but $\Inf(\pi)\cap E_{i} = \emptyset$.
    \item [Parity] This condition is defined by a function
      $\parity:Q\rightarrow \mathbb{N}$. We call a run $\pi$ accepting if the
      maximum of the set $\parity(\Inf(\pi))$, which describes the pointwise
      application of $\parity$ to the set $\Inf(\pi)$, is even (note that due
      to the finiteness of $Q$, $\Inf(\pi)$ is finite as well and thus the
      maximum of $\parity(\Inf(\pi))$ exists).
  \end{description}
  For any of these objects $\Gamma\in\set{F, \mathcal{F}, \set{\tuple{E_{0},
  F_{0}},\dots,\tuple{E_{n}, F_{n}}}, \parity}$ we use $\Acc(\Gamma)$ to refer
  to the accepted language. If necessary we use subscripts to $\Acc$ to make 
  the interpretation of its argument clear.
\end{definition}\fxfatal{find fitting reference for prefix-independence}
Note that by the nature of these acceptance conditions, namely that acceptance
solely depends on those states that occur infinitely often, the acceptance is
at any moment determined by the \enquote{future}. We call this
\emph{prefix-independence} and formerly capture this by stating that every
$\alpha = \alpha_{1}\alpha_{2}\dots\in\Acc(\Gamma)$ implies that for any $i>0$
also $\alpha_{i}\alpha_{i+1}\dots\in\Acc(\Gamma)$ (again we let $\Gamma$ be a
meta variable, ranging over the described finite representations of acceptance
conditions). We categorize word automata by their acceptance condition and if
they are deterministic. Thus, we call - for example - a word automaton
$\mathcal{A}$ equipped with a Büchi-condition a \ac{NBA} or respectively
\ac{DBA} if $\mathcal{A}$ is deterministic. And analogously we obtain word
automata for Muller-, Rabin- and Parity-conditions and corresponding
acronyms. 
\acuse{NMA}\acuse{DMA}\acuse{NRA}\acuse{DRA}\acuse{NSA}\acuse{DSA}\acuse{NPA}
\acuse{DPA}

The theory to these - so called - $\omega$-automata is well
established. We recall some of the central results and provide proofs since it
allows us to define auxiliary structures in a simple context which we use later
on in more involved settings. Our arguments follow, in some condensed and
occasionally less formal form, \cite[Chapter 1]{AutoLogInfGames}. We start with
\begin{example}
  We consider the language $\mathcal{L}$ as the set of all infinite
  words over the alphabet $\set{a,b}$ such that $a$ occurs only finitely often.
  This language can be accepted using e.g. an \ac{NBA} $\mathcal{A}$ as defined 
  in Figure \ref{fig:finaautomata}. The argument that this \ac{NBA} accepts 
  $\mathcal{L}$ is as follows: The non-determinism allows the automaton to 
  \enquote{guess} one moment from which on no more $a$ is read. For any word in 
  $\mathcal{L}$ such a moment exists and can therefore be correctly guessed 
  while every word that is accepted by $\mathcal{A}$ needs to move to its
  $q_{F}$ state and it is straightforward to argue that no more $a$ can occur
  afterwards.

  Alternatively, we can accept $\mathcal{L}$ by a \ac{DPA} $\mathcal{B}_{P}$,
  \ac{DRA} $\mathcal{B}_{R}$, \ac{DMA}
  $\mathcal{B}_{M}$ which all share the same structure as defined in Figure
  \ref{fig:finaautomata}. We use the different acceptance conditions to model
  the same restriction, namely that $q_{a}$ only occurs finitely often while
  $q_{b}$ occurs infinitely often.
  \begin{description}
    \item [$\mathcal{B}_{P}$] We define $\parity(q_{a}) = 1$ and
      $\parity(q_{b}) = 0$, thus - since the parity of $q_{a}$ trumps the
      parity of $q_{b}$ but is odd - $q_{a}$ must only occur finitely often.
    \item [$\mathcal{B}_{R}$] Here we define $\set{\tuple{E = \set{q_{a}},
      F = \set{q_{b}}}}$, which models the restriction very clearly by
      explicitly stating which states are \enquote{good} respectively
      \enquote{bad} to visit infinitely often.
    \item [$\mathcal{B}_{M}$] The acceptance family is fixed with
      $\mathcal{F} = \set{\set{q_{b}}}$, thus the only way to achieve an
      accepting run is to eventually stay in $q_{b}$.
  \end{description}
  It is noteworthy that all these conditions are essentially modelling the
  abscence of a state. This is occasionally done by defining a set of states
  that must only be visited finitely often. Such an acceptance condition is
  called a co-Büchi-condition with $F = \set{q_{a}}$ and describes the inverse
  of a Büchi-condition (hence the name).
 
  Note that on the other hand we used a structural way to model this negative
  restriction for $\mathcal{A}$.
  \label{ex:fina}
\end{example}
\begin{drawing}
  \caption{In (a) an \ac{NBA} is illustrated which accepts the language of
  words with finitely many $a$. The states of the Büchi-condition $F$ are
  marked by doubling the outline, i.e. $F = \set{q_{F}}$.
  In (b) a deterministic automaton is defined which simply moves to $q_{a}$
  (resp. $q_{b}$) if an $a$ (resp. $b$) is read (starting in $q_{a}$).}
  \label{fig:finaautomata}
  \resizebox{\textwidth}{!}{\includegraphics{tikz/fina-automaton.pdf}}
\end{drawing}
We radically compress the rich theory of $\omega$-automata by stating the 
following
\begin{theorem}
  \cite[Theorem 1.19, Theorem 1.24, Section 1.3.2,Theorem 3.2]{AutoLogInfGames}
  The class of recognizable languages coincides for \acp{NBA}, \acp{NMA},
  \acp{DMA}, \acp{NRA}, \acp{DRA}, \acp{NPA} and \acp{DPA} and is called
  $\omega$-regular languages. \acp{DBA} are strictly less expressive.
  \label{thm:omegaregularexp}
\end{theorem}
Additionally, we will restrict the proof to some of its arguments, namely one
which allows us to introduce the concept of \acp{LAR} and some that are easily
explained and also later on referred to.
\begin{proof}
  Firstly, we provide an argument to show that \acp{DBA} are less expressive.
  Consider again $\mathcal{L}$ from Example \ref{ex:fina} and the following
  argument: the deterministic nature of any \ac{DBA} $\mathcal{A}$ yields one
  possible run for every word of $\mathcal{A}$. This means that words with
  common finite prefixes share common finite prefixes of their individual runs.
  Assume to have one \ac{DBA} $\mathcal{A}$ which accepts $\mathcal{L}$ and 
  consider the following family of words with common prefixes
  \begin{equation*}
    b^{\omega}, b^{n_{0}}ab^{\omega}, b^{n_{0}}ab^{n_{1}}ab^{\omega}, \dots,
  \end{equation*}
  where every $n_{i}$ is chosen such that the unique run in $\mathcal{A}$
  just visited a state in $F$ (which needs to happen since every element of
  this word-family is in $\mathcal{L}$ and therefore accepted by $\mathcal{A}$).
  Thus, by iterating \enquote{sliding in} $a$ after a visit in $F$ we construct 
  a word which is accepted but contains infinitely many $a$ contradicting that
  $\mathcal{A}$ actually recognizes $\mathcal{L}$.

  Secondly, we argue that Muller-, Rabin- and Parity-conditions are
  equally expressive. Therefore, we initially consider that all deterministic
  automata are non-deterministic automata which do not use their
  non-determinism. Furthermore it is easy to see, that Rabin- and
  Parity-conditions are captured by Muller-conditions by enumerating all
  $\Inf$-sets that satisfy the corresponding conditions. In a second step we
  show that \acp{NMA} can be translated to \acp{NPA} as well as \acp{NRA}. This
  translation makes use of the following construct:
  \begin{definition}[Latest Appearance Record]
    For a finite state set $Q$ define the set of permutations of elements in
    $Q$ as $\perm(Q)\subseteq Q^{\size{Q}}$ and
    \begin{equation*}
      \lar(Q) = \set{\interval{w,h}\mid w\in\perm(Q)\text{ and }1\leq
      h\leq\size{Q}}
    \end{equation*}
    Additionally we define an update function
    $\up:\lar(Q)\times Q\rightarrow\lar(Q)$ with
    \begin{equation*}
      \up(\interval{q_{1}\dots q_{n},h}, q)
      = \interval{qq_{1}\dots q_{i-1}q_{i+1}\dots q_{n},i}
      \text{ for the unique }i\text{ s.t. }q=q_{i}
    \end{equation*}
    and conclude with one auxillary definition:
    \begin{description}
      \item [Hit set] for $\ell = \interval{q_{1}\dots q_{n},h}$ we call
        $\set{q_{1},\dots,q_{h}}$ the hit set of $\ell$.
    \end{description}
  \end{definition}
  For a word $q_{1}q_{2}\dots\in Q^{\omega}$ we can obtain one associated
  sequence of elements in $\lar(Q)$ by picking one arbitrary starting value
  $\ell_{1}$ and successively applying the update operation, i.e.
  $\ell_{1}\ell_{2}\dots\in\lar(Q)^{\omega}$ with
  $\ell_{i+1} = \up(\ell_{i},q_{i})$ for all $i>0$. We can now state that
  $\Inf(q_{1}q_{2}\dots)$ moves to the beginning of the $\lar(Q)$ elements in
  the associated sequence
  \begin{lemma}
    \cite[Lemma 1.21]{AutoLogInfGames}
    $\Inf(q_{1}q_{2}\dots) = F$ if and only if from one $k>0$ the hit set of
    all $\ell_{i}$ for $i>k$ is a subset of $F$ and there are infinitely many
    $i>k$ s.t. the hit set of $\ell_{i}$ coincides with $F$.
    \label{lem:larhitset}
  \end{lemma}
  This Lemma induces that the sequence of hit sets stabilises to the set
  $\Inf(q_{1}q_{2}\dots)$. Thus, $q_{1}q_{2}\dots$ satisfies a Muller condition
  $\mathcal{F}$ if and only if the hit sets stabilises to an element of
  $\mathcal{F}$. This can be captured within a parity condition by associating
  to $\ell = \interval{p_{1}\dots p_{n},h}$ with hit set
  $H = \set{p_{1},\dots,p_{h}}$ a parity condition
  \begin{equation*}
    \parity(\ell) = \begin{cases}
      2\cdot\size{H} &\text{ if }H\in\mathcal{F}\\
      2\cdot\size{H}-1 &\text{ if }H\notin\mathcal{F}
    \end{cases}
  \end{equation*}
  Thus, winning hit sets do have an even and losing hit sets do have an odd
  parity and notably the highest parity value is even if and only if
  $\Inf(q_{1}q_{2}\dots)\in\mathcal{F}$. Therefore, we can define a \ac{NPA}
  that has as state set the elements $\lar(Q)$ and mirrors the transitions of
  the original \ac{NMA} through the application of the update function, i.e.
  for every $\tuple{q, a, p}$ there is a corresponding 
  $\tuple{\ell_{q}, a, \up(\ell_{q}, p)}$ for every $\ell_{q}\in\lar(Q)$ that
  is produced by $\up(\cdot,q)$. Every run in the \ac{NPA} can be translated 
  back to a run in the original \ac{NMA} and vice versa and by Lemma 
  \ref{lem:larhitset} and the definition of $\parity$ we obtain the acceptance
  equivalence of both runs. We close this argument by stating that
  any Parity-condition can be expressed by a Rabin-condition as follows:
  we define for every occuring even parity $k\in\parity(Q)$ a pair
  $\tuple{E_{k}, F_{k}}$ where $F_{k} = \parity^{-1}(k)$ and
  $E_{k} = \cup_{p>k}\parity^{-1}(p)$; hence, an accepting run regarding the
  Parity-condition satisfies the pair associated with the highest parity and
  on the other hand, any run that is accepting by the Rabin-condition, namely
  by the pair $\tuple{E_{k}, F_{k}}$, has  $k$ as the highest parity which is
  the even witness rendering the run accepting.

  Thirdly, we conclude by stating (without proof) that for every \acp{NMA} 
  exists an equivalent \ac{NBA} and - more easily - the other way around
  \begin{theorem}
    \cite[Theorem 1.10]{AutoLogInfGames}
    For every \acp{NBA} exists an equivalent \ac{NMA} and for every \acp{NMA}
    exists an equivalent \ac{NBA}.
  \end{theorem}
  And also we avoid the lengthy technicalities of determinization of an
  \ac{NBA} by simply stating
  \begin{theorem}
    \cite[Theorem 3.6]{AutoLogInfGames}
    For every \acp{NBA} exists an equivalent \ac{DMA}.
  \end{theorem}
\end{proof}

Finally, we state here
\fxfatal{effective construction for union is not mentioned in reference}
\begin{theorem}
  \cite[Consequence from Theorem 1.5 and Theorem 1.24]{AutoLogAndInfGames}
  The $\omega$-regular languages form a Boolean-algebra, i.e. are closed under
  union, intersection and negation. The transformations can be effectively
  constructed.
  \label{thm:omegaregboolean}
\end{theorem}
\begin{proof}
  The proof consist of operations that take two (respectively one) word 
  automata and construct a word automaton that accepts the union, intersection 
  or respectively the negation. Beginning with the union, we make use of
  non-determinism such that the resulting automaton guesses at the beginning in
  which language the word is and simulates the \enquote{correct} automaton. The 
  closure under intersection makes use of a natural product construction, 
  namely
  \begin{definition}
    For $\mathcal{A}_{1} = \tuple{Q, \Sigma, q_{0}, \Delta}$ and
    $\mathcal{A}_{2} = \tuple{P, \Sigma, p_{0}, \nabla}$ we define
    \begin{equation*}
      \mathcal{A}_{1}\otimes\mathcal{A}_{2} = \tuple{Q\times P, \Sigma, 
      \tuple{q_{0}, p_{0}}, \Delta\otimes\nabla}
    \end{equation*}
    with
    \begin{equation*}
      \Delta\otimes\nabla = 
      \set{\tuple{\tuple{q^{1}, p^{1}}, \sigma, 
      \tuple{q^{2}, p^{2}}}: \tuple{q^{1},\sigma, q^{2}}\in\Delta, 
      \tuple{p^{1},\sigma, p^{2}}\in\nabla}.
    \end{equation*}
  \end{definition}
  Every run in this product can be separated into runs in $\mathcal{A}_{1}$ and
  $\mathcal{A}_{2}$. W.l.o.g. we can assume the original two automata to be
  equipped with Muller-conditions $\mathcal{F}_{1},\mathcal{F}_{2}$ and define
  for the product automaton the Muller-condition 
  \begin{equation*}
    \mathcal{F} = \set{\set{\tuple{q^{1}, p^{1}},\dots,\tuple{q^{1}, p^{1}}}:
    \set{q^{1},\dots,q^{n}}\in\mathcal{F}_{1},
    \set{p^{1},\dots,p^{n}}\in\mathcal{F}_{2}}.
  \end{equation*}
  Hence the run in the product automaton is accepted if and only if the 
  associated runs in the original automata are accepted.

  The closure under negation can be expressed very elegantly (cp. 
  \cite[Transformation 1.25.]{AutoLogInfGames}). W.l.o.g. we consider the 
  original automaton to be a \ac{DPA}. By setting a new Parity-condition with
  $\parity'(q) = \parity(q) + 1$ and keeping the original structure we exchange
  non-accepting and accepting runs and therefore obtain a structural equivalent 
  \ac{DPA} that precisely accepts the complement of the original automaton.
\end{proof}

\section{Probabilistic Büchi Automata}
Upon the concept of \acp{NBA} there are approaches to substitute the
non-deterministic choices by probabilistic ones, e.g.
\cite{RecOmeLangProbAuto,DecProblemsForProbAuto,Groesser}. We begin with
a formal introduction of an automaton model which makes use of this idea,
called \aclp{PBA}. Then we proceed by introducing the necessary concept of
measuring theory to formally define their semantics. Additionally, these basic
concepts of measuring theory are re-used later on for more complex
probabilistic automata models.

A \ac{PBA} essentially is a \ac{NBA} where the non-determinism is solved by a 
probability distribution. Therefore, we define analogously to 
\cite{Groesser}
\begin{definition}[Probabilistic Büchi Automata]
  A \acl{PBA} $\mathcal{A}$ over a finite alphabet $\Sigma$ is defined by a
  tuple $\tuple{Q, \Sigma, \delta, q_{0}, F}$ where $Q$ is a finite state set,
  $q_{0}\in Q$ the initial state,
    $\delta:Q\times\Sigma\times Q\rightarrow \interval{0,1}$
  a transition probability function such that for all pairs $q\in Q$ and
  $\sigma\in\Sigma$ we have $\sum_{p\in Q}\delta(q,\sigma,p)\in\set{0,1}$
  and $F\subseteq Q$ is the set of final states.
\end{definition}
Note that this definition may also be altered to allow initial distributions
rather than one initial state \cite{RecOmeLangProbAuto}. Conceptually, a
\ac{PBA} $\mathcal{P}$ processes an input word similarly as other word automata
by sequentially reading the letters of the input word and moving along its
states. Provided the current state is $q$ and the next letter of the input word 
is $a$ then $\mathcal{P}$ consults $\delta$ to determine its next state,
specifically $\mathcal{P}$ chooses a state $p$ by the probability
$\delta(q,a,p)$. Naturally, any run of $\mathcal{P}$ starts in its initial
state $q_{0}$ (respectively $\mathcal{P}$ may choose its initial state by a
given probability distribution $\iota:Q\rightarrow\interval{0,1}$). Considering
one fixed input word $\alpha$ the \ac{PBA} $\mathcal{P}$ provides a process
which produces corresponding state sequences with certain probabilities. Its
acceptance is defined by the notion of how probable the produced state 
sequences are to satisfy the associated Büchi-condition $F$. The formal
definition of this intuition requires a little work beforehand.
Following \cite{Groesser,Bauer}, we fix a set $\Omega$ which is the collection 
of all possible results, in the context of \acp{PBA} all possible sequences of
states $Q^{\omega}$ to the input word $\alpha$. 
For such an $\Omega$ we introduce a \emph{$\sigma$-algebra} which is a 
collection of subsets of $\Omega$, formally:
\begin{definition}[$\sigma$-Algebra]
  For a set $\Omega$ we call $\mathcal{F}\subseteq\Pot(\Omega)$ for $\Omega$ a
  $\sigma$-algebra if
  \begin{enumerate}
    \item $\Omega\in\mathcal{F}$,
    \item for every $A\in\mathcal{F}$ we have $\tuple{\Omega\setminus A}
      \in\mathcal{F}$,
    \item for a countable collection $\tuple{A_{i}}_{i\in\mathbb{N}}$ with
      $A_{i}\in\mathcal{F}$ we also have $\tuple{\cup_{i\in\mathbb{N}}A_{i}}\in
      \mathcal{F}$.
  \end{enumerate}
\end{definition}
A probability space is defined by a set of possible results, a $\sigma$-algebra
which describes those collection of events we can observe and a function which
describes how probable a chosen observation is:
\begin{definition}[Probability Space]
  For a set $\Omega$ and a $\sigma$-algebra $\mathcal{F}$ for $\Omega$ we
  define a probability function as $\mu:\mathcal{F}\rightarrow\interval{0,1}$
  such that
  \begin{enumerate}
    \item $\mu(\Omega) = 1$,
    \item for a countable collection $\tuple{A_{i}}_{i\in\mathbb{N}}$ with
      $A_{i}\in\mathcal{F}$ we have $\mu(\cup_{i\in\mathbb{N}}A_{i}) =
      \sum_{i\in\mathbb{N}}\mu(A_{i})$.
  \end{enumerate}
  And we call a triple $\tuple{\Omega,\mathcal{F},\mu}$ a probability space.
  For any finite or at most countably large set $\Omega$ we can additionally
  define a
  \begin{description}
    \item [Probability Distribution] as a function
      $P:\Omega\rightarrow\interval{0,1}$ such that
      $\sum_{\omega\in\Omega}P(\omega) = 1$. 
  \end{description}
\end{definition}
Thus, we are interested in a probability space that is induced by the \ac{PBA}
$\mathcal{P}$ on the base set $Q^{\omega}$ while reading the input word 
$\alpha$. Fix for every $u\in Q^{*}$ the set 
$\cyl(u) = \set{u\beta : \beta\in Q^{\omega}}\subseteq Q^{\omega}$, a 
\emph{cylinder} as illustrated in Figure \ref{fig:cylinder}.
\begin{drawing}
  \caption{All infinite sequences of states $\set{q_{1},\dots, q_{k}}$ can be
  organised in a tree. In this tree the set $\cyl(u_{1}\dots u_{n})$ are all 
  possible prolongations of the initial sequence $u_{1}\dots u_{n}$ as 
  illustrated by the blue path and attached cylinder.}
  \label{fig:cylinder}
  \begin{center}
  % \resizebox{\textwidth}{!}{
    \includegraphics{tikz/cylinder.pdf}
  % }
  \end{center}
\end{drawing}
By using the transition probabilities of $\mathcal{P}$ we can formulate the 
probability to stay within a certain cylinder while reading a finite prefix of 
the input word. Let $v = u_{0}\dots u_{n}$ be such a finite prefix of $\alpha$.
First we observe, that all cylinders that are not rooted in $q_{0}$ can be 
discarded. For any sequence $q_{0}q_{1}\dots q_{n}$ the run of $\mathcal{P}$
on $\alpha$ stays within $\cyl(q_{0}q_{1}\dots q_{n})$ with the probability to
move along the path $q_{0}q_{1}\dots q_{n}$ while reading $u_{1}\dots u_{n}$.
This is the product of the probabilities to move from $q_{i-1}$ to $q_{i}$
while reading $u_{i}$ for $1\leq i\leq n$; thus 
$\prod_{1\leq i\leq n}\delta(q_{i-1},u_{i},q_{i})$. In order to associate with
the state sequences of $\mathcal{P}$ a probability space we rely on the 
$\sigma$-algebra which is created by including the sets $\cyl(w)$ for all 
$w\in Q^{*}$ and closing the set under negation and countably union. This is
\fxfatal{find reference for borel algebra}
commonly referred to as \emph{Borel}-algebra, cp. \cite{}, and formally 
defined as
\begin{definition}[Borel-algebra on words]
  For a finite set $A$ we call $\mathcal{B}(A)\subseteq\Pot(A^{\omega})$ the 
  smallest $\sigma$-algebra containing $\cyl(w)$ for all $w\in A^{*}$. We call
  a set $C\subset A^{\omega}$ \emph{Borel} if $C\in\mathcal{B}(A)$.
\end{definition}
Given an input word $\alpha$ and having fixed a $\sigma$-algebra, namely the
Borel-algebra over $Q$ which is induced by all cylinders, and the probability 
for staying in a cylinder for $\alpha$.
This allows with 
\cite[Theorem 5.6]{Bauer}\footnote{This theorem is called Carath\'{e}odory's
extension theorem, cp. \cite[Chapter 2.3.]{RandAutoInfTrees}.} to obtain a 
probability space
\begin{equation*}
  \tuple{Q^{\omega}, \mathcal{B}(Q), \mu_{\alpha}}.
\end{equation*}
Note that by \cite[Theorem 5.4]{Bauer} this $\mu_{\alpha}$ is unique.

Since we want to define the acceptance of an \ac{PBA} $\mathcal{P}$ of a word
$\alpha$ in terms of the induced probability of the set 
$\set{\alpha\in Q^{\omega}\mid\alpha\text{ satisfies the Büchi-condition }F}$,
it is necessary to show that this set is measureable, i.e. Borel. This is known
from e.g. \cite[Chapter 4.1.1.]{Groesser} but we present a proof here which
follows \cite[Proposition 6]{RandAutoInfTrees} since this argument can be
easily presented and is re-used later in a more involved context.
\begin{lemma}[Measurability]
  The set $\Acc(F)$ for a Büchi-condition $F\subseteq Q$ is measurable in 
  $\mathcal{B}(Q)$.
  \label{lem:measureabilityAcceptance}
\end{lemma}
\begin{proof}
  In order to show the measureability of $\Acc(F)$ we formulate it at as
  Boolean combination of cylinders inducing its membership in the 
  Borel-algebra by the closure properties of a $\sigma$-algebra.
  Initially, we start with a co-Büchi condition, i.e. those words which 
  eventually do not visit a target set $T$ anymore. More precisely, such a 
  set $T$ defines the accepted language as
  \begin{equation*}
    \Acc_{\cobuechi}(T) = \set{\alpha_{0}\alpha_{1}\dots\in Q^{\omega}\mid
    \text{ there is } i \text{ such that for all } j>i \text{ holds }
    \alpha_{j}\notin T}.
  \end{equation*}
  We claim that
  \begin{equation} 
    \Acc(T) = \bigcup\limits_{u\in Q^{*}}(
    \cyl(u)\setminus\bigcup\limits^{v_{0}\dots v_{n}\in\prolong(u)}_{v_{n}\in T}
    \cyl(v))
    \label{eq:measureability}
  \end{equation}
  which renders $\Acc(T)$ measurable as countable union of measurable sets.
  For $\beta\in\Acc(T)$ we know that there is eventually no occurence of $T$
  anymore. This induces that for every finite prefix $u\sqsubseteq\beta$ after 
  the last occurence of an element in $T$ holds
  $\beta\notin\bigcup\limits^{v_{0}\dots v_{n}\in\prolong(u)}_{v_{n}\in E}
  \cyl(v)$ and thus $\beta$ is element of the right hand side of Equation 
  \ref{eq:measureability}. On the other hand if $\beta\notin\Acc(T)$ we know 
  that for every finite prefix $u\sqsubseteq\beta$ there is a (finite) 
  prolongation $u\sqsubseteq v_{0}\dots v_{n}\sqsubseteq\beta$ such that 
  $v_{n}\in T$, hence $\beta$ is for every such $u$ removed by the cylinder 
  associated with $v_{0}\dots v_{n}$ since $v_{0}\dots v_{n}\in\prolong(u)$.
  This yields that $\beta$ is not element of the right hand side of Equation
  \ref{eq:measureability} which proves the announced equality. 
  For any Büchi-condition $F\subseteq Q$ we use its duality to the 
  co-Büchi-condition $T = Q\setminus F$, i.e.
  \begin{equation*}
    \Acc_{\buechi}(F) = Q^{\omega}\setminus\Acc_{\cobuechi}(T).
  \end{equation*}
  The measureability of $\Acc(F)$ follows by the closure of $\mathcal{B}(Q)$
  under complementation and the explored measureability of $\Acc(T)$.
\end{proof}
Since we explicitly defined \acp{PBA} with Büchi-conditions this suffices to
show their definition to be useful. But it is a natural escalation to consider
more elaborate acceptance conditions, e.g. Muller-, Parity- or 
Rabin-conditions. We show the measureability of those sets here as well, since
it is a easy consequence of Lemma \ref{lem:measureabilityAcceptance}. Also, we
note that we introduce, analogously as for $\omega$-regular word automata, 
corresponding acronyms. \acuse{PRA}\acuse{PMA}\acuse{PPA}
\begin{corollary}
  For a Muller-condition, a Parity-condition and a Rabin-condition
  defined by $\mathcal{F}\subseteq\Pot(Q)$, $\parity$, 
  $R = \set{\tuple{E_{0}, F_{0}},\dots,\tuple{E_{n}, F_{n}}}$ respectively, the 
  sets $\Acc(\mathcal{F})$, $\Acc(\parity)$ and $\Acc(R)$ are measureable in 
  $\mathcal{B}(Q)$.
  \ref{cor:borelAcceptance}
\end{corollary}
\begin{proof}
  Since the Rabin- and Parity-condition can be expressed by fitting 
  Muller-conditions it suffices to show the measureability of any 
  $\Acc(\mathcal{F})$ for a Muller-condition $\mathcal{F}\subseteq\Pot(Q)$.
  Fix one Muller-condition $\mathcal{F} = \set{F_{1},\dots,F_{n}}$. We claim
  that for one $F = \set{f_{1},\dots, f_{k}}\in\mathcal{F}$
  \begin{equation*}
    \Acc_{\muller}(\set{F}) = \tuple{
      \bigcap\limits_{1\leq i\leq k}\Acc_{\buechi}(\set{f_{i}})}\setminus
      \Acc_{\cobuechi}(Q\setminus F).
  \end{equation*}
  The individual Büchi-conditions on $f_{i}$ for $1\leq i\leq k$ ensure that 
  every of these states is visited infinitely often while the 
  co-Büchi-condition on all other states ensure that they are only visited
  finitely often rendering the $\Inf$-set to be $F$. By simply setting
  \begin{equation*}
    \Acc_{\muller}(\mathcal{F}) = \bigcup\limits_{F\in\mathcal{F}}(
    \Acc_{\muller}(\set{F}))
  \end{equation*}
  we obtain the measureability of $\Acc_{\muller}(\mathcal{F})$ by the closure
  properties of the $\sigma$-algebra $\mathcal{B}(Q)$.
\end{proof}

This finally allows us to define the semantics of a \ac{PBA} $\mathcal{P}$
formally with
\begin{definition}[Probabilistic Büchi Automaton - Acceptance]
  A \ac{PBA} $\mathcal{P} = \tuple{Q, \Sigma, \delta, q_{0}, F}$ positively 
  (resp. almost-surely) accepts a word $\alpha\in\Sigma^{\omega}$ if
  $\mu_{\alpha}(\Acc(F)) > 0$ (resp. $\mu_{\alpha}(\Acc(F))$).
\end{definition}
This yields two kinds of \acp{PBA} separated by the measure of their accepted 
runs. We want to provide a small discussion of the theory regarding \acp{PBA}.
Therefore we discuss an example of a \ac{PBA} from \cite{RecOmeLangProbAuto} 
which allows us to get a feel for the behavior while also providing a witness 
to separate the expressiveness of $\omega$-regular languages and languages 
positively accepted by \acp{PBA}.
\begin{drawing}
  \caption{A \ac{PBA} accepting under positive acceptance a 
  non-$\omega$-regular language depicted by the same notions as finite word 
  automata before.}
  \label{fig:posacceptingpba}
  \begin{center}
    \resizebox{0.35\textwidth}{!}{%
      \includegraphics{tikz/posacceptingpba.pdf}
    }
  \end{center}
\end{drawing}
\begin{example}
  We examine the \ac{PBA} $\mathcal{P}$ as defined in Figure 
  \ref{fig:posacceptingpba}. The accepted language is by 
  \cite{RecOmeLangProbAuto}
  \begin{equation*}
    \mathcal{L}_{>0} = \set{a^{k_{1}}ba^{k_{2}}b\dots:k_{i}>0\text{ for all }
    i>0\text{ and } \prod_{i>0}(1-\tuple{\frac{1}{2}}^{k_{i}}) > 0}.
  \end{equation*}
  This can be explained the following way: intially $\mathcal{P}$ starts in 
  $q_{0}$, thus the whole \emph{probability mass} lays within $q_{0}$. Every
  read $a$ dissipates half of the mass in $q_{0}$ to $q_{1}$ while the mass in
  $q_{1}$ stays in $q_{1}$. Every read $b$ discards all mass in $q_{0}$ while
  moving all mass in $q_{1}$ to $q_{0}$. Thus, reading $a$ gradually saves away
  probability mass into $q_{1}$ and $b$ restarts this process. Note that any 
  word ending in $a^{\omega}$ is not accepted since an infinite dissipatation 
  leaves no mass in $q_{0}$ behind but only the mass visiting $q_{0}$ 
  infinitely often is considered accepting. Thus, we need to have some 
  probability mass which moves infinitely often through the dissipatation step 
  but gradually, due to the loss of mass, steps need to \enquote{save} more 
  mass in order to not let it diminish too fast.
  \label{ex:posacceptingpba}
\end{example}
As mentioned before the \ac{PBA} $\mathcal{P}$ from Example 
\ref{ex:posacceptingpba} is not $\omega$-regular giving
\begin{lemma}
  Follows from the proof of \cite[Theorem 4]{RecOmeLangProbAuto}.
  The language
  \begin{equation*}
    \set{a^{k_{1}}ba^{k_{2}}b\dots:k_{i}>0\text{ for all }i>0\text{ and }
    \prod_{i>0}(1-\tuple{\frac{1}{2}}^{k_{i}}) > 0}
  \end{equation*}
  can be positively accepted by a \ac{PBA} but is not $\omega$-regular.
  \label{lem:posaccpba>omegareg}
\end{lemma}
\begin{proof}
  It is well known that any $\omega$-regular language contains an ultimately
  periodic word, i.e. a word of the form $u\cdot (v)^{\omega}$ where 
  $\epsilon\neq v$. We argue that no ultimately periodic word is part of the
  language. Since any word ending in $a^{\omega}$ is not part of the language
  (as argued in Example \ref{ex:posacceptingpba}) any ultimatively periodic
  word that might be part of the language contains at least one $b$ in its
  period $v$. But this induces that the sequences of $a$ are bound by a natural
  number $k_{0}$ yielding that for this word
  \begin{equation*}
    \prod_{i>0}(1-\tuple{\frac{1}{2}}^{k_{i}}) \leq
    \underbrace{\prod_{i>0}(1-\tuple{\frac{1}{2}}^{k_{0}})}_{
      \text{infinite product of a constant }c<0} = 0
  \end{equation*}
  rendering it not accepted.
\end{proof}
Furthermore, we state here without proof
\begin{lemma}
  \cite[Lemma 5]{RecOmeLangProbAuto} For any \ac{NBA} $\mathcal{A}$ exists a
  \ac{PBA} $\mathcal{P}$ which accepts the same language.
\end{lemma}
Which combined yields
\begin{theorem}
  \cite[Theorem 4]{RecOmeLangProbAuto}
  The class of languages that can be accepted by a \ac{PBA} strictly contains
  the class of $\omega$-regular languages.
\end{theorem}
Additionally, we know that the class of languages that are positively accepted 
by a \ac{PBA} forms a Boolean algebra. This is captured in
\begin{theorem}
  \cite[Chapter 4.3.]{Groesser}
  The class of languages that can be accepted by a \ac{PBA} form a Boolean 
  algebra. The transformations can be effectively constructed.
  \label{thm:pbaboolalgebra}
\end{theorem}
\begin{proof}[Proof-sketch]
  A union operator is very easily obtained by the following idea: given two
  \acp{PBA} $\mathcal{P}_{1},\mathcal{P}_{2}$ with initial states $q^{1}_{0},
  q^{2}_{0}$ respectively, then we can construct a \ac{PBA} $\mathcal{P}$ which
  effectively uses a initial distribution 
  $\iota:Q^{1}\cup Q^{2}\rightarrow\interval{0,1}$ such that 
  $\iota(q^{1}_{0}) = \iota(q^{2}_{0}) = \frac{1}{2}$ while $\iota(p) = 0$ for
  any other state $p$. By introducing a new initial state $q_{0}$ and 
  \enquote{skipping over} $q^{1}_{0},q^{2}_{0}$ in the first step, i.e.
  setting
  \begin{equation*}
    \delta(q_{0},\sigma, p) = \frac{1}{2}\cdot\delta^{i}(q^{i}_{0},\sigma, p)
    \text{ with }
    i = \begin{cases}
      1&\text{if }p\in Q^{1},\\
      2&\text{if }p\in Q^{2}
    \end{cases}
  \end{equation*}
  we can emulate such an initial distribution $\iota$. This yields that the 
  resulting $\mathcal{P}$ accepts $\alpha$ with a probability
  $\frac{1}{2}\cdot\mu^{1}_{\alpha}(\Acc(F^{1})) + 
  \frac{1}{2}\cdot\mu^{2}_{\alpha}(\Acc(F^{2}))$ which is greater than $0$ if
  and only if one of the probabilities is greater than $0$.

  Complementation requires a rather involved operation which we do not present 
  here; but we mention an intermediate construction, namely a \ac{PRA} 
  $\mathcal{R}$ associated with a \ac{PBA} $\mathcal{P}$. The 
  interesting aspect of $\mathcal{R}$ is that it induces a binary probability 
  measure on its acceptance condition, i.e. for its Rabin-condition $R$ we have
  $\mu_{\alpha}(\Acc(R))\in\set{0,1}$, but it accepts the same language as
  $\mathcal{P}$. The main idea of its construction is to sample partial runs of 
  the original \ac{PBA} and keeping track of those that are accepting. These 
  partial runs can be then \enquote{sticked together}\footnote{The idea of 
  sticking partial runs together is conceptually similar to the proof of 
  Theorem \ref{thm:omegaregularexp}.}. Therefore we state here
  \begin{theorem}
    \cite[Theorem 4.3.2]{Groesser}
    For each \ac{PBA} $\mathcal{P}$ there exists a \ac{PRA} $\mathcal{R}$ that 
    accepts the same language, but for every word the acceptance measure for
    $\mathcal{R}$ is either $0$ or $1$.
    \label{thm:pbatopra}
  \end{theorem}
  Since we soon see that \acp{PBA} with almost-sure acceptance are strictly
  less expressive than \acp{PBA} with positive acceptance we note the 
  correspondance to Theorem \ref{thm:omegaregularexp} in the
  sense that more expressive acceptance conditions allow for a 
  \enquote{stuctural} difference, which in this case is the acceptance measure
  (rather than determinsm before). Also, we note that all \enquote{strong} 
  conditions again coincide but we postpone the proof since it is a corollary 
  from a later result\footnote{
    Nevertheless, it makes use of the same concept, namely \acp{LAR}.
  }.
  \begin{theorem}
    The expressiveness for \ac{PRA}, \ac{PMA} and \ac{PPA} coincides under
    positive as well as almost-sure acceptance.
    \label{thm:probautoequiv}
  \end{theorem}
\end{proof}
The gain in expressiveness for \ac{PBA} with positive acceptance over 
$\omega$-regular languages is unfortunately accompanied by some undesired 
effects. Notably, while emptiness for a \ac{NBA} can be decided by means of 
graph algorithms we have that given a \ac{PBA} $\mathcal{P}$ it is undecideable 
to find if there is any word positively accepted by $\mathcal{P}$ as stated in
\begin{theorem}
  \cite[Theorem 2]{DecProblemsForProbAuto}
  The emptiness problem for \ac{PBA} is undecideable.
  \label{thm:emptinesspospba}
\end{theorem}

In order to re-gain some desired algorithmic properties of e.g. the emptiness
problem \cite{DecProblemsForProbAuto} considers almost-sure acceptance. By
Theorem \ref{thm:pbatopra} we conclude easily that the emptiness problem for
almost-sure accepting \ac{PRA} (and by Theorem \ref{thm:probautoequiv} also for
\ac{PPA} and \ac{PMA}) is undecideable. But for Büchi-conditions this is not
the case as stated in
\begin{theorem}
  \cite[Theorem 6]{DecProblemsForProbAuto}
  The emptiness problem for \ac{PBA} with almost-sure acceptance is decideable.
  \label{thm:emptinessalmostsurepba}
\end{theorem}
Again, we consider an example for a \ac{PBA} with almost-sure acceptance (taken
from \cite{DecProblemsForProbAuto}.
\begin{example}
  Let $\mathcal{P}$ be a \ac{PBA} as defined in Figure 
  \ref{fig:almostsureacceptingpba}. The language accepted by $\mathcal{P}$ is
  \begin{equation*}
    L_{\lambda} = \set{a^{k_{1}}ba^{k_{2}}b\dots\mid k_{i}>0\text{ for }i>0
    \text{ and }\prod\limits_{i>0}\tuple{1-\lambda^{k_{i}}} = 0}.
  \end{equation*}
  Every $a$-sequence $w\in\set{a}^{*}$ models an experiment which determines 
  how probable it is to stay in $q_{2}$, namely $\lambda^{\size{w}}$. Every 
  experiment is concluded with the occurence of a single $b$.  Naturally, the 
  probability to \enquote{fail} such an experiment is $1-\lambda^{\size{w}}$. 
  Due to the equivalent behaviour of $q_{3}$ and $q_{0}$ all these experiments 
  are independent and therefore, consistenly failing these experiments with 
  $a$-sequences of length $k_{1}, k_{2},\dots$ starting from the $m$-th 
  experiment happens with probability
  \begin{equation*}
    p_{m} = \prod\limits_{i>m}(1-\lambda^{k_{i}})
    \text{ and thus }
    \prod\limits_{i>0}(1-\lambda^{k_{i}}) = 
    \underbrace{\prod\limits_{m\geq i>0}(1-\lambda^{k_{i}})}_{=c_{m}}
    \cdot p_{m}.
  \end{equation*}
  $c_{m} > 0$ implies $c_{m}\cdot p_{m} = 0$ if and only if 
  $p_{m} = 0$.
  Every non-accepting run $\pi$ consistently fails from one experiment onwards.
  This allows to conclude with asymptotic equvialence of $p_{m}$ and 
  $c_{m}\cdot p_{m}$ and $\sigma$-additivity of a probability measure that the 
  probability of non-accepting runs is
  \begin{equation*}
    \sum_{i > 0} p_{m}\text{, and therefore }
    \sum_{i > 0} p_{m} = 0\text{ iff }\prod\limits_{i>0}(1-\lambda^{k_{i}}) =0.
  \end{equation*}
  In order to accept almost-surely the set of non-accepting runs needs to be
  \emph{negligible}, i.e. carrying a probability of $0$.  Thus, indeed 
  $\mathcal{P}$ accepts $L_{\lambda}$.

  If $\lambda$ is set to $\frac{1}{2}$, the resulting language 
  $\mathcal{L}_{=1}$ is - to a certain degree - dual to the language in Example 
  \ref{ex:posacceptingpba} (without considering all words ending in 
  $a^{\omega}$ or those words starting in $b$ or ommitting an 
  \enquote{$a$-phase}). This duality is rooted in structural similarities. 
  Examining the \emph{Separation} part, it mirrors the $a$-transitions of the 
  \ac{PBA} in Figure \ref{fig:posacceptingpba}. But an occurences of $b$ does 
  not discard the probability mass in $q_{2}$ ($q_0$, respectively) but saves
  it in an accepting state and re-introduces into the circulation (as seen in 
  the \emph{Disposal} part).
  \label{ex:almostsureacceptingpba}
\end{example}
\begin{drawing}
  \caption{A \ac{PBA} which accepts a non-$\omega$-regular language under
  almost-sure acceptance. We conceptually separate it into two regions, namely
  the \enquote{Separation-} and \enquote{Disposal-}region (marked by the green
  or red box respectively).}
  \label{fig:almostsureacceptingpba}
  \begin{center}
    \resizebox{0.4\textwidth}{!}{%
      \includegraphics{tikz/almostsureacceptingpba.pdf}
    }
  \end{center}
\end{drawing}
Considering Example \ref{ex:almostsureacceptingpba} it is a natural question if
the choice of $\lambda$ matters. Quoting the following
\begin{lemma}
  \cite[Lemma 1]{DecProblemsForProbAuto}
  For each $n\in\mathbb{N}_{>1}$ there exists a sequence $\tuple{k_{i}}_{i>0}$
  such that
  \begin{equation*}
    \prod_{i>0}(1-\lambda^{k_{i}}) > 0 \text{ if and only if }
    \lambda<\frac{1}{n},
  \end{equation*}
  \label{lem:measureinpba}
\end{lemma}
allows us to answer this question positively. Choosing $\lambda_{1}$ and
$\lambda_{2}$ differently, we can find $n$ such that 
$\lambda_{1} < \frac{1}{n} < \lambda_{2}$ and then the languages of 
$\mathcal{P}$ with $\lambda_{1}$ and $\lambda_{2}$ do not agree on the sequence
given by Lemma \ref{lem:measureinpba} for $n$ since $\lambda_{1}$ renders
this sequence non-accepting in $\mathcal{P}$ while $\lambda_{2}$ renders it
accepting (as described in \cite{DecProblemsForProbAuto}).

Regarding the relationship of $\omega$-regularity to languages which are 
accepted by a \ac{PBA} with almost-sure acceptance we find that
\begin{theorem}
  \cite[Theorem 4, (b), (c)]{DecProblemsForProbAuto}
  The classes of $\omega$-regular languages and languages accepted by a 
  \ac{PBA} with almost-sure acceptance are incomparable.
\end{theorem}
\begin{proof}
  The proof separates in both directions of possible inclusions. As noted in
  Figure \ref{fig:almostsureacceptingpba} the defined \ac{PBA} $\mathcal{P}$
  with almost-surely accepts a non-$\omega$-regular language, hence
  \begin{lemma}
    There is a non-$\omega$-regular language that is accepted by any \ac{PBA} 
    with almost-sure acceptance.
  \end{lemma}
  \begin{proof}
    As expected, we use the language $\mathcal{L}_{=1}$ from Example 
    \ref{ex:almostsureacceptingpba} to witness this claim. In Example 
    \ref{ex:almostsureacceptingpba} we already mentioned the 
    \enquote{almost duality} of this language to $\mathcal{L}_{>0}$ from 
    Example \ref{ex:posacceptingpba}. By defining
    \begin{equation*}
      \mathcal{L}_{\omega} = \set{
        \alpha_{1}\alpha_{2}\dots\in\set{a,b}^{\omega}\middle|
        \text{s.t. }
        \begin{aligned}
          &\alpha_{1} = b&\text{or }\\
          &\alpha_{i} = \alpha_{i+1} = b&\text{for one }i>0\text{ or }\\
          &\alpha_{i} = \alpha_{i+1} = \dots = b&\text{for one }i>0\text{ holds}
        \end{aligned}
      },
    \end{equation*}
    we can state that 
    $\set{a,b}^{\omega}\setminus\mathcal{L}_{>0} = 
      \mathcal{L}_{=1}\cup\mathcal{L}_{\omega}$.
    $\mathcal{L}_{\omega}$ can be separated into its individual parts where 
    each part is $\omega$-regular and so is $\mathcal{L}_{\omega}$ by closure 
    under union for $\omega$-regular languages. Thus, assuming 
    $\mathcal{L}_{=1}$ $\omega$-regularity renders 
    $\mathcal{L}_{=1}\cup\mathcal{L}_{\omega}$ $\omega$-regular and by closure 
    under complement of $\omega$-regular languages also $\mathcal{L}_{>0}$ 
    which is a contradiction to Lemma \ref{lem:posaccpba>omegareg}. Therefore, 
    we state that $\mathcal{L}_{=1}$ is not $\omega$-regular.
  \end{proof}
  And on the other hand we state that
  \begin{lemma}
    There is a $\omega$-regular language that cannot be accepted by any 
    \ac{PBA} with almost-sure acceptance.
  \end{lemma}
  \begin{proof}
    We examine the $\omega$-regular language $\mathcal{L}$ over the alphabet
    $\set{a,b}$ of those words that contain only finitely many $a$ (cp. Example
    \ref{ex:fina}).
    \fxfatal{to be finished}
  \end{proof}
\end{proof}

\section{Markov Decision Processes}
In the following we introduce \acp{MDP}, a model of interaction between a 
probabilistic domain and an actor within this domain. The actions of the actor
impact the behavior of the domain and depending on the behavior of the domain
the actor may adapt her behavior. It shares significant structural similarities
to \acp{PBA} but allows for a rather different interpretation. Nevertheless, we
reuse various concepts from \acp{PBA} to define \acp{MDP}. The following 
definitions follow \cite{RandAutoInfTrees}:
\begin{definition}[Markov Decision Process]
  A \acl*{MDP} is modelled as tuple
  $\tuple{S, A, \tuple{\tau_{a}}_{a\in A}, s_{0}}$ where $S$ is a set of states
  and $A$ a set of actions. Given an action $a\in A$ the corresponding
  transition function $\tau_{a}:S\times S\rightarrow \interval{0,1}$ satisfies
  for every $q\in S$ that $\sum_{p\in S}\tau_{a}\tuple{q,p} = 1$.
  $s_{0}$ is the initial state. Additionally we define a few helpful
  auxilliaries:
  \begin{description}
    \item [Plays] We consider all infinite sequences of states
      (i.e. $S^{\omega}$) that start in $s_{0}$ a valid play. All plays
      are gathered in $\plays = \set{
        \alpha\in S^{\omega}\mid \alpha_{0} = s_{0}} = \cyl(s_{0})$.
    \item [Strategy] We define $\varphi:S^{+}\rightarrow A$ as strategy for
      a \ac{MDP}. Such a strategy models interaction with a \ac{MDP} by
      giving a specific $a\in A$ to which the \ac{MDP} reacts by $\tau_{a}$.
    \item [Initial Distribution] Occasionally, we substitute the initial state
      $s_{0}$ with an initial probability distribution
      $\iota_{0}:S\rightarrow[0,1]$ which allows the plays to start in any
      $s\in S$ such that $\iota_{0}(s) > 0$.
  \end{description}
  \label{def:mdp}
\end{definition}
A strategy $\varphi$ for an \ac{MDP}
$\mathcal{M} = \tuple{S, A, \tuple{\tau_{a}}_{a\in A}, s_{0}}$ induces a 
probability measure $\mu_{\varphi}$ on the Borel-algebra $\mathcal{B}(S)$. 
\acp{PBA} can be interpreted as \acp{MDP} where the decisions in every state
are induced by a word $\alpha = \alpha_{1}\alpha_{2}\dots\in\Sigma^{\omega}$
rather than a player. Any \ac{PBA} $\mathcal{P}$ can be interpreted as \ac{MDP}
and for any $\alpha$ a corresponding strategy 
$\varphi_{\alpha}:Q^{+}\rightarrow\Sigma$ with 
$\varphi_{\alpha}(w) = \alpha_{\size{w}}$ can be defined. On the other hand, do
strategies for \acp{MDP} allow for an interaction between the player and the
environment, thus the player might react differently considering which state
she stays in, e.g.
\begin{example}
  We interpret the \ac{PBA} pictured in Figure \ref{fig:posacceptingpba} as
  \ac{MDP} $\mathcal{M}$. Furthermore, we challenge the player with the task to
  visit states in $F$ infinitely often. The player trivially has a strategy 
  that allows him to satisfy this task by
  \begin{equation*}
    \varphi(p_{1}\dots p_{n}) = \begin{cases}
      b&\text{if }p_{n} = q_{1},\\
      a&\text{if }p_{n} = q_{0}.
    \end{cases}
  \end{equation*}
  The player is not restricted as words are to be \enquote{consistent} 
  regarding the length of the play. A word has exactly one letter at each 
  position while a player may provide different actions (or letters) after
  the same length of the play depending on the state she currently resides in
  (or even the current history of the play).
  \label{ex:pbaasmdp}
\end{example}
This freedom of the player can be restricted again. Therefore, we define in the
following \acp{POMDP}. A \ac{POMDP} is a \ac{MDP} $\mathcal{M}$ with an 
associated equivalence relation $\sim$. The equivalence relation models a 
restriction of the player to observe the state of $\mathcal{M}$. For every
$s\in S_{\mathcal{M}}$ we define
$[s]_{\sim} = \set{r\in S\mid \sim(r,s)}$ and
$S_{\mathcal{M}}/_{\sim}$ as set of all these equivalence classes. A
strategy for a \ac{POMDP} $\tuple{\mathcal{M}, \sim}$ is defined as
$\varphi:(S_{\mathcal{M}}/_{\sim})^{+}\rightarrow A_{\mathcal{M}}$.
\begin{example}
  Again, consider a \ac{PBA} $\mathcal{P}$ and interpret it as an \ac{MDP}
  $\mathcal{M}$ we observed that every word $\alpha$ induces a corresponding
  strategy $\varphi_{\alpha}$. But not every strategy induces a word because
  strategies on $\mathcal{M}$ may choose depending on the state of the play
  different letters for plays of the same length which creates an inconsistency
  with respect to an - hypothetical - associated word (cp. Example 
  \ref{ex:pbaasmdp}). We add to $\mathcal{M}$ an equivalence relation
  $\sim = S_{\mathcal{M}} \times S_{\mathcal{M}}$ (as suggested in
  \cite{DecProblemsForProbAuto}), hence there is exactly one equivalence class.
  Firstly, we observe that $\varphi_{\alpha}$ is still a valid strategy for the
  resulting \ac{POMDP} $\mathcal{N} = \tuple{\mathcal{M}, \sim}$. Secondly,
  since there is exactly one equivalence class every strategy for $\mathcal{N}$
  observes at any time only the length of the history. Hence we can provide an
  equivalent strategy of the form $\varphi:\mathbb{N}\rightarrow \Sigma$. This
  in turn means that every strategy in $\mathcal{N}$ induces a word in
  $\Sigma^{\omega}$ of the form $\varphi(0)\varphi(1)\dots$. Furthermore, the
  measure of one strategy and an associated word coincide, i.e. the language of
  $\mathcal{P}$ can be understood as strategy space for $\mathcal{N}$ and vice
  versa. This illustrates an idea which is used to define emptiness games for
  certain automata (e.g. \cite[Proposition 45]{RandAutoInfTrees}).
  \label{ex:pbaaspomdp}
\end{example}
The definitions of \acp{MDP} and \acp{POMDP} are for now probabilistic 
transition systems and strategies induce a behavior of such a transition 
system. To model goals or task for the player to satisfy we again use 
Büchi-, Rabin-, Parity- and Muller-conditions. We can then ask if a player has
a strategy to positively or almost-surely satisfy the associated condition in
an \ac{MDP} or \ac{POMDP}. The equality described in Example 
\ref{ex:pbaaspomdp} directly induces some undecideability results, namely
\begin{theorem}
  \cite[Corollary 3 (a)]{DecProblemsForProbAuto}
  \cite[Theorem 5]{QualAnaPOMDP}
  It is undecideable to compute a strategy for a \ac{POMDP} that either 
  positively or almost-surely satisfies a Rabin-, Parity- or Muller-condition.
  Additionally, it is undecideable to compute a strategy for a \ac{POMDP} that
  positively satisfies a Büchi-condition.
\end{theorem}
\begin{proof}
  Any algorithm to compute a strategy for a \ac{POMDP} that positively 
  satisfies a Büchi-condition immediately solves the emptiness problem for
  \acp{PBA} with positive acceptance which is undecideable by Theorem 
  \ref{thm:emptinesspospba}. Furthermore, it is easy to express 
  Büchi-conditions as Parity-, Rabin- or Muller-conditions, rendering the 
  positive acceptance of these conditions in \ac{POMDP} at least as difficult
  as for Büchi-conditions. 
  
  By Theorem \ref{thm:pbatopra} and Theorem \ref{thm:probautoequiv} there is 
  for any \ac{PBA} an equivalent \ac{PRA}, \ac{PPA} and \ac{PMA} which 
  almost-surely accepts the same language. Hence again computing a strategy for 
  the almost-sure satisfaction of Rabin-, Parity- or Muller-conditions for 
  \acp{POMDP} solves the undecideable emptiness problem for \acp{PBA} with 
  positive acceptance.
\end{proof}
On the other hand, there are some positive results regarding computation of 
strategies for \acp{MDP} and for almost-sure satisfaction of Büchi-conditions
in \acp{POMDP}:
\begin{theorem}
  \cite[Theorem 5]{QualAnaPOMDP}
  It is possible to compute a strategy for a \ac{POMDP} that almost-surely 
  satisfies an associated Büchi-condition.
\end{theorem}
and
\fxfatal{find nice way to extend this to Rabin and Muller conditions}
\begin{theorem}
  \cite[Theorem 4.1.7.]{QuanStochParityGames}
  It is possible to compute a strategy for a \ac{MDP} that almost-surely
  satisfies an associated Büchi- or Parity-condition.
\end{theorem} 
Additionally to the close connection of \acp{POMDP} to probabilistic word 
automata we make use of these models in the later course to define decision
procedures for even more elaborate probabilistic automata.

\section{Tree Automata}
In Section \ref{sec:wordautomata} it is noted that word automata attach to a
word a sequence of states. The idea of classic tree automata is to attach
states to more complex structures, namely trees. For a finite set of
directions $D$ and a finite alphabet $\Sigma$ we define a $D$-ary $\Sigma$-tree
$t:D^{*}\rightarrow\Sigma$. A tree automaton produces a tree of states
which is attached to the input tree, hence a $D$-ary $Q$-tree where $Q$ is the
set of states. The following introduction conceptually follows 
\cite[Chapter 8]{AutoLogInfGames}
\begin{definition}[Tree automaton]
  Let $Q$ be a finite set of states and $q_{0}\in Q$ be one initial state.
  Furthermore, let $\Delta$ denote a set of transitions of the form
  $\tuple{q,\sigma, \tuple{q_{d}}_{d\in D}}$ where $q\in Q, q_{d}\in Q$ for
  all $d\in D$ and $\sigma\in\Sigma$. Thus, define a tree automaton
  \begin{equation*}
    \mathcal{A} = \tuple{Q, q_{0}, D, \Sigma, \Delta, \Acc\subseteq Q^{\omega}}.
  \end{equation*}
  And its semantics with the following auxillary notions
  \begin{description}
    \item[Run] a run of $\mathcal{A}$ on a $D$-ary $\Sigma$-tree $t$ is a
      $D$-ary $Q$-tree $r$ such that $r(\epsilon) = q_{0}$ and for every 
      $u\in D^{*}$ there is one 
      $\tuple{q,\sigma, \tuple{q_{d}}_{d\in D}}\in\Delta$ with $r(ud) = q_{d}$,
    \item[Acceptance Condition] the acceptance condition $\Acc$ is considered
      to be represented as Büchi-, Parity-, Muller- or Rabin-condition,
    \item[Projection of a tree] for any $\alpha=\alpha_{1}\alpha_{2}\dots\in
      D^{\omega}$ and any $D$-ary $\Sigma$-tree $t$ let $t(\alpha)$ denote the 
      word $\beta = \beta_{0}\beta_{1}\dots\in\Sigma^{\omega}$ such that for 
      every $i\in\mathbb{N}_{>0}$ holds 
      $\beta_{i} = t(\alpha_{1}\dots\alpha_{i})$ and $\beta_{0} = t(\epsilon)$.
  \end{description}
  $\mathcal{A}$ accepts a tree $t$ if there exists a run $r$ of $\mathcal{A}$
  on $t$ such that for every $\alpha\in D^{\omega}$ $r(\alpha)\in\Acc$.
\end{definition}
We introduce as we are already accustomed fitting acronyms, e.g.
\acuse{PTA}  \acuse{RTA}  \acuse{MTA} \acuse{BTA}, and present an easy example 
to familiarize ourself with the notions of tree automata
\begin{example}
  Consider $\mathcal{L}_{\exists a}$ as the language of those binary trees over 
  the $\set{a,b}$ that contain at least one $a$. This language can be accepted 
  by a tree automaton by non-deterministically choosing a path to an occurence 
  of an $a$ and rendering every other path accepted. And the chosen path 
  accepted from the point onwards where an $a$ occured. The corresponding tree 
  automaton can be described by two states $q_{s}, q_{a}$, where $q_{s}$ is a 
  state that searches for an $a$ while $q_{a}$ is a state that renders all its 
  subtrees accepting. $q_{a}$ reproduces itself into all its subtrees, while 
  $q_{s}$ reproduces itself only in one of its subtrees and 
  \enquote{dismissing} the other one by sending $q_{a}$ in it. The acceptance 
  condition is described as a Büchi condition by the set $F = \set{q_{a}}$, 
  thus, since $q_{a}$ only produces $q_{a}$ in all following subtrees, it can 
  be also understood as a reachability condition. This yields the tree 
  automaton
  \begin{equation*}
    \mathcal{A}_{\exists a} = \tuple{Q = \set{q_{s}, q_{a}}, q_{s},
    \Delta ,F = \set{q_{a}}}
  \end{equation*}
  with
  \begin{equation*}
    \Delta = \set{\tuple{q_{a}, a, q_{a}, q_{a}},\tuple{q_{a}, b, q_{a}, q_{a}},
      \tuple{q_{s}, b, q_{s}, q_{a}}, \tuple{q_{s}, b, q_{a}, q_{s}},
      \tuple{q_{s}, a, q_{a}, q_{a}}}.
  \end{equation*}
  For all trees in $\mathcal{L}_{\exists a}$ the automaton
  $\mathcal{A}_{\exists a}$ can produce an accepting run by \enquote{guessing}
  a path to the occurence of $a$ while every tree accepted by
  $\mathcal{A}_{\exists a}$ does need to contain an $a$ since otherwise $q_{s}$
  is never transformed into $q_{a}$ which yields one non-accepting path in any
  run. Enforcing, that $q_{s}$ always reproduces into both subtrees yields an
  automaton which recognizes the language of those trees which do have an $a$
  on every branch. We denote this language as $\mathcal{L}_{\forall a}$.
  \label{ex:treeexa}
\end{example}
It is noteworthy that $\mathcal{A}_{\exists a}$ uses a very simple acceptance
condition, namely a reachability condition which is emulated by a Büchi
condition. The following example on the other hand uses a more elaborate
acceptance condition:
\begin{example}
  This example is similiar to e.g.
  \cite[Exercise 8.3 and the proof of Theorem 8.6]{AutoLogInfGames}.
  Let $\mathcal{L}_{\not\infty a}$ be the language of all binary trees over the
  set $\set{a,b}$ that contain on every path only finitely many $a$. Note the
  similarity to Example \ref{ex:fina} for word automata. This
  language can be recognized by tree automata with a very easy structure,
  namely there are two states $q_{a}, q_{b}$ which only are visited if the
  corresponding letter is read. Thus, we define
  \begin{equation*}
    \Delta = \set{
      \tuple{q_{a}, a, q_{a}, q_{a}},
      \tuple{q_{b}, a, q_{a}, q_{a}},
      \tuple{q_{a}, b, q_{b}, q_{b}},
      \tuple{q_{b}, b, q_{b}, q_{b}}
    }.
  \end{equation*}
  Any Rabin-, Muller- or Parity-condition as described in Example \ref{ex:fina}
  accepts the correct language since these precisely define the abscence of
  infinitely many occurences of $q_{a}$.

  For the corresponding \ac{NBA} in Example \ref{ex:fina} we used a structural
  way to model the abscence of further occurences of $a$ from one point 
  onwards.  This argument of guessing the moment when no further $a$ appears 
  cannot be used in the case of trees since every such guess involves the 
  complete subtree. Considering the tree $t:\set{0,1}*\rightarrow\set{a,b}$ 
  with $t(w) = a$ if and only if $w = 1^{n}0$ for any $n\in\mathbb{N}_{>0}$ we 
  see that $t\in\mathcal{L}_{\not\infty a}$, but for all $k\in\mathbb{N}_{>0}$ 
  the subtree rooted in $1^{k}$ contains an $a$. Thus, there is no point from
  which this subtree is $a$-free, therefore this idea of guessing such a point 
  does not translate to tree automata.
\end{example}
The difficulties to define a \ac{BTA} to accept $\mathcal{L}_{\not\infty a}$ 
are inherent to the Büchi-condition. In fact it is possible to show that 
$\mathcal{L}_{\not\infty a}$ cannot be accepted by any \ac{BTA}, thus 
separating the expressiveness of tree automata as in
\begin{theorem}
  \cite[Corollary 8]{WeakDefRel} cited after
  \cite[Theorem 8.6]{AutoLogInfGames}.
  \acp{BTA} are strictly weaker than \ac{MTA} in the sense that there exists 
  a language recognizable by a \ac{MTA} but not recognizable by a \ac{BTA}.
\end{theorem}
This is in contrast to Theorem \ref{thm:omegaregularexp} where we could use the
non-determinism of an \ac{NBA} to emulate a more expressive acceptance 
condition, e.g. a Muller-condition. But by the same techniques as for the proof 
of Theorem \ref{thm:omegaregularexp} for the equivalence of the 
\enquote{strong} acceptance conditions, namely \acp{LAR}, we can ensure
\begin{theorem}
  \cite[Theorem 8.7]{AutoLogInfGames}
  \acp{MTA}, \acp{RTA} and \acp{PTA} all recognize the same tree languages.
  \label{thm:treeautoequiv}
\end{theorem}
Regarding the closure properties of this class of tree languages it is again
possible to show its closure under union, intersection and negation. This gives
\begin{theorem}
  \cite[Theorem 1.3]{SOTheoAndTrees}
  \cite[Theorem 1.5]{SOTheoAndTrees}
  The class of languages that can be accepted by \acp{MTA}, \acp{RTA} and 
  \acp{PTA} forms a Boolean-algebra. The transformations can be effectively
  constructed.
  \label{thm:treeautoboolean}
\end{theorem}
We do not state the proof explicitly since the used concepts for union and
intersection are the same as for the proof Theorem \ref{thm:omegaregboolean},
namely we can obtain union by constructing an automaton that performs an 
initial \emph{guess} which input automata is simulated and an automaton for the
intersection simulates both input automata by a a product construction and uses 
a Muller-condition which formulates the acceptance of the individual components 
by their original acceptance conditions. In order to convey the closure under
negation we introduce further concepts regarding tree automata which allow to
present a proof in a natural way.

\subsection{Alternating Tree Automata}
Up to this point the used automata mirrored the structure of their inputs
very closely. Word automata generated words of states and tree automata 
generated trees of states of the same arity of their input trees. This notion 
can be relaxed for tree automata to obtain a new class of tree
automata, that is \emph{Alternating Tree Automata}. Following 
\cite{AltTreeAuto} tree automata operate by sending down \enquote{copies} 
through the different paths. In the classical setting at every branching point 
every successor is awarded with one copy of a state of the automaton. The 
aforementioned relaxation lies in the idea to allow at a branching point to 
award some successor with more than one state while others may not receive even 
a single one. This concept is also used to define automata that run over 
transition systems, e.g. \cite[Chapter 9]{AutoLogInfGames} and 
\cite{SynProbEnv}, where the input tree is the unrollment of the transition 
system.

Formally, before transitions for tree automata are defined as tuples of the 
form $\tuple{q, \sigma, \tuple{q_{d}}_{d\in D}}$. This specifically defines for
every direction one single state to move along this direction. We introduce
transitions of the form $\tuple{q,\sigma,\delta_{A}}$ where $\delta_{A}$ is a 
characteristic function of a non-empty subset $A\subseteq D\times Q$ called a
\emph{clause-function}, i.e.
\begin{equation*}
  \delta_{A}:D\times Q\rightarrow\set{0,1}\text{ with }
  \delta_{A}(a) = \begin{cases}
    1&\text{if }a\in A,\\
    0&\text{if }a\notin A.
  \end{cases}
\end{equation*}
Semantically, $\delta_{A}$ sends a copy of $q$ down the direction $d$ for every
$\tuple{d,q}\in A$. This notion allows us to refine the tree automaton of 
Example \ref{ex:treeexa}:
\begin{example}
  Recall $\mathcal{A}_{\exists a}$ from Example \ref{ex:treeexa} which
  determines if a tree contains an $a$ with 
  \begin{equation*}
    \Delta = \set{
      \tuple{q_{a}, a, q_{a}, q_{a}},
      \tuple{q_{a}, b, q_{a}, q_{a}},
      \tuple{q_{s}, a, q_{a}, q_{a}},
      \tuple{q_{s}, b, q_{s}, q_{a}},
      \tuple{q_{s}, b, q_{a}, q_{s}}
    }.
  \end{equation*}
  The concept of alternating tree automata allows to formulate the
  \enquote{searching} part of the run more concisely\footnote{
    Occasionally, e.g. in \cite[Chapter 9]{AutoLogInfGames}, alternating tree
    automata are equipped with the possibility to render a subtree accepted 
    regardless of its structure. We explicitly do not include this notion, but 
    it is easy to see that this would allow to equivalently define transitions
    $\tuple{q_{a}, a, \delta_{\top}},\tuple{q_{a}, b, \delta_{\top}},
    \tuple{q_{s}, a, \delta_{\top}}$ where $\delta_{\top}$ renders the subtree
    accepted.
  }
  by dropping the necessity to send a $q_{a}$ along the
  path that is not chosen, thus including
  \begin{equation*}
    \tuple{q_{s}, b, \delta_{\set{\tuple{0, q_{s}}}}},
    \tuple{q_{s}, b, \delta_{\set{\tuple{1, q_{s}}}}}.
  \end{equation*}
\end{example}
We formally define similar to \cite{SynProbEnv}
\begin{definition}[Alternating Tree Automata]
  For a finite set of states $Q$, one distinct intial state $q_{0}\in Q$, a
  finite set of directions $D$, a finite alphabet $\Sigma$ and a transition
  relation $\Delta$ we define 
  \begin{equation*}
    \mathcal{A} = \tuple{Q, q_{0}, D, \Sigma, \Delta, \Acc\subseteq Q^{\omega}}.
  \end{equation*}
  The semantics of $\mathcal{A}$ is given by a run $r$ of $\mathcal{A}$ on a
  $D$-ary $\Sigma$-tree $t$. Here $r$ is a $D\times Q$-ary $\nabla$-tree where 
  $\nabla$ is the set of all clause-functions occuring in $\Delta$ with the 
  following necessities:
  \begin{enumerate}
    \item $r(\epsilon) = \delta_{A}$ for 
      $\tuple{q_{0}, t(\epsilon), \delta_{A}}\in\Delta$,
    \item for every $u = \tuple{d_{1}, q_{1}}\dots\tuple{d_{n}, q_{n}}\in
      \tuple{D\times Q}^{*}$ with $r(u) = \delta_{A}$ there exists
      $\tuple{q_{n}, t(d_{1}\dots d_{n}), \delta_{A}}\in\Delta$.
  \end{enumerate}
  We consider such a run $r$ accepting if all paths that move along 
  clause-functions are part of $\Acc$. Formally, we fix for any run $r$ the set 
  of its \enquote{marked path} as
  \begin{equation*}
  M_{r} = \set{
    \tuple{d_{1}, q_{1}}\tuple{d_{2}, q_{2}}\dots\in
    \tuple{D\times Q}^{\omega}\middle|
    \begin{aligned}
      &r(\tuple{d_{1}, q_{1}}\dots
      \tuple{d_{i}, q_{i}})(d_{i+1}, q_{i+1}) = 1&\text{if }i>0\\
      &r(\epsilon)(d_{1}, q_{1}) = 1&\text{if }i=0
    \end{aligned}
    }
  \end{equation*}
  and require that
  \begin{equation*}
    M_{r}\subseteq D^{\omega}\times\Acc.
  \end{equation*}
  Again, we consider for $\Acc$ acceptance conditions which are representable
  as Büchi-, Rabin-, Muller- or Parity-conditions and use according acronyms,
  namely \acs{ABTA}, \acs{ARTA}, \acs{AMTA}, \acs{APTA} respectively.
  \acuse{ABTA} \acuse{AMTA} \acuse{ARTA} \acuse{APTA} 
\end{definition}
By using the same argument as for Theorem 
\ref{thm:omegaregularexp} and Theorem \ref{thm:treeautoequiv} we obtain
\begin{theorem}
  \ac{ARTA}, \ac{AMTA} and \ac{APTA} recognize the same class of languages.
  \label{thm:atreeautoequiv}
\end{theorem}
Although \emph{alternation} is an extension of the \enquote{classic} tree 
automata it turns out that it does not increase the expressibility; that is
for every alternating tree automta there is a classic tree automata which 
accepts the same language of trees.
\begin{theorem}[The Simulation Theorem]
  \cite[Theorem 1.2]{SimAltTreeAuto}
  There is an effective construction which, when given an \ac{AMTA}, produces 
  an equivalent \ac{MTA}. Furthermore, given an \ac{ABTA}, there is a way to 
  effectively construct an equivalent \ac{BTA}.
  \label{thm:treesimulation}
\end{theorem}
This result and the apparent observation that alternation does not weaken the 
formalism to accept trees allows to translate the closure properties stated in 
Theorem \ref{thm:treeautoboolean} to alternating tree automata as well. Thus, 
we obtain that there are effectively constructable transformations for the 
union, intersection and complement of tree languages accepted by \ac{AMTA}. 
Nevertheless, we want to present one construction for the closure under 
intersection because it allows us to relate concepts of \acp{PBA} and of
alternation.
\begin{corollary}
  The class of languages of infinite trees that can be recognized by \acp{AMTA}
  is closed under intersection.
\end{corollary}
\begin{proof}[Alternative Proof]
  Given two \acp{AMTA}
  \begin{equation*}
    \mathcal{A}_{1} = \tuple{Q, q_{0}, D, \Sigma, \Delta_{1}, \mathcal{F}_{1}}
      \text{ and }
    \mathcal{A}_{2} = \tuple{P, p_{0}, D, \Sigma, \Delta_{2}, \mathcal{F}_{2}}
  \end{equation*}
  we construct an \ac{AMTA} for their intersection. W.l.o.g. we assume that 
  $Q\cap P = \emptyset$. The idea is to perform two independent runs on the 
  tree in parallel. We illustrate this in Figure \ref{fig:parallelruns}. 
  Formally, it is accomplished by initially dispatching one transition of each 
  automaton onto the tree. After this initial dispatch both state sets $Q$ and
  $P$ operate independently on the tree. Hence, we define
  \begin{equation*}
    \mathcal{A}_{\cap} = \tuple{
      Q\cup P\uplus\set{q^{i}}, q^{i}, D, \Sigma, 
      \Delta_{1}\cup\Delta_{2}\cup\Delta_{\cap}, 
      \mathcal{F}_{1}\cup\mathcal{F}_{2}
    }
  \end{equation*}
  with
  \begin{equation*}
    \Delta_{\cap} = \set{
      \tuple{q^{i},\sigma,\delta_{A\cup B}}:
        \tuple{q_{0},\sigma,\delta_{A}}\in\Delta_{1}
      \text{ and }
        \tuple{p_{0},\sigma,\delta_{B}}\in\Delta_{2}
      \text{ for every }
        \sigma\in\Sigma
    }.
  \end{equation*}
  Thus, we can construct from the resulting run $r$ in $\mathcal{A}_{\cap}$ two
  individual runs in $\mathcal{A}_{1}$ and $\mathcal{A}_{2}$ respectively, e.g.
  for $\mathcal{A}_{1}$ it is the run $r_{1}$ in the $Q$-part of the domain of 
  $r$ while the initial transition in $r$ uses a $\delta_{A\cup B}$ where 
  $r_{1}$ uses $\delta_{A}$.
\end{proof}

While considering the semantics of \acp{PBA} we used a notion of considering 
individual runs and their probabilities. This can be captured very similar to 
the concept of alternation as follows: we can regard any word 
$\alpha\in\Sigma^{\omega}$ as a $\set{0}$-ary $\Sigma$-tree $t_{\alpha}$. Then 
one \ac{PBA} $\mathcal{P}$ induces a run in a tree-sense by unrolling the state
sequences of $\mathcal{P}$ around the unary tree $t_{\alpha}$. Hereby, we can
substitute the clause-functions which have a very absolute semantic (either a
path is taken or it is not) by a probability distribution. When we gather the
individual probability distributions of $\mathcal{P}$, that is set 
$\mathcal{G}$ of all functions of the form 
$G_{\sigma}^{q}:\set{0}\times Q\rightarrow\interval{0,1}$ such that
$G_{\sigma}^{q}(0, p) = \delta(q,\sigma, p)$. We can model the run of 
$\mathcal{P}$ as a $\set{0}\times Q$-ary $\mathcal{G}$-tree where the chosen
$G_{\sigma}^{q}$ one the paths $\tuple{0,q_{1}}\dots\tuple{0,q_{n}}$ are 
consistent with the current state ($q = q_{n}$) and input symbol 
($\sigma = t(0^n)$). Therefore, every path corresponds to one state sequence of 
$\mathcal{P}$ and the visited $G_{\sigma}^{q}$ on the path induce the 
associated probabilities for the peformed steps. In this sense we can use 
Figure \ref{fig:parallelruns} as illustration for the part of the union 
operator of the proof of Theorem \ref{thm:pbaboolalgebra} where the initial 
separating dispatch is in every direction tuned down by a factor of 
$\frac{1}{2}$. This intuition is later on re-visited and formally 
substantiated. In the meantime we introduce the concept of \emph{Graph Games} 
to obtain a transformation that constructs the \ac{AMTA} which accepts the 
negation of the language of a given \ac{AMTA}. Mainly, we formulate the 
acceptance of a tree in terms of a game between two players. One player 
constructs the run to prove the existance of a valid run while the other play 
chooses the path along the run to spoil the correctness by finding a 
non-accepted path.

\subsection{Graph Games}
Tree automata are closely related to graph games, e.g.
\cite[Chapter 9]{AutoLogInfGames}. Such games are held between two players in
an \emph{arena}. An arena is a directed graph where the nodes are partioned
into two sets; each set is associated with one player. A game on such an arena
begins in one node and unfolds by the choices of the players. The player to
whom the current node $v$ belongs may choose the node $u$ the game proceeds to
from the set of those nodes connected to $v$. By associating a winning
condition for one player to the game we can call a game won by this player if
the played state sequence belongs to her winning condition. In this thesis we
consider zero-sum games, i.e. if the winning condition of one player is not met
we consider the opponent victorious. This leads to the definition
\begin{definition}[Graph Games]
  \begin{description}
    \item [Arena] Let $V$ be a set of nodes which is partioned into $V_{0}$ and
      $V_{1}$ and $E\subseteq V\times V$ a set of edges, then we define an
      arena $\tuple{V, V_{0}, V_{1}, E}$.
    \item [Game] For an arena $\tuple{V, V_{0}, V_{1}, E}$ we define with a
      winning condition $\Acc$ and one distinguished initial vertex
      $v_{0}\in V$ the game
      $\tuple{\mathcal{G}, v_{0}} = \tuple{V, V_{0}, V_{1}, E, \Acc}$.
    \item [Play] A play for a game $\tuple{\mathcal{G}, v_{0}} = \tuple{V,
      V_{0}, V_{1}, E, \Acc}$ is any sequence $v_{0}v_{1}\dots\in
      V^{\omega}$ which starts in $v_{0}$ and where for every $i > 0$ holds
      that $v_{i}\in v_{i-1}E$.
    \item [Strategy] For $\sigma\in\set{0,1}$ we define a strategy
      $f_{\sigma}: V^{*}V_{\sigma}\rightarrow V$ where for any $w\in V^{*}$ and
      $v\in V_{\sigma}$ $f_{\sigma}(w\cdot v)\in vE$ (where $vE =
      \set{u\in V\mid\tuple{v,u}\in E}$). A play is considered winning for
      player $0$ if it belongs to $\Acc$. Notably it holds that two strategies
      $f_{0}, f_{1}$ induce a play $v_{0}v_{1}\dots$ by fixing for any $v\in V$
      the term
      \begin{equation*}
        \sigma(v) = \begin{cases}
          0&\text{if }v\in V_{0}\\
          1&\text{if }v\in V_{1}\\
        \end{cases}\text{ and enforcing }
        v_{i+1} = f_{\sigma(v_{i})}(v_{0}\dots v_{i}).
      \end{equation*}
      If a strategy for player $\sigma$ can equivalently be represented as a
      function $f:V_{\sigma}\rightarrow V$ (naturally still satisfying that
      $f(u)\in uE$ for all $u\in V_{\sigma}$) we call this strategy
      \emph{memoryless} or \emph{positional}.
    \item [Winning] We say a play $v_{0}v_{1}\dots$ is \emph{consistent} with a
      strategy $f$ for player $\sigma$ if for every $i$ with
      $v_{i}\in V_{\sigma}$ holds that $v_{i+1} = f(v_{0}\dots v_{i})$. 
      A strategy $f$ for player $\sigma$ is called a \emph{winning strategy} if
      \emph{every} play consistent with $f$ is winning for player $\sigma$.
      We denote with \emph{winning regions}
      $\mathcal{W}^{\mathcal{G}}_{\sigma}$ those nodes $v\in V$ such that
      player $\sigma$ has a winning strategy in $\tuple{\mathcal{G}, v}$.
  \end{description}
  As we are already accustomed $\Acc$ is represented in finite ways by using
  Büchi-, Rabin-, Muller- or Parity-conditions.
\end{definition}
Given any game $\mathcal{G}$ the question arises that for every node $v$ one of
the players can ensure her win by playing the correct strategy (regardless of
the strategy her opponent chooses), i.e.
$\mathcal{W}^{\mathcal{G}}_{0}\cup\mathcal{W}^{\mathcal{G}}_{1} = V$. We call
a game with this property \emph{determined}. There is a fundamental result by
Martin establishing determinacy for all Borel winning conditions for another 
kind of games\footnote{Gale-Stewart games} \cite{BorelDeterminacy}. 
Fortunately, this translates to graph games and allows us to state using Lemma 
\ref{lem:measureabilityAcceptance} and its Corollary \ref{cor:borelAcceptance}
that
\begin{theorem}
  \cite[Corollary 2.10]{AutoLogInfGames}
  All graph games with Büchi-, Rabin-, Muller- or Parity-condition are 
  determined.
\end{theorem}
And additionally, for Parity-conditions we even obtain that the corresponding
strategies are positional, i.e.
\begin{theorem}
  \cite[Theorem 6]{ParityGamesPosDet}
  For a graph game with a Parity-condition with finitely many parities both 
  players have positional winning strategies on their corresponding winning 
  regions.
  \label{thm:posdetparity}
\end{theorem}

As mentioned above we use graph games to model the semantics of tree automata.
Therefore, we define an acceptance game for an automaton and a tree, i.e. an 
(infinite) graph game where one player constructs a run of the automaton on the
tree and the other player explores the tree and tries to find a path which is
not accepted.

\subsection{Weighted Descent Tree Automata}
Building upon \cite{RandAutoInfTrees} we expand on the notion of weighting
the different paths of the run. Hereby, we incorporate the concept of
\emph{alternation} by allowing to send different states on the same path
through the tree with individual weight. Thus, we capture on transition in a
probability function over states and directions of an automaton.
\begin{definition}[Generator]
  For a set of states $Q$ and a set of directions $D$ we call a probability
  function on $Q\times D$, i.e. $G: Q\times D\rightarrow [0,1]$ with
  $\sum\limits_{\substack{q\in Q\\ d\in D}}G(q,d) = 1$, a generator over $Q$
  and $D$. A finite non-empty set of generators over sets $Q$ and $D$ is called
  a clause $C = \set{G_{1},\dots,G_{n}}$.
\end{definition}
With these transitions we adapt the common concepts of tree automata by
allowing the automaton to build a run of \enquote{transitions}.
\begin{definition}[Weighted Descent Tree Automaton]
  We define a \acl{WDTA} as tuple
  $\mathcal{A} = \tuple{Q, q_{0}, D, \Sigma, \Delta, T}$ where $Q$ is a finite
  set of states, $q_{0}$ the initial state, $D$ a finite set of directions,
  $\Sigma$ is a finite Alphabet and $T\subseteq Q^{\omega}$ is a
  $\omega$-regular target of infinite words of elements in $Q$. The transitions
  in $\Delta$ are given as clauses for every state and symbol:
  $\Delta:Q\times\Sigma\rightarrow\mathcal{C}^{Q}_{D}$
  where $\mathcal{C}^{Q}_{D}$ denotes the set of all clauses over $Q$ and $D$.
  Additionally, we define the set of all used generators as
  $\mathcal{G}_{\mathcal{A}} = \bigcup\limits_{q\in Q,\sigma\in\Sigma}
    \Delta(q,\sigma)$.
\end{definition}
The semantics of a \ac{WDTA} $\mathcal{A}$ is given as a run
$r:\tuple{Q\times D}^{*}\rightarrow \mathcal{G}_{\mathcal{A}}$. Analogously to
a strategy in Definition \ref{def:mdp} a run induces a probability measure on
the set of cylinders over $(Q\times D)$ by
\begin{equation}
  \mu_{r}(\cyl(\tuple{q_{1},d_{1}}\dots\tuple{q_{n},d_{n}}))
    = r(\epsilon)(q_{1},d_{1})\cdot\prod\limits_{i = 1}^{n - 1}
    r(\tuple{q_{1},d_{1}}\dots\tuple{q_{i},d_{i}})(q_{i+1},d_{i+1})
\end{equation}
for every $\tuple{q_{1},d_{1}}\dots\tuple{q_{n},d_{n}}\in\tuple{Q\times D}^{*}$.

In the following we often focus on parity conditions and motivate this by the
observation that parity conditions can be used to express all other conditions
(as suggested but not proven in \cite[page 24:9]{RandAutoInfTrees}).
\begin{lemma}
  For every \ac{WDTA} $\mathcal{A}$ with a Büchi, Rabin or Muller
  acceptance condition we can construct an equivalent \ac{WDTA} $\mathcal{B}$
  with a parity condition.
\end{lemma}
\begin{proof}
  Firstly, we observe that Büchi and Rabin conditions can be expressed
  as Muller conditions \cite[Proposition 5.3]{LangAutoLog}. Secondly, we
  construct for a \ac{WDTA} $\mathcal{A} = \tuple{Q, q_{0}, D, \Sigma, \Delta,
  \mathcal{F} = \set{F_{1},\dots,F_{n}}}$ with a Muller condition $\mathcal{F}$
  an equivalent \ac{WDTA} $\mathcal{B}$ with a parity condition via the use of
  a \ac{LAR} (analogously to e.g. \cite{SimAltTreeAuto} for unweighted tree
  automata). The idea of an \ac{LAR} is to keep a record of the order of
  recently visited states which eventually stabilizes to those states seen
  infinitely often. Using a \ac{LAR} increases the state space but preserves
  the structure, especially the weighting, of a run and thus yields the same
  measure of the set of accepted paths. 
  We construct
  $\mathcal{B}=\tuple{\lar(Q),\ell_{0}, D, \Sigma, \Delta',\parity}$ where
  $\ell_{0}$ is one arbitrary element of $\lar(Q)$ and $\parity$ is defined as
  described above for the Muller condition of $\mathcal{A}$. For every clause
  $\Delta(q,\sigma) = \set{G_{1},\dots,G_{n}}$ we define
  $\Delta'(\ell,\sigma) = \set{G_{1}',\dots,G_{n}'}$ with
  \begin{equation*}
    G_{i}'(\ell', d) = \begin{cases}
      G_{i}(q,d) &\text{ if }\ell' = \up(\ell,q)\\
      0          &\text{ otherwise}
    \end{cases}
  \end{equation*}
  This yields that every run of $\mathcal{A}$ on a tree $t$ induces a run of
  $\mathcal{B}$ on $t$ by substituting every $G$ by $G'$ and vice versa. Since
  the set of accepting paths in both runs have the same measure we obtain the
  equivalence of $\mathcal{A}$ and $\mathcal{B}$.
\end{proof}
We say that $\mathcal{A}$ accepts $t$ if an accepting run exists where the
notion of an accepting run is (analogously to \acp{PBA}) tied to an
\enquote{acceptable measure}, e.g. Positive Acceptance or Almost-Sure
Acceptance.

Additionally, we define certain structural properties on \acp{WDTA}
\begin{definition}[Structural Properties]
  A \ac{WDTA} $\mathcal{A}$ is called
  \begin{description}
    \item [choiceless] if there is at most one generator in each clause, i.e.
      for every pair $q\in Q, \sigma\in\Sigma$ holds
      $\size{\Delta(q, \sigma)} = 1$.
    \item [uni-directional] if for every clause there is at most one state send
      to every direction, i.e. for every $G\in\mathcal{G}_{\mathcal{A}}$
      there is at most one $q\in Q$ such that $G(q, d) > 0$ for all
      $d\in D$. Intuitively this means that the automaton explores every path
      with at most one state.
    \item [uniformly distributed (u.d.)] if $\mathcal{A}$ is uni-directional
      and for a direction $d\in D$ every clause agrees on the weight that is
      sent down that direction. Thus, for all $d\in D$ holds that for all
      $G_{1}, G_{2}\in\mathcal{G}_{\mathcal{A}}$ we have
      $G_{1}(q, d) = G_{2}(p, d)$ for the unique $q, p$ for which
      $G_{1}(q, d) > 0$, respectively $G_{2}(p, d) > 0$ or
      $G_{1}(q, d) = G_{2}(p, d) = 0$ for all $q, p$. Thus, we can fix a
      probability distribution $B:D\rightarrow \interval{0,1}$ such that for
      every $G\in\mathcal{G}_{\mathcal{A}}$ there is one $q\in Q$ with
      $B(d) = G(q, d)$. We call this distribution $B$ the \emph{blueprint} of
      $\mathcal{A}$. 
  \end{description}
\end{definition}
The examined tree automata in \cite{RandAutoInfTrees} are therefore captured by
uniformly distributed \acp{WDTA} over the directions $D = \set{0,1}$ with
blueprint $B(0) = B(1) = \frac{1}{2}$.

\subsection{Closure Properties}
In the following we want to explore the closure properties of the introduced
\acp{WDTA} regarding union, intersection and negation. Unsuprisingly, the
non-determinism of the model induces closure under union for certain classes in
a straightforward manner (as suggested by \cite{RandAutoInfTrees}). We
generally only examine these properties for automata over the same set of
directions and the same alphabet.
\begin{proposition}[Union - uni-directional, unrestricted]
  Uni-directional and unrestricted \acp{WDTA} are closed under union.
  \label{prop:uniunrunion}
\end{proposition}
\begin{proof}
  For two automata
  $\mathcal{A}_{1} = \tuple{Q, q_{0}, D, \Sigma, \Delta_{1}, T_{1}}$ and
  $\mathcal{A}_{2} = \tuple{P, p_{0}, D, \Sigma, \Delta_{2}, T_{2}}$ we can
  w.l.o.g. assume that $Q\cap P = \emptyset$. The union \ac{WDTA} guesses in
  the very first transition which of the automata is checked for the tree:
  \begin{equation*}
    \tuple{Q\cup P\cup\set{z}, z, D, \Sigma,
    \Delta_{1}\cup\Delta_{2}\cup\set{
      \tuple{z,\sigma}\mapsto C_{\sigma}}_{\sigma\in\Sigma}, T_{1}\cup T_{2}}
  \end{equation*}
  where $z$ is a new state and
  $C_{\sigma} = \Delta_{1}(q_{0},\sigma)\cup\Delta_{2}(p_{0}, \sigma)$. Thus,
  in $z$ the decision if a generator from $\mathcal{A}_{1}$ or
  $\mathcal{A}_{2}$ is chosen determines for which automata the run is
  generated. It is noteworthy that every run is in bijection to a run of
  $\mathcal{A}_{1}$ or $\mathcal{A}_{2}$ and thus induces the same measurement
  on the set of accepted paths and that this construction preservers
  uni-directionality.
\end{proof}
\begin{corollary}
  The class of u.d. \acp{WDTA} with a fixed blueprint $B$ is closed under
  union.
\end{corollary}
\begin{proof}
  The construction for Proposition \ref{prop:uniunrunion} respects a common
  blueprint of $\mathcal{A}_{1}$ and $\mathcal{A}_{2}$.
\end{proof}
\fxwarning{what about u.d. with different blueprints? more general question:
how are non-determinism and weighting related? orthogonal or dependent?}

Regarding intersection we observe a significant difference between positive and
almost-sure acceptance. This is rooted in the \enquote{global} nature of
almost-sure acceptance while positive acceptance can be accomplished by
\enquote{local} phenomenon, e.g. one accepted subtree somewhere in the tree.
Thus, for almost-sure acceptance a general intersection operator can separate
in the first transition the runs of both \ac{WDTA} with a probability of
$\frac{1}{2}$ each.\fxwarning{add picture} Both these runs do individually need
an acceptance measure of $1$ to render the new run almost-surely accepted.
This can be captured with the following lemma
\begin{lemma}
  A run $r:T\rightarrow \mathcal{G}_{\mathcal{A}}$ of $\mathcal{A}$ is
  almost-surely accepted if and only if every subtree of $r$ is almost-surely
  accepted.
  \label{lem:subtreeacc}
\end{lemma}
\fxfatal{heavily rewrite proof; maybe find reference for a comparable lemma}
\begin{proof}
  Considering that the examined acceptance conditions in this thesis are all
  history independent, i.e. for every $\alpha$ that satisfies an acceptance
  condition if and only if every $\beta$ with $\alpha = u\cdot\beta$ for a
  finite $u$ satisfies the condition. If all subtrees of $r$ are almost-surely
  accepted then $r$ itself. On the other hand, if not all subtrees of $r$ are
  almost-surely accepted then there is a finite path to a non accepted subtree
  with a positive measure $m$. The measure of accepted path in the subtree is
  then $n<1$, hence $r$ is at least $m\cdot n$ short of measure $1$.
\end{proof}
which yields the following theorem
\begin{proposition}
  Unrestricted \acp{WDTA} with almost-sure acceptance are closed under
  intersection.
\end{proposition}
\begin{proof}
  We introduce the intersection automaton as follows
  \begin{definition}
    For $\mathcal{A} = \tuple{Q, q_{0}, D, \Sigma, \Delta, \parity}$ and
    $\mathcal{B} = \tuple{P, p_{0}, D, \Sigma, \Delta', \parity'}$ we define
    \begin{equation*}
      \mathcal{C} = \tuple{Q\uplus P\uplus\set{b}, b, D, \Sigma,
      \Delta\uplus\Delta'\uplus\nabla, \parity\uplus\parity'\uplus
      \set{b\mapsto 0}}
    \end{equation*}
    with
    \begin{equation*}
      \Delta(q_{0},\sigma) = \set{G_{\sigma}^{1},\dots,G_{\sigma}^{n}}
      \text{ and }
      \Delta(p_{0},\sigma) = \set{K_{\sigma}^{1},\dots,K_{\sigma}^{m}}
    \end{equation*}
    we set
    \begin{equation*}
      \nabla(b,\sigma) = \bigcup^{1\leq i\leq n}_{1\leq j\leq m}\set{
        \frac{G_{\sigma}^{i}}{2} \cup \frac{K_{\sigma}^{j}}{2}}
    \end{equation*}
    where $\frac{G}{2}$ describes the halving of every function value of $G$.
  \end{definition}
  Any run $r$ of $\mathcal{C}$ on a tree $t$ consists of two parallel runs on
  $t$, namely $r_{\mathcal{A}}$ of $\mathcal{A}$ and $r_{\mathcal{B}}$ of
  $\mathcal{B}$. By Lemma \ref{lem:subtreeacc} holds that $r$ is almost-surely
  accepted if and only if every subtree of $r$ is almost-surely accepted which
  holds if and only if every subtree of $r_{\mathcal{A}}$ and $r_{\mathcal{B}}$
  is almost-surely accepted. This characterisation yields the claimed equality.
\end{proof}
For uni-directional \acp{WDTA} with common blueprint the common product
construction for intersection leads to a intersection operator, hence
\begin{proposition}
  Uni-directional \acp{WDTA} with common blueprint are closed under
  intersection.
\end{proposition}

\subsection{Emptiness}
Similarly to \acp{PBA}, we want to define for a given \ac{WDTA} $\mathcal{A}$
a game that captures the behaviour of $\mathcal{A}$. Again, this will result in
the definition of \ac{POMDP}. This game is designed to go through the following
steps:
\begin{enumerate}
  \item initially, the player chooses any $G\in\mathcal{G}_{\mathcal{A}}$
    such that $G\in\Delta(q_{0},\sigma)$ for any $\sigma\in\Sigma$
  \item then the game moves to a position $\tuple{q,d}\in\tuple{Q\times D}$
    with probability $G(q,d)$
  \item the player is not allowed to observe the state of the current position
    but may choose dependent on the observed direction $d$ one
    $\sigma\in\Sigma$ and a transition $G\in\Delta(q,\sigma)$ for every
    $q\in Q$
  \item the game proceeds to any $\tuple{q,d}$ with the corresponding
    probability $G(q,d)$
\end{enumerate}
Similiar to Example \ref{ex:pbaaspomdp} a strategy only represents a tree if 
for every play the choice of a letter $\sigma$ is consistent throughout all 
plays associated with one certain word of directions. Therefore, we introduce 
in the choice of the player the restriction of observation in step $3$. This 
allows the player to exclusively observe the directions taken throughout the 
game and base her/his decision of which letter to place on this observation 
only.
\begin{definition}[Emptiness Game]
  For a \ac{WDTA} $\mathcal{A} = \tuple{Q, q_{0}, D, \Sigma, \Delta, T}$ we
  fix the set of actions $A$ for the player as a set
  \begin{equation*}
    A = Q\rightarrow\Delta_{\Sigma}
  \end{equation*}
  where $\tuple{Q\rightarrow\Delta_{\Sigma}}$ is the set of functions that map
  for one fixed $\sigma$ a state $q\in Q$ to a generator in $\Delta(q,\sigma)$.
  Let $\sigma(f)$ for $f\in\tuple{Q\rightarrow\Delta_{\Sigma}}$ be the
  associated element in $\Sigma$ for $f$. The emptiness game is then defined as
  a \ac{POMDP}
  \begin{equation*}
    \mathcal{M}_{\mathcal{A}} = \tuple{\tuple{Q\times D}\uplus \set{q_{0}}, A,
    \tuple{\tau_{a}}_{a\in A}, q_{0}}
  \end{equation*}
  where
  \begin{equation*}
    \tau_{f}(\tuple{q,d},\tuple{q',d'}) = f(q)(q',d')
  \end{equation*}
  and the associated observation relation is $\sim$ with
  \begin{equation*}
    \tuple{q, d}\sim\tuple{p, d'}\text{ if and only if } d = d'
  \end{equation*}
\end{definition}
In order to prove the viability of this game definition we show that a strategy
$s$ can be understood as a tree $t$ and that the induced probability measure on
paths coincides with a run $r$ of $\mathcal{A}$ on $t$. And for any associated
measureable objective $\mathcal{O}\subseteq Q^{\omega}$ which can be projected
onto the states of $\mathcal{M}_{\mathcal{A}}$ by only considering the state
component of any position in the play the measures of plays in
$\mathcal{M}_{\mathcal{A}}$ and in the run-tree coincide. Thus, we get
\begin{theorem}
  There is a strategy $s$ which ensures that an objective
  $\mathcal{O}\subseteq Q^{\omega}$ is positively (resp. almost-surely)
  satisfied in $\mathcal{M}_{\mathcal{A}}$ if and only if there is tree $t$ and
  a run $r$ of $\tuple{\mathcal{A},\mathcal{O}}$ on $t$ which is positively
  (resp. almost-surely) accepted.
  \label{thm:emptinessgame}
\end{theorem}
\begin{proof}
  First of all, we recall that any strategy for $\mathcal{M}_{\mathcal{A}}$ is
  defined as a function which chooses for any finite play the next action, i.e.
  $s:\tuple{\tuple{Q\times D}\uplus\set{q_{0}}}^{+}\rightarrow A$. But
  considering the properties of the game closely the strategy can be reduced to
  its effective core. By the restriction of observation every such strategy
  only observes the directions and thus can be expressed as a function of the
  form $s:\tuple{D\uplus\set{q_{0}}}^{+}\rightarrow A$. Secondly, we define
  $P = \set{\alpha_{1}\alpha_{2}\dots\in\tuple{\tuple{Q\times D}\uplus
  \set{q_{0}}}^{+}\mid \alpha_{0} = q_{0}\text{ and there is no }i>0
  \text{ s.t. }\alpha_{i} =q_{0}}$
  and argue that only plays in $P$ actually do matter in the game.
  \begin{lemma}
    Every two strategies $s,s'$ that agree on all finite prefixes of
    observations of plays in $P$ induce the same measure for plays in
    $\mathcal{M}_{\mathcal{A}}$.
  \end{lemma}
  \begin{proof}
    The begin of any play in $q_{0}$ is by definition of \acp{POMDP} and the
    fact that $q_{0}$ is the initial state. Furthermore, consider any finite
    prefix $u\in\tuple{\tuple{Q\times D}\uplus \set{q_{0}}}^{+}$ of a play
    $\beta\notin P$. And let $i$ be the index of the second occurence of
    $q_{0}$ in $u$. By the definition of $\mathcal{M}_{\mathcal{A}}$ the
    movement from $u_{i-1}$ to $u_{i}$ has a probability of $0$ regardless of
    the choice of either $s$ or $s'$. This yields
    $\mu_{s}(\cyl(u_{0}\dots u_{i})) = \mu_{s'}(\cyl(u_{0}\dots u_{i})) = 0$.
    Thus, only plays in $P$ possibly do have a positive measure, hence
    strategies that coincide in these plays are equivalent.
  \end{proof}
  We can therefore regard any strategy as a function
  $s:q_{0}\cdot D^{*}\rightarrow A$ and extract an associated tree $t$ by
  $t(u) = \sigma(s(q_{0}\cdot u))$ for any $u\in D^{*}$ and also a run $r$ of
  $\mathcal{A}$ on $t$ by setting for
  $\tuple{q_{0}, d_{0}}\dots\tuple{q_{n}, d_{n}}\in\tuple{Q\times D}^{*}$ and
  $f = s(q_{0}d_{0}d_{1}\dots d_{n})$:
  $r(\tuple{q_{0}, d_{0}}\dots\tuple{q_{n}, d_{n}}) = f(q_{n})$ which is by
  definition of $f$ a valid generator from $\Delta(q_{n}, t(d_{0}\dots d_{n}))$.
  In this fashion we can biject plays of the emptiness game to paths in the
  run-tree which induce the same probability measure implying the claim.
\end{proof}
\begin{corollary}[Emptiness Almost-Sure Büchi WDTA]
  The emptiness problem for a \ac{WDTA} with almost-sure acceptance measure of
  a Büchi condition can be decided in exponential time.
  \label{cor:emptiness}
\end{corollary}
\begin{proof}
  Apply \cite[Theorem 5]{QualAnaPOMDP} to the corresponding emptiness game.
\end{proof}
\begin{corollary}[Emptiness Almost-Sure Uni-Directional WDTA]
  The emptiness problem for an uni-directional \ac{WDTA} with almost-sure
  acceptance measure of a $\omega$-regular condition can be decided in
  polynomial time.
\end{corollary}
\begin{proof}
  Since only one state is at any time on a position in the tree the restriction
  of observation can be discarded without losing the consistency of the
  associated tree to the strategy. Then, apply
  \cite[Theorem 3]{RandAutoInfTrees} to the corresponding emptiness game.
\end{proof}
We designed for one \ac{WDTA} a corresponding emptiness game in form of an
\ac{POMDP} and in the proof to Theorem \ref{thm:emptinessgame} we used the
resemblance of a runtree to the unrollment of an \ac{POMDP} as induced by a
strategy. This naturally poses the question if a translation in the other
direction is viable and, indeed, it is.
\begin{theorem}
  \label{thm:POMDPequivWDTA}
  For every \ac{POMDP} $\mathcal{M}$ exists an \enquote{equivalent}
  deterministic \ac{WDTA} $\mathcal{A}$ with the same state space.
\end{theorem}
\begin{proof}
  Let $\mathcal{M} = \tuple{S, A, \tuple{\tau_{a}}_{a\in A}, s_{0}, \sim}$ be a
  \ac{POMDP}. We can extract the possible observations in $\mathcal{M}$ and
  gather them as $O = \set{\interval{s}_{\sim}\mid:s\in S}$. A strategy for
  $\mathcal{M}$ therefore is only dependent on the sequence of observations up
  to the current state of play, i.e. a word in $u\in s_{0}O^{*}$. Fixing the
  set of directions and the set of letters for a tree $t$ to $O$ and $A$
  respectively renders $t:O^{*}\rightarrow A$ as a viable strategy $s$ for
  $\mathcal{M}$ by identifying $t(u)$ with $s(s_{0}\cdot u)$. This naturally
  leads to
  \begin{definition}
    For $\mathcal{M} = \tuple{S, A, \tuple{\tau_{a}}_{a\in A}, s_{0}, \sim}$
    with $O = \set{\interval{s}_{\sim}: s\in S}$ define
    \begin{equation*}
      \mathcal{A} = \tuple{S, s_{0}, O, A, \Delta}
    \end{equation*}
    where
    \begin{equation*}
      \Delta(s, a\in A) = \set{G_{s}^{a}}\text{ and }
      G_{s}^{a}(s', o) = \begin{cases}
        \tau_{a}(s, s')&\text{ if }o = \interval{s'}_{\sim}\\
        0              &\text{ otherwise}
      \end{cases}
    \end{equation*}
  \end{definition}
  Thus, from the current state those states with observation $o\in O$ are sent
  in direction $o$. Therefore, the unique run $r$ on any tree $t$ yields for a
  state sequence $u\in S^{*}$ and a sequence of observations $v\in O^{\size{u}}$
  that
  \begin{equation*}
    \mu_{r}(\cyl(\tuple{u_{0},v_{0}}\dots\tuple{u_{n},v_{n}})) =
    \begin{cases}
      \prod_{0\leq i\leq n-1}\tau_{t(v_{0}\dots v_{i})}(u_{i}, u_{i+1})
        &\text{ if }u_{0} = s_{0}\text{ and }\interval{u_{i}}_{\sim} = v_{i}\\
      0 &\text{ otherwise}
    \end{cases}
  \end{equation*}
  which coincides with the measure for $\mu_{s}(\cyl(u))$ in $\mathcal{M}$.
\end{proof}

\subsection{Equivalence of \acp*{WDTA} and \acp*{PBA}}
By reducing the directions to a singelton set a tree degenerates to a single
path. This path can be interpreted as one word and thus, we can incorporate the
concept of \acp{PBA} into the theory of \acp{WDTA} by the following theorem
\begin{theorem}
  For every \ac{PBA} $\mathcal{P}$ existent an equivalent \ac{WDTA}
  $\mathcal{A}$ and for every choiceless \ac{WDTA} $\mathcal{A}$ with
  $\size{D_{\mathcal{A}}} = 1$ exists an equivalent \ac{PBA}.
  \label{theorem:pbaequiv}
\end{theorem}
\begin{proof}
  For a \ac{PBA} $\mathcal{P} = \tuple{Q, \Sigma, \delta, q_{0}, F}$ we define
  \ac{WDTA} $\mathcal{A} = \tuple{Q, q_{0}, \set{0}, \Sigma, \Delta, F}$ with
  $\Delta(q,\sigma) = \set{G_{q}^{\sigma}}$ and
  $G_{q}^{\sigma}(p, 0) = \delta(q, \sigma, p)$. A word
  $\alpha\in\Sigma^{\omega}$ can be expressed equivalently as function
  $\alpha:\mathbb{N}\rightarrow\Sigma$ and with the bijective mapping of $0^n$
  to $n$ we obtain an equivalent tree $\alpha:\set{0}^{*}\rightarrow\Sigma$.
  The (unique) run of $\mathcal{A}$ on $\alpha$ is in bijection to the runtree
  of $\mathcal{P}$ on $\alpha$ which yields the claimed equality.
\end{proof}
This directly entails some undecideability results carried over from \acp{PBA}.
\begin{corollary}
  The undecideability of the emptiness problem for \acp{PBA} with positive
  acceptance \cite{Groesser} renders the emptiness problem for \acp{WDTA} with
  positive acceptance undecideable.
\end{corollary}
\begin{corollary}
  The emptiness problem for \acp{WDTA} with almost-sure acceptance is
  undecideable.
\end{corollary}
\begin{proof}
  By \cite[Proof of Theorem 1]{DecProblemsForProbAuto} there is an equivalent
  probabilistic Rabin automaton for which the accepted paths have either
  measure $0$ or $1$ for every \ac{PBA} with positive acceptance. Thus, for the
  the equivalent \ac{WDTA} to this probabilistic Rabin automaton positive and
  almost-sure acceptance coincides rendering the emptiness problem for both
  acceptance criteria undecideable.
\end{proof}
Note that this undecideability result does not contradict the decideable
emptiness for \acp{WDTA} with Büchi condition and almost-sure acceptance but
simply shows that Büchi conditions are less expressive (as it is for
non-weighted tree automata\fxfatal{find reference}).

Having used the fact that moving from Büchi to Rabin acceptance conditions
allow for \acp{PBA} to allow an almost-sure acceptance rather than a positive
acceptance sparks the question if this can be translated to choiceless
\acp{WDTA} as well. Unfortunately, this question can be answered negatively
with
\begin{proposition}
  There exists a language that is accepted by a choiceless \ac{WDTA} with a
  positive acceptance of a Büchi condition that is not accepted by any
  choiceless \ac{WDTA} with a Muller condition.
\end{proposition}
\begin{proof}
  We define $\mathcal{L}_{\exists a}$ as the language of all trees with
  directions $\set{0,1}$ over the alphabet $\set{a,b}$ that do contain an $a$.
  First, we show that this language can be accepted by a choiceless Büchi
  \ac{WDTA} with positive acceptance of a Büchi condition. But this is
  straightforward by constructing a \ac{WDTA} with two states $q_{a}, q_{b}$
  where $q_{b}$ is the initial state. The final state is $q_{a}$ and we
  distribute uniformely over both branches $q_{b}$ until an $a$ occurs where
  the automaton distributes uniformely the state $q_{a}$ regardless of the read
  letter, thus $q_{a}$ is a positive sink-state. Any tree that is accepted does
  necessarily contain an $a$ since it is the only chance to produce an
  acceptance subtree and conversely, if a tree does contain an $a$ there is a
  finite path of length $n$ towards the subtree rooted at this occurence of $a$,
  hence in the run of the automaton on this tree there is an accepted subtree
  which is reached with probability $(\frac{1}{2})^{n} > 0$ rendering the run
  accepting for this tree.

  On the other hand we show that there is no choiceless \ac{WDTA} with an
  almost-sure Muller condition that accepts precisely $\mathcal{L}_{\exists a}$.
  For this consider three trees $t_{0}, t_{1}, t_{b}$ where every letter in
  $t_{i}$ is $b$ except for $t_{i}(i) = a$ for $i = 0,1$ and $t_{b}$ only
  contains $b$. Assume there is a choiceless \ac{WDTA} $\mathcal{A}$ with an
  almost-sure acceptance of a Muller condition to accept
  $\mathcal{L}_{\exists a}$. The unique runs of $A$ on $t_{0},t_{1}, t_{b}$ do
  start with the same distribution in the root since
  $t_{0}(\epsilon) = t_{1}(\epsilon) = t_{b}(\epsilon) = b$ and $\mathcal{A}$
  is choiceless and the runs on $t_{0}$ and $t_{1}$ are accepting.
  Furthermore, we can savely assume that at least on state in each direction
  does carry weight. Because if w.l.o.g. no state in direction $0$ carries any
  weight the measure on all accepted runs for the run on $t_{0}$ and $t_{b}$ is
  equal. Thus, either $t_{0}$ is not accepted or $t_{b}$ is accepted. Both
  cases contradict the assumption that $\mathcal{A}$ precisely accepts
  $\mathcal{L}_{\exists a}$. Additionally, for every state that carries weight
  in the first level of the run of $\mathcal{A}$ on either $t_{0}$ or $t_{1}$
  does need to have a almost-sure measure on its accepted paths. But those
  states on the left side produce for $t_{1}$ and $t_{b}$ the same paths, while
  the states on the right side produce for $t_{0}$ and $t_{b}$ produce the same
  paths. These paths are almost-surely accepted for $t_{0}$ (resp. $t_{1}$) and
  therefore also for $t_{b}$ rendering the unique run on $t_{b}$ almost-surely
  accepted yielding the desired contradiction and concluding the proof.
\end{proof}

\subsection{A forrest of languages}
The different structural properties of \acp{WDTA} introduce different language
classes. We explore in the following how these classes are related to each
other. First of all, we notice that determinism obviously is a restriction.
\begin{proposition}
  The class of languages recognizable with \acp{WDTA} almost-sure acceptance
  is a proper superset of languages recognizable with determinisitc \acp{WDTA}
  with almost-sure acceptance.
\end{proposition}
\begin{proof}
  For u.d. \acp{WDTA} with a common blueprint this follows from
  \cite[Proposition 10]{RandAutoInfTrees}.
  The general case is a little more elaborate but yields an interesting
  intuition: non-deterministic \acp{WDTA} allow for search of properties on
  one path while determinism entails a spread of weight and thus cannot
  recognize properties on one, finitly many or countably many paths if all
  paths are examined. \fxfatal{elaborate}
\end{proof}
It is a very interesting result that alternation in non-weighted tree automata
does not increase the general expressiveness (see \cite{SimAltTreeAuto}).
This result does unfortunately not translate unconstraint to the weighted case.
\begin{proposition}
  The class of languages recognizable with uni-directional \acp{WDTA} with
  Büchi condition is incomparabel with the class of languages recognizable with
  choiceless \acp{WDTA} with Büchi condition under almost-sure acceptance.
\end{proposition}
\begin{proof}
  It is known from \cite[Theorem 4 (b), (c)]{DecProblemsForProbAuto} that
  $\omega$-regular languages and languages recognizable by \acp{PBA} are
  incomparable. We consider the inverse of Theorem \ref{theorem:pbaequiv} for
  \acp{WDTA} over a singleton direction set. Let $D$ be a set with $\size{D}=1$
  and $\mathcal{D} = \tuple{Q, q_{0}, D, \Sigma, \Delta, F}$ a deterministic
  \ac{WDTA}, hence w.l.o.g. (under almost-sure acceptance we can complete
  automata with a non-accepting sink state)
  $\Delta(q,\sigma) = \set{G^{q}_{\sigma}}$. We can straightforwardly define an
  equivalent \ac{PBA} $\mathcal{P} = \tuple{Q, \Sigma, \delta, q_{0}}$ with
  $\delta(q, \sigma, p) = G^{q}_{\sigma}(p, d)$ for the one $d\in D$. Since the
  runtree of $\mathcal{P}$ coincides with the unique run of $\mathcal{D}$ on
  any $\alpha$ the equivalence is obvious. Let
  $\mathcal{U} = \tuple{P, p_{0}, D, \Sigma, \Delta', F'}$ be a uni-directional
  \ac{WDTA}. Since there is only one $d\in D$ and every transition in
  $\mathcal{U}$ is only allowed to put weight into one state per direction
  every run of $\mathcal{U}$ on any $\alpha$ can be reduced to one path with
  weight $1$. This path is either accepting or non-accepting and thus
  the class of accepted languages of those \ac{WDTA} is the class of
  $\omega$-regular languages. Remarkably, we can for any \ac{PBA} define an
  equivalent uni-directional \ac{WDTA} (for any transition from $q$ to $p$ in
  the word automaton introduce a transition in the tree automaton that puts all
  its weight from $q$ to $p$). The claimed incomparability translates
  immediately from the incomparability of the word automata.
\end{proof}
\begin{corollary}
  For Büchi conditions there are deterministic \acp{WDTA} that do not have an
  equivalent uni-directional \ac{WDTA} with any acceptance measure.
\end{corollary}
\begin{proof}
  In above construction the measure of the one path of a run in an
  uni-directional \ac{WDTA} is binary ($1$ if the path is accepting and $0$
  otherwise). Thus the acceptance measures coincide. For the \ac{PBA} the
  runtree is in bijection to the run of the \ac{WDTA} and
  \cite[Theorem 4]{RecOmeLangProbAuto} states that \acp{PBA} with positive
  measure are more expressive than $\omega$-regularity.
\end{proof}

\section{Depth vs. Width}
In \cite[Chapter 4]{RandAutoInfTrees} the concept of resolving non-determinism
by probability distributions (as suggested for \acp{PBA}) is explored in the
context of weighted tree automata. Thus, the automaton does not
\enquote{build} a run by choosing fitting transitions but every transition is
explored with a certain probability. We refer to this concept as \emph{Depth}
since it can be illustrated as a number of runs executed in parallel and
weighted accordingly to the probabilities of possible choices to build the run
(see Figure \ref{fig:parallelruns}). We argue that the introduced concept of
\enquote{alternation} for weighted tree automata actually captures this concept
by allowing for a certain \emph{Width} in runs, hence we can resolve
probabilities of transitions by moving states downwards in the runtree according
to the transitions with an adapted weighting. Since resolving non-determinism
probabilistically renders an automaton literally \enquote{choiceless} we expect
the corresponding equivalent \ac{WDTA} to indeed have the choiceless property.
Additionally, we restrict the transitions to obey a certain structure, i.e. we
enforce a property which we reffered to as uniform distribution for \acp{WDTA}.
This de-couples the probability of a movement through the individual runs and
the probability of the run itself which ensures that the definition is
well-founded. Also, since resolving non-determinism with probabilities in
\acp{PBA} yields interesting results this inclusion further strengthens the
relevance of \acp{WDTA}. \fxwarning{sounds as if we are unsure about the
relevance in the first place}

\subsection{Probabilistic Weighted Automata}
In order to explore the setting of resolving non-deterministic choices by
probability distributions we introduce analogously to
\cite[Definition 4.1.1]{RandAutoInfTrees} the class of \ac{PWA} with
\begin{definition}[Probabilistic Weighted Automata]
  Fix a finite alphabet $\Sigma$, a finite set of directions $D$ and a finite
  set of states $Q$. We fix a probability distribution
  $B:D\rightarrow\interval{0,1}$ which fixes the movement through any run. The
  transitions are captured by a finite non-empty set of functions
  $\set{\delta_{1},\dots,\delta_{n}}$ with $\delta_{i}:D\rightarrow Q$ for
  $1\leq i\leq n$. A function $\Delta$ is used to map every tuple of any
  $q\in Q$ and $\sigma\in\Sigma$ to a probability distribution of the
  associated set of transitions $\set{\delta_{1},\dots,\delta_{n}}$.
  Furthermore, we introduce an $\omega$-regular target set
  $T\subseteq Q^{\omega}$ and pick one $q_{0}\in Q$ to combine all these
  elements to a \ac{PWA}
  \begin{equation*}
    \mathcal{A} = \tuple{Q, q_{0}, D, \Sigma, B, \Delta, T}.
  \end{equation*}
\end{definition}
One run of such an automaton $\mathcal{A}$ on a tree $t:D\rightarrow\Sigma$ is
differently defined than runs for \acp{WDTA} since the run does not need to
encode the weighting of paths through the run. Thus, we define one run
$r:D^{*}\rightarrow Q$ such that for every $w\in D^{*}$ there exists one
$\delta\in\supp(\Delta(r(w), t(w)))$ with $r(w\cdot d) = \delta(d)$ for
all $d\in D$ to which we refer to as $\delta_{r(w)}$ and additionally,
$r(\epsilon) = q_{0}$. As seen before, the distribution $B$ induces a measure
$\mu_{B}$ on the $\sigma$-algebra $\mathcal{F}_{\mathcal{A}}$ which is
generated by the cylinders of all $w\in D^{*}$. The set of accepting paths are
those paths which associated state sequence satisfy the target $T$:
$\Acc(r)=\set{\alpha\in D^{\omega}\mid r(\alpha)\in T}$. Semantically, $r$ is
considered almost-surely accepting if $\mu_{B}(\Acc(r)) = 1$.

Additionally, to examine the probabilities induced by $\Delta$ we introduce a
$\sigma$-algebra which is generated by partial runs, i.e. finite beginnings of
runs. Therefore, we define a finite tree as a prefix-closed subset of finite
words over directions, hence
\begin{definition}[Prefix-Tree]
  For a finite set of directions $D$ we call a finite $T\subseteq D^{*}$ a
  prefix-tree if for every $w\in T$ and every finite prefix $v$ of $w$ holds
  $v\in T$. Additionally, we call a prefix-tree $T$ \emph{proper} if for any
  $w\in T$ exists $d\in D$ such that $w\cdot d\in T$ also $w\cdot d'\in T$ for
  all other $d'\in D$ holds. We define the \enquote{inner} nodes of $T$ as
  those notes that do have an extension in $T$ as
  $\inner(T) = \set{w\in T\mid w\cdot d\in T\text{ for any }d\in D}$.
\end{definition}
For a \ac{PWA} $\mathcal{A}$ and a tree $t:D\rightarrow\Sigma$ 
we can - depending on $t$ - define all partial runs of $\mathcal{A}$ on $t$ as
$r:T\rightarrow Q$ for any proper prefix-tree $T$. This partial run has to be
consistent with $t$. Considering such a partial run $r$ we can define the set
of runs $r'$ of $\mathcal{A}$ on $t$ such that these runs agree on $T$ with
$r$, i.e. for all $w\in T$ holds $r(w) = r'(w)$, as $\compRuns(r)$.
Analogously, to the concept of cylinders over a set we can capture a
$\sigma$-algebra $\mathcal{R}_{\mathcal{A}}$ over runs by using the sets
$\compRuns(r)$ for every partial run $r$ as generating sets. For any partial
run $r$ over the prefix-tree $T$ (and thus for the set of compatible runs with
$r$) there is an associated probability with
\begin{equation*}
  \mu_{t}(\compRuns(r)) = \prod\limits_{w\in\inner(T)}
  \Delta(r(w),t(w))(\delta_{r(w)}).
\end{equation*}
Again, as for \acp{WDTA}, this yields a pre-measure on
$\mathcal{R}_{\mathcal{A}}$ which can be uniquely extended to a measure by
\cite[Theorem 5.4]{Bauer}, hence we obtain a measurable space
$\tuple{\mathcal{R}_{\mathcal{A}}, \mu_{t}}$. In terms of this measurable space
we define the acceptance condition. In \cite{RandAutoInfTrees} different
notions of acceptance are discussed, e.g.
\begin{enumerate}
  \item without regard for the weighting induced by $B$ the semantic can be
    defined by the measure of $\mu_{t}$ of those runs that satisfy a Büchi
    condition \cite[analogously to Proposition 38]{RandAutoInfTrees},
  \item regarding the weighting of the generators multiple combinations of
    positive or almost-sure acceptance for the individual runs and positive and
    almost-sure acceptance for those runs deemed accepting.
\end{enumerate}
We want to focus on the acceptance condition of almost-sure property of those
individual runs that are almost-surely accepting. Thus, we considere a tree
accepted if almost-all runs do satisfy the almost-sure acceptance of the
objective $T$, i.e. $\mu_{t}(\set{r\in\Runs\mid\mu_{B}(\Acc(r)) = 1}) = 1$.
Hence, we fix the set of all viable runs on $t$ as $\Runs$ and
the set of all possible paths in a run $\Paths = D^{\omega}$ and define for an
automaton $\mathcal{A}$ the following function within the product
$\sigma$-algebra of all runs and paths
\begin{equation*}
  f_{\mathcal{A}}:\Runs\times\Paths\rightarrow\interval{0,1}
  \text{ with }
  f_{\mathcal{A}}(r, p) = \begin{cases}
    1&\text{ if }r(p)\text{ satisfies }T\\
    0&\text{ otherwise.}
  \end{cases}
\end{equation*}
In the following we show the integrability of the function $f$ and with this
integrability we argue that the definition of the semantic of the \ac{PWA}
$\mathcal{A}$ is well-founded.
\begin{proposition}
  $f_{\mathcal{A}}$ is a measureable function w.r.t. the $\sigma$-algebra
  $\mathcal{R}_{\mathcal{A}}\otimes\mathcal{F}_{\mathcal{A}}$. And thus,
  integrable in $\tuple{\mathcal{R}_{\mathcal{A}},\mu_{t}}\otimes
  \tuple{\mathcal{F}_{\mathcal{A}},\mu_{B}}$.
\end{proposition}
\begin{proof}
  In order to show the measureability of $f_{\mathcal{A}}$ it suffices to show
  the measureability of $f_{\mathcal{A}}^{-1} =
  \set{\tuple{r,p}\in\Runs\times\Paths\mid r(p)\in T}$ which we do in the
  following analogously to \cite[Lemma 36]{RandAutoInfTrees}. And since more
  complex conditions can be expressed as Boolean combinations of Büchi
  conditions (as used in the proof of e.g. Lemma
  \ref{lem:measureabilityAcceptance}) we examine only a Büchi condition and
  infer the result for other $\omega$-regular $T$. By
  \cite[Theorem 22.1]{Bauer} is the product $\sigma$-algebra
  $\mathcal{R}_{\mathcal{A}}\otimes\mathcal{F}_{\mathcal{A}}$ generated by the
  sets $\compRuns(r)\times\cyl(p)$ for all proper partial runs $r$ and
  $p\in D^{*}$. To ease the following argument we restrict our attention to
  partial runs that are \enquote{balanced}(as suggested by
  \cite[Remark 35]{RandAutoInfTrees}, i.e. all paths have the same length.
  That this restriction is purely argumentativ is ensured by
  \begin{lemma}
    The $\sigma$-algebra that is generated by balanced proper partial runs and
    the $\sigma$-algebra generated by all proper partial runs are identical.
  \end{lemma}
  \begin{proof}
    Easily to see is that the set of all proper partial runs contain all
    balanced partial runs which ensures that the algebra generated by proper
    partial runs is at most more complex than the algebra generated by balanced
    proper partial runs. On the other hand, considering one proper partial run
    $r:T\rightarrow Q$. Fix $n = \max{\size{w}:w\in T}$. Pick any $v\in T$ with
    $\size{v}<n$ and $v\cdot d\notin T$ for all $d\in D$. If no such $v$ exists
    $T$ is balanced. If not, it holds that there are only finitely many
    successor functions $\set{\delta_{1},\dots,\delta_{n}}$ associated with the
    state $r(v)$ and the letter $t(v)$. For every $1\leq i\leq n$ construct run
    $r_{i}$ with $r_{i}(u) = r(u)$ for all $u\in T$ and
    $r_{i}(v\cdot d) = \delta(d)$ for all $d\in D$. The domain of every $r_{i}$
    is again a proper partial run and repeating this construction yields
    finitely many balanced proper partial runs $\set{r_{1},\dots, r_{m}}$ that
    agree with $r$ on $T$ and are consistent with $t$. For any $w\in D^{*}$ we
    get that the union of all sets $\compRuns(r_{i})\times\cyl(w)$ for
    $1\leq i\leq n$ coincides with $\compRuns(r)\cyl(w)$ and thus,
    the $\sigma$-algebra induced by balanced proper partial runs contains
    all generating set of the $\sigma$-algebra induced by proper partial runs
    rendering both algebras identical.
  \end{proof}
  As noted above we examine in the following w.l.o.g. a Büchi condition for $T$
  induced by $F\subseteq Q$. This proof re-iterates concepts of the proof for
  Lemma \ref{lem:measureabilityAcceptance} in a more complex setting. For any
  $p\in D^{*}$ fix the set of all $R_{p}\subseteq\Runs\times\Paths$ such that
  $\tuple{r,\rho}\in R_{p}$ if and only if $p\sqsubset\rho$ and for all
  $p\sqsubset u\sqsubset\rho$ holds $r(u)\notin F$. The complement of
  $\cup_{w\in D^{*}}R_{w}$ describes $f_{\mathcal{A}}^{-1}$, since every
  element $\tuple{r,p}$ in the complement of $\cup_{w\in D^{*}}R_{w}$ is not
  part of any $R_{w}$. Obviously, it is not part of those $R_{w}$ for which
  $w\not\sqsubset p$ and for those $w\sqsubset p$ all $w$ do have a prolongation
  $v$ with $w\sqsubset v\sqsubset p$ with $r(v)\in F$. If on the other hand
  $\tuple{r,p}\in f_{\mathcal{A}}^{-1}$ then $p$ is a path in $r$ which
  satisfies the Büchi condition and thus for every prefix $w\sqsubset p$ there
  is a later point $v$ with $w\sqsubset v\sqsubset p$ with $r(v)\in F$ which
  makes $\tuple{r,p}$ not part of any $R_{w}$.

  It remains to show that $R_{w}$ are measureable for every $w\in D^{*}$. Fix
  one such $w$ and for every $n>\size{w}$ gather for all balanced proper
  partial runs $r$ with depth $n$ and words $p\in D^{n}$ with $w\sqsubset p$
  and $r(p)\notin F$. The countable union of all such $\compRuns(r)$ and
  $\cyl(p)$ is collected in $C_{n}$ and we claim that
  $R_{u} = \cap_{\size{u}<n}C_{n}$ by the following argument: for any
  $\tuple{r,p}\in R_{u}$ every prolongation of $u$ that stays on $p$ does not
  visit $F$ and hence for every these prolongations $v$ we know that
  $\tuple{r,p}$ is part of $C_{\size{v}}$ and hence
  $\tuple{r,p}\in\cap_{\size{u}<n}C_{n}$. On the other hand assume
  $\tuple{r,p}\in\cap_{\size{u}<n}C_{n}$, thus for every viable prolongation
  of length $k$ for $u$ $C_{k}$ witnesses the absence of an occurence of $F$.
  
  This renders $f_{\mathcal{A}}^{-1}$ measureable and as indicator function for
  a measureable set integrateable in
  $\tuple{\mathcal{R}_{\mathcal{A}},\mu_{t}}\otimes
  \tuple{\mathcal{F}_{\mathcal{A}},\mu_{B}}$.
\end{proof}
Given the function $f_{\mathcal{A}}$ and its measureability allows to define
a function
\begin{equation*}
  g_{\mathcal{A}}:\Runs\rightarrow\interval{0,1}
  \text{ with }
  g(r) = \mu_{t}(\set{p\in\Paths\mid r(p)\in T}).
\end{equation*}
This function $g_{\mathcal{A}}$ is measureable in $\mathcal{R}_{\mathcal{A}}$
since $g_{\mathcal{A}}^{-1}(\set{1})$ is measureable by \cite[Lemma 23.1]{Bauer}
and again as an indicator function of a measureable set integrable in
$\tuple{\mathcal{R}_{\mathcal{A}},\mu_{t}}$ which renders the measure
$\mu_{t}(\set{r\in\Runs\mid\mu_{B}(\Acc(r)) = 1 })$ well-defined and hence the
acceptance condition of $\mathcal{A}$. This, concludingly, allows us to deduce
\begin{proposition}
  For a \ac{PWA} $\mathcal{A}$ and a tree $t$ holds
  \begin{equation*}
    \mathcal{A}\text{ accepts }t
    \text{ iff }
    \int f_{\mathcal{A}} d\mu_{t}\otimes\mu_{B} = 1.
  \end{equation*}
  \label{prop:pwabyf}
\end{proposition}
\begin{proof}
  The proof consist of a series of equivalences but first of all we introduce
  a helpful lemma:
  \begin{lemma}
    \cite[Lemma 40]{RandAutoInfTrees} Let $\tuple{\Omega,\mathcal{F},\mu}$ be
    a probability space and $f$ a measureable function from $\Omega$ to
    $\interval{0,1}$, then $\int_{\Omega}f d\mu = 1$ if and only if 
    $\mu(f^{-1}(\set{1})) = 1$.
    \label{lem:almosteverywhere}
  \end{lemma}
  Thus, we can derive the following equivalences:
  \begin{align*}
    \mathcal{A}\text{ accepts }t
     &\text{ iff }\mu_{t}(g_{\mathcal{A}}^{-1}(\set{1}) = 1&\\
    &\text{ iff }\int_{\Runs} g d\mu_{t} = 1
     &\text{Lemma \ref{lem:almosteverywhere}}\\
    &\text{ iff }\int_{\Runs}\int_{\Paths} f_{\mathcal{A}} d\mu_{B} d\mu_{t}
     &\text{Definition of }g\\
    &\text{ iff }\int_{\Runs\times\Paths}f_{\mathcal{A}}d\mu_{B}\otimes\mu_{t}.
     &\text{Tonelli's Theorem \cite[Theorem 23.6]{Bauer}}
  \end{align*}
\end{proof}
We proceed by defining an equivalent \ac{WDTA} for a given \ac{PWA}, yielding
\begin{theorem}[PWA inclusion]
  For any \ac{PWA} $\mathcal{A}$ exists a choiceless \ac{WDTA} $\mathcal{B}$
  such that the languages of $\mathcal{A}$ and $\mathcal{B}$ are equivalent.
\end{theorem}
\begin{proof}
  First of all, we define
  $P_{r} = \set{p\in\Paths\mid r(p) \text{ satisfies } T_{\mathcal{A}}}$ which
  is measureable by \cite[Lemma 23.1]{Bauer} because it is the $\Paths$-cut of
  $f_{\mathcal{A}}^{-1}(\set{1})$ and this yields the following equivalence
  \begin{equation*}
    \int f_{\mathcal{A}} d\mu_{t}\otimes\mu_{B} =
    \int\limits_{r\in\Runs}\int\limits_{p\in\Paths}\chi_{P_{r}}(p)
    d\mu_{B} d\mu_{t}.
  \end{equation*}
  We provide the definition of $\mathcal{B}$ as
  \begin{definition}
    For a given \ac{PWA}
    $\mathcal{A} = \tuple{Q, q_{0}, D, \Sigma, B, \Delta, T}$ define a \ac{WDTA}
    $\mathcal{B} = \tuple{Q, q_{0}, D, \Sigma, \Delta', T}$ with
    \begin{equation*}
      \Delta'(q,\sigma) = \set{G_{\sigma}^{q}}
      \text{ and }
      G_{\sigma}^{q}(p, d) = B(d)\cdot\sum^{\delta\in\supp(\Delta(q,\sigma))}_{
      \delta(d) = p}\Delta(\delta).
    \end{equation*} 
  \end{definition}
  And note that indeed $\mathcal{B}$ is choiceless. Further, we examine the
  unique run $r$ of $\mathcal{B}$ on $t$ and the measure $\mu_{r}$ it defines
  for the $\sigma$-algebra which is generated by all cylinders over words in
  $\tuple{Q\times D}$. This measure can be expressed as follows:
  \begin{align*}
    \mu_{r}(\cyl(\tuple{q_{1},d_{1}}\dots\tuple{q_{n},d_{n}}))
    = &\prod\limits_{1\leq i<n} B(d_{i})\sum\limits^{
      \delta\in\supp(\Delta(q_{i},t(d_{1}\dots d_{i})))}_{\delta(d_{i+1}) =
      q_{i+1}}\Delta(\delta)\\
    = &\mu_{B}(\cyl(d_{1}\dots d_{n}))\cdot\prod\limits_{1\leq i<n}\sum\limits^{
      \delta\in\supp(\Delta(q_{i},t(d_{1}\dots d_{i})))}_{\delta(d_{i+1}) =
      q_{i+1}}\Delta(\delta)\\
    = &\mu_{B}(\cyl(d_{1}\dots d_{n}))\\
      &\cdot\mu_{t}(\set{r\in\Runs\mid\text{ for }1\leq i\leq n:r(d_{1}\dots d_{i}) = q_{i}})\\
    = &\int\limits_{r\in\Runs}\int\limits_{p\in\cyl(d_{1}\dots d_{n})}
        \chi_{\cyl(q_{1}\dots q_{n})}(r(p))d\mu_{B} d\mu_{t}.
  \end{align*}
  Using this expression it follows that
  \begin{equation*}
    \mu_{r}(\set{\tuple{q_{1},d_{1}}\tuple{q_{2},d_{2}}\dots\in\tuple{Q\times D}^{\omega}\mid q_{0}q_{1}\dots\in T})
    =\int\limits_{r\in\Runs}\int\limits_{p\in\Paths}\chi_{P_{r}}(p)d\mu_{B} d\mu_{t}.
  \end{equation*}
  Which concludes that $\mathcal{A}$ accepts $t$ if and only if $\mathcal{B}$
  accepts $t$.
\end{proof}
