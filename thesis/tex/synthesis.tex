\chapter{Synthesis}
\label{chapter:synthesis}
The synthesis problem is formulated in \cite{Church} as the question if for a 
given logical formula, we call this specification, we can derive an algorithm
which behavior is \enquote{good} in the sense of the formula. We formalize this
question in the following
\begin{definition}[Synthesis Problem]
  Given a logical specification  $\phi(\cdot, \cdot)$ over inputs and 
  outputs from $I^{\omega}$ and $J^{\omega}$ respectively. The synthesis 
  problem requires to compute for any such $\phi$ an algorithm 
  $S:I^{+}\rightarrow J$ such that for every 
  $\alpha_{1}\alpha_{2}\dots\in I^{\omega}$ and every 
  $S(\alpha) = S(\alpha_{1})S(\alpha_{1}\alpha_{2})\dots$ satisfies 
  $\phi(I, S(I))$ or prove that such an $S$ cannot exist (cp. the 
  illustration in Figure \ref{fig:synthesis}).
\end{definition}
\begin{drawing}
  \caption{Illustration of the synthesis question. The aim is to provide an 
  algorithm which \enquote{synthesises} for any specification a strategy or 
  proves that there cannot exist a strategy that satisfies the specification.}
  \label{fig:synthesis}
  \begin{center}
    \includegraphics{tikz/synthesis.pdf}
  \end{center}
\end{drawing}
Naturally, the complexity of this problem is tightly related to the 
expressibility of $\phi$. The comprehensive demand of this question, namely
to generate for all inputs a \enquote{good} output, allows for a
game-theoretic formulation. As suggested in \cite{SeqCondStrat} we can consider
the environment as antagonistic and formulate the synthesis question in terms
of strategies, i.e. one player generates inputs while another player generates
outputs. We call these players \inputp{} and \outputp{} respectively. The game
unfolds by \inputp{} choosing sequentially inputs $i_{1}i_{2}\dots$ and 
\outputp{} reacting by $j_{1}j_{2}\dots$. Thus, a play
\begin{center}
  \begin{tabular}{cccc}
    $i_{1}$ & $i_{2}$ & $i_{3}$ & \dots\\
    $j_{1}$ & $j_{2}$ & $j_{3}$ & \dots
  \end{tabular}
\end{center}
forms and \outputp{} wins if and only if 
$\phi(i_{1}i_{2}\dots,j_{1}j_{2}\dots)$ evaluates to true. Strategies of 
\outputp{} are usually described as functions $f:I^{+}\rightarrow J$ such that
\outputp{} plays at position $n>0$ the output-symbol 
$f(i_{1}\dots i_{n}) = j_{n}$. In this sense we are interested in winning 
strategies of \outputp{}. Following, we present known synthesis results 
for those $\phi$ which allow to capture the associated relation as a 
$\omega$-regular language. Subsequently, we pivot towards probabilistic 
environments and review an approach to synthesis algorithms there which are not 
necessarily surely correct but almost-surely satisfy a specification $\phi$. 
At last, we consider probabilistic environments which are modelled as
\acp{POMDP}.

\section{Antagonisitic Environments}
In the following we consider an $\omega$-regular class of specifications 
$\phi$ for inputs $I$ and outputs $J$, namely those such that we can define a 
$\omega$-regular language $\mathcal{L}_{\phi}\subseteq 
\tuple{J\times I}^{\omega}$ with
\begin{equation}
  \tuple{j_{0}, i_{0}}\tuple{j_{1}, i_{1}}\dots\in\mathcal{L}_{\phi}
  \text{ iff }
  \phi(i_{0}i_{1}\dots, j_{1}j_{2}\dots)\text{ is true.}
  \label{eq:omegaregularphi}
\end{equation}
Observably, the output symbol $j_{0}$ is irrelevant but included to ease the 
technicalities of the following argument. With the well researched theory of
tree automata the associated synthesis problem for $\omega$-regular 
specifications can be solved rather transparently. In fact it is one of the 
initial motivations to study tree automata \cite{AutoInfObj}. The idea is to 
use trees to model the interaction between input and output symbols. The 
directions of a tree model inputs while the symbols in the tree represent 
outputs. Similar to the arguments of the proof of Theorem 
\ref{thm:POMDPequivWDTA} a tree can therefore be understood as strategy and we 
want to design a \ac{PTA} such that a tree is only accepted if all paths are 
part of $\mathcal{L}_{\phi}$. This can be easily modelled 
(cp. \cite[Lemma 15]{AutoInfObj}) with
\begin{definition}[Synthesis \ac{PTA}]
  For a given \ac{DPA}
  \begin{equation*}
    \mathcal{P} = \tuple{Q, q_{0}, J\times I, \delta, \parity}
  \end{equation*}
  we define a \ac{PTA}
  \begin{equation*}
    \mathcal{A} = \tuple{Q, q_{0}, I, J, \Delta, \parity}
  \end{equation*}
  where $\Delta$ contains transtitions $\tuple{q, j, (p_{i})_{i\in I}}$ with
  $p_{i} = \delta(q, \tuple{j, i})$.
\end{definition}
Notably, $\mathcal{A}$ executes $\mathcal{P}$ on every path and therefore, if 
we choose $\mathcal{P}$ as the \ac{DPA} which precisely accepts 
$\mathcal{L}_{\phi}$, we deduce that $\mathcal{A}$ accepts only those trees 
that satisfy $\phi$ on all paths. This implies that $\mathcal{A}$ accepts those
strategies $t$ which satisfy $\phi$. Hence, constructing (see above) and 
deciding the emptiness (see Theorem \ref{thm:emptinessPTA}) for $\mathcal{A}$ 
yields the desired synthesis algorithm for $\omega$-regular specifications 
$\phi$ and gives
\begin{theorem}
  \cite[Theorem 21, Theorem 22]{AutoInfObj}
  The synthesis problem for $\omega$-regular specifications $\phi$ can be 
  decided.

  If a strategy exists and $\phi$ is captured by a \ac{DPA} 
  \begin{equation*}
    \mathcal{P} = \tuple{Q, q_{0}, J\times I, \delta, \parity}
  \end{equation*}
  then we can compute such a strategy in time in 
  $\mathcal{O}(\size{\parity(Q)}\cdot\size{Q\times Q}\cdot\tuple{
    \frac{\size{Q}}{d}}^{d})$ with 
  $d = \lfloor \frac{\size{\parity(Q)}}{2} \rfloor$.
\end{theorem}
This approach suits the game-theoretic interpretation of the synthesis problem
well. Consider the associated emptiness-game to the defined \ac{PTA} 
$\mathcal{A}$. Observable, $\mathcal{A}$ shows deterministic behavior, hence 
we can reduce \eve{}'s strategy to the decision which letter to choose rather
than choosing a transition. Also, \adam{}'s role is always captured by choosing
a direction the game moves to. Therefore, \eve{}'s and \adam{}'s strategies 
specify the behavior of \outputp{} and \inputp{} respectively while the 
\ac{DPA} that is associated with $\phi$ is executed in parallel.

In the following we want to consider specifications $\phi$ which are not 
$\omega$-regular but defineable by almost-surely accepting \acp{PBA}. Thus, in
analogy to the formulation (\ref{eq:omegaregularphi}) above we consider $\phi$ 
such that there is a \ac{PBA} $\mathcal{P}$ which almost-surely accepts the 
language $\mathcal{L}_{\mathcal{P}}$ with
\begin{equation}
  \tuple{j_{0}, i_{0}}\tuple{j_{1}, i_{1}}\dots\in\mathcal{L}_{\mathcal{P}}
  \text{ iff }
  \phi(i_{0}i_{1}\dots, j_{1}j_{2}\dots)\text{ is true.}
  \label{eq:pbaregularphi}
\end{equation}
The approach to this problem is formalized by introducing a new class of graph
games, called \acp{POSG} (cp. \cite{POSG, PureStratPOSG}). Reconsidering the 
behavior of \acp{POMDP} we can capture their semantic as a game between two 
players on the underlying graph of states and edges $\tuple{s_{1}, s_{2}}$ 
which are induced by non-zero probabilities for the movement from $s_{1}$ to 
$s_{2}$ for some action of \eve{} as follows: at any point she provides an 
action and the opponent chooses one of the associated edges. \eve{}
acts \enquote{deterministically} in the sense that for a certain history 
one specific action $a$ is played while the opponent plays probabilistically 
(as defined by $\tau_{a}$). \acp{POSG} expand on this notion by introducing a 
third player (again called \adam{}). At every position both players 
independently and simultaniously choose an action and then the third player 
plays by choosing a successor state probabilistically. Again we allow for 
restricted observations for \eve{} and \adam{} and formalize these notions 
analogously to \acp{POMDP} but with two players 
participating in the choices at every state:
\begin{definition}[\acl{POSG}]
  A \ac{POSG}-arena $G$ is defined by a set of states $S$ (with an 
  inital state $s_{0}\in S$), actions for \eve{} and \adam{} as $E$ and $A$ 
  respectively, transition probabilities $\tuple{\tau_{e,a}}_{e\in E, a\in A}$ 
  and equivalence classes $\sim_{E}$ and $\sim_{A}$ restricting the 
  observations of \eve{} and \adam{} respectively. We obtain
  \begin{equation*}
    G = \tuple{S, s_{0}, E, A, \tuple{\tau_{e,a}}_{e\in E, a\in A}, 
    \sim_{E}, \sim_{A}}
  \end{equation*}
  with
  \begin{equation*}
    \tau_{e,a}:S\times S\rightarrow\interval{0,1} \text{ s. t. }
    \tau_{e,a}(s, \cdot)\in\mathcal{D}(S)\text{ for all }a\in A, e\in E.
  \end{equation*}
  A strategy for \eve{} (\adam{}) is defined as 
  $f:\interval{S}_{\sim_{E}}^{*}\rightarrow E$ 
  ($g:\interval{S}_{\sim_{A}}^{*}\rightarrow A$). For any such pair of 
  strategies $f$ and $g$ we obtain a probability space
  \begin{equation*}
    \tuple{S^{\omega}, \mathcal{B}(S), \mu_{f, g}}.
  \end{equation*}
  A \ac{POSG} is defined by an arena $G$ and an associated language
  $\Acc\subseteq S^{\omega}$ forming $\mathcal{G} = \tuple{G, \Acc}$. Notably,
  $\mathcal{G}$ is a zero-sum game, i.e. \eve{} tries to obtain a play in 
  $\Acc$ while \adam{} tries to force plays in $S^{\omega}\setminus\Acc$.
\end{definition}
For any such $\mathcal{G} = \tuple{
S, s_{0}, E, A, \tuple{\tau_{e,a}}_{e\in E, a\in A}, \sim_{E}, \sim_{A}, \Acc}$ 
we can consider various goals for \eve{}, defined by different $\Acc$ and
positive or almost-sure satisfaction. In similar sense as for graph games we
consider a strategy $f$ for \eve{} almost-surely (postively) winning if for all
strategies $g$ of \adam{} we have $\mu_{f,g}(\Acc) = 1$ 
($\mu_{f,g}(\Acc) > 0$). Note that $\Acc$ has to be Borel to ensure 
well-definedness but we consider again $\Acc$ defined in finite means by 
BÃ¼chi-, Parity-, Rabin- or Muller-conditions for which this already is 
established. The natural initial observation that \adam{}'s role can be reduced 
to oblivion by only granting him a single action allows to capture the notions
of \acp{POMDP} which entails strong restrictions regarding algorithmic 
approaches, namely we obtain
\begin{corollary}
  \cite{PureStratPOSG, POSG}
  For a given \ac{POSG} $\mathcal{G} = \tuple{G, \Acc}$ the following problems
  are undecideable:
  \begin{itemize}
    \item Exists a positively winning strategy for \eve{} if $\Acc$ is defined 
      as BÃ¼chi-, Parity-, Rabin- or Muller-condition?
    \item Exists an almost-surely winning strategy for \eve{} if $\Acc$ is
      defined as Parity-, Rabin- or Muller-condition?
  \end{itemize}
\end{corollary}
\begin{proof}
  These are immediate consequences of the negligibility (not in the sense of
  measurability theory but in the game theoretic sense) of \adam{}'s actions
  and Theorem \ref{thm:emptinesspospba} (or the respective Corollary 
  \ref{cor:posstratpomdp}).
\end{proof}
Due to these harsh restrictions we focus in the following on almost-surely 
winning strategies for \eve{} in \ac{POSG} with BÃ¼chi-conditions. Additionally,
we only consider \acp{POSG} where \eve{} and \adam{} are 
\emph{equally informed}, i.e. $\sim_{E} = \sim_{A}$. In this case
we obtain the possibility to compute these strategies for \eve{} by
\begin{theorem}
  \cite[Theorem 6]{POSG} with the included reference to 
  \cite[Lemma 4]{DecProblemsForProbAuto} or \cite[Theorem 5.3]{PureStratPOSG}.
  It is possible to decide if there is an almost-surely winning strategy for 
  \eve{} in a \ac{POSG} $\mathcal{G} = \tuple{G, F}$ where $F$ is a 
  BÃ¼chi-condition and $\sim_{E} = \sim_{A}$.

  This decision procedure takes time doubly exponential in $\size{S}$.
  \label{thm:StratPOSG}
\end{theorem}
Since we rely for the time bound on arguments from \cite{PureStratPOSG} which 
is not published at the moment of completion of this thesis we present the 
necessary argumentation in Appendix \ref{app:POSG} to ensure its availability.
Nevertheless, we answer the synthesis question imposed by an almost-surely
accepting \ac{PBA} $\mathcal{P}$ positively for antagonistic environments. The 
idea is to define a \ac{POSG} in which both players only observe an 
input-output game while in the \enquote{background} the stoachastic process of
$\mathcal{P}$ operates and any play is eventually evaluated in terms of 
$\mathcal{P}$. Fix
\begin{equation*}
  \mathcal{P} = \tuple{Q, q_{0}, I\times J, \delta, F'}
\end{equation*}
and define
\begin{definition}[\ac{POSG} for $\mathcal{P}$]
  Set
  \begin{equation*}
    \mathcal{G}_{\mathcal{P}} = \tuple{I\times Q\times J\uplus\set{q_{0}}, J,
      I, \tuple{\tau_{j,i}}_{j\in J,i\in I}, \sim_{E}, \sim_{A}, F}
  \end{equation*}
  with
  \begin{equation*}
    \sim = \sim_{E} = \sim_{A} = \set{\tuple{\tuple{i, q, j}, 
    \tuple{i', q', j'}}\in \tuple{I\times Q\times J}^{2}\mid i = i', j = j'}
  \end{equation*}
  Moreover, we fix $F = I\times F'\times J$ and
  \begin{equation*}
    \tau_{j',i'}(\tuple{i, q, j}, \tuple{o, p, u}) = \begin{cases}
      \delta(q, \tuple{i', j'}, p)&\text{if }o = i', u = j',\\
      0&\text{otherwise},
    \end{cases}
  \end{equation*}
  where $q_{0}$ is treated as $\tuple{i, q_{0}, j}$ for any $i\in I, j\in J$.
\end{definition}
Here \eve{} corresponds with \outputp{} while \adam{} plays the role of 
\inputp{}. One central observation is that regarding the observations of \eve{} 
and \adam{} $\mathcal{G}_{\mathcal{P}}$ presents as input-output game. Setting 
$S = I\times Q\times J$ we observe by definition of $\sim$ that we can 
partition $S$ into $\set{\interval{\tuple{i, *, o}}_{\sim}:i\in I, o\in J}$ 
where $\interval{\tuple{i, *, o}}_{\sim}$ describes the equivalence class
$\set{\tuple{i, q, o}:q\in Q}$. By definition of all $\tau_{j,i}$ we obtain
$\supp(\tau_{j,i}(s, \cdot))\subseteq\interval{\tuple{i,*,j}}_{\sim}$. Hence,
every strategy for \eve{} (\adam{}) presents as function 
$f:\tuple{I\times J}^{*}\rightarrow J$ 
($g:\tuple{I\times J}^{*}\rightarrow I$). The only stochastic process in this
game is associated with the state component which is observed neither by 
\eve{} nor by \adam{}. This allows us to deduce that any pair of 
strategies $f$ and $g$ for \eve{} and \adam{} respectively induce one unique
word $\alpha_{f}^{g}\in\tuple{I\times J}^{\omega}$. Moreover, we can consider
a subset of $\mathcal{B}(I\times Q\times J)$ which is induced by 
$\alpha_{f}^{g} = \tuple{i_{1}, j_{1}}\tuple{i_{2}, j_{2}}\dots$. Namely, we 
define two sets
\begin{align*}
  F &= \bigcap_{k>0}\bigcup_{
    \substack{
      p_{1}\dots p_{k}\in Q^{k}\\
      u_{1}\dots u_{k}\in J^{k}
    }
  }\cyl(\tuple{i_{1}, p_{1}, u_{1}}\dots\tuple{i_{k}, p_{k}, u_{k}})\\
  G &= \bigcap_{k>0}\bigcup_{
    \substack{
      p_{1}\dots p_{k}\in Q^{k}\\
      u_{1}\dots u_{k}\in I^{k}
    }
  }\cyl(\tuple{u_{1}, p_{1}, j_{1}}\dots\tuple{u_{k}, p_{k}, j_{k}}).
\end{align*}
By definition $F$ and $G$ are those sets in $\mathcal{B}(I\times Q\times J)$ 
such that the $J$-component respectively the $I$-component agrees with 
$\alpha_{f}^{g}$. From these sets we obtain $F\cap G$.
By definition of $\tau_{i, j}$ for all $i\in I, j\in J$ we deduce that 
\begin{equation*}
  \mu_{f,g}(C) = 0\text{ for all }
  C\in \mathcal{B}(I\times Q\times J)\setminus\tuple{F\cap G}
\end{equation*}
because for any element $c\in C$ either the $I$- or $J$-component at some 
index $k$ deviates from the $I$- or $J$-component of $\alpha_{f}^{g}$ 
respectively. $\tau_{i_{k}, j_{k}}$ causes a probability of $0$ for $c$.
The central idea of this proof is formulated in
\begin{lemma}
  Applying element-wise a projection to the $Q$-component for every set in 
  $F\cap G$ yields a bijection to $\mathcal{B}(Q)$. Additionally, $\mu_{f,g}$ 
  coincides with $\mu_{\alpha_{f}^{g}}$ w.r.t. to this bijection.
  \label{lem:fginpba}
\end{lemma}
\begin{proof}
  First, we see that for every $p_{1}\dots p_{n}\in Q^{*}$ there are two 
  unique sequences $i_{1}\dots i_{n}$ and $j_{1}\dots j_{n}$ such that
  $\cyl(\tuple{i_{1}, q_{1}, j_{1}}\dots\tuple{i_{n}, q_{n}, j_{n}})\cap 
  F\cap G$ coincides with 
  $\cyl(p_{1}\dots p_{n})\times \alpha^{f}\times\alpha_{g}$ where 
  $\alpha^{f}$ and $\alpha_{g}$ are the projection of $\alpha^{f}_{g}$ to the
  $I$- and $J$-component respectively. Furthermore, we fix one 
  $p_{1}\dots p_{n}\in Q^{*}$. Observing
  \begin{align*}
    \mu_{f, g}&(
      \cyl(\tuple{i_{1}, p_{1}, j_{1}}\dots\tuple{i_{n}, p_{n}, j_{n}})\\
    &= \tau_{j_{1}, i_{1}}(q_{0}, \tuple{i_{1}, p_{1}, j_{1}})
      \prod\limits_{1\leq k < n}\tau_{j_{k}, i_{k}}(\tuple{i_{k}, p_{k}, 
        j_{k}},\tuple{i_{k+1}, p_{k+1}, j_{k+1}})\\
    &= \delta(q_{0}, \tuple{i_{1}, j_{1}}, p_{1})
      \prod\limits_{1\leq k < n}\delta(p_{k}, \tuple{i_{k+1}, j_{k+1}}, 
        p_{k+1})\\
    &= \mu_{\alpha_{f}^{g}}(\cyl(p_{1}\dots p_{n}))
  \end{align*}
  gives the desired equality by unique extension of $\mu_{f, g}$ and 
  $\mu_{\alpha_{f}^{g}}$.
\end{proof}

This leads us into characterising almost-surely winning strategies for \eve{} 
in $\mathcal{G}_{\mathcal{P}}$ in
\begin{lemma}
  A strategy $f$ in $\mathcal{G}_{\mathcal{P}}$ is almost-surely winning for
  \eve{} if and only if $f$ synthesises an algorithm for the associated 
  specification $\phi_{\mathcal{P}}$.
\end{lemma}
\begin{proof}
  Initially, we observe that for a fixed strategy $f$ every input
  $\beta = \beta_{0}\beta_{1}\dots\in I^{\omega}$ describes one strategy of 
  \adam{} by setting $g(u) = \beta_{\size{u}}$. On the other hand, we obtain
  for every possible strategy $g$ one sequence of inputs, namely the 
  $I$-projection of $\alpha_{f}^{g}$. Hence, the strategy space of \adam{}
  coincides with all possible input-sequences. 

  Therefore, given an almost-surely winning strategy $f$ for \eve{} we get 
  for every $g$ that $\mu_{f,g}(\Acc(F)) = 1$. By Lemma \ref{lem:fginpba} 
  this implies $\mu_{\alpha_{f}^{g}}(\Acc(F')) = 1$ and therefore 
  $\alpha_{f}^{g}$ is accepted by $\mathcal{P}$. This means that every 
  possible input-sequence $\beta$ is met with an output-sequence $\gamma$ 
  such that $\phi_{\mathcal{P}}(\beta, \gamma)$ evaluates to true.

  If on the other hand $f$ is not almost-surely for \eve{} there is a riposte 
  $g$ of \adam{} such that $\mu_{f,g}(\Acc(F)) < 1$ which analogously to the 
  reasoning above yields that $\mu_{\alpha_{f}^{g}}(\Acc(F')) < 1$ and 
  therefore the non-acceptance of $\alpha_{f}^{g}$ by $\mathcal{P}$. 
  This implies that \adam{} can generate an input-sequence $\beta$ such that 
  \eve{} generates the output-sequence $\gamma$ but 
  $\phi_{\mathcal{P}}(\beta, \gamma)$ evaluates to false.
\end{proof}

By this characterisation of winning strategies of \eve{} in 
$\mathcal{G}_{\mathcal{P}}$ we immediately may conclude
\begin{theorem}
  For any almost-surely accepting \ac{PBA} 
  \begin{equation*}
    \mathcal{P} = \tuple{Q, q_{0}, I\times J, \delta, F'}
  \end{equation*}
  the synthesis problem for the specification $\phi$ imposed by $\mathcal{P}$
  (as in (\ref{eq:pbaregularphi})) can be decided. If a strategy exists it can 
  be computed in time doubly exponential in 
  $\size{I}\cdot \size{Q}\cdot \size{J} + 1$.
\end{theorem}
\begin{proof}
  Using Theorem \ref{thm:StratPOSG} on $\mathcal{G}_{\mathcal{P}}$ gives the
  desired decision procedure.
\end{proof}
This result actually is intriguing in the sense that we consider a 
probabilistic specification but obtain a deterministic algorithm which surely 
shows desired behavior. We consider the following
\begin{example}
  Reconsider the \ac{PBA} examined in Example \ref{ex:almostsureacceptingpba}.
  We alter this \ac{PBA} slightly to obtain a specification which is defined in
  terms of an \ac{PBA} by replacing $a$-elements by those occurences where the
  ouput differs from the last input and $b$-elements by occurences where the 
  output mirrors the input. The initial output is dismissed (as suggested by
  (\ref{eq:pbaregularphi})). The resulting almost-surely accepting \ac{PBA} is
  illustrated in Figure \ref{fig:synthesispba}. And the derived input-output 
  game is shown in Figure \ref{fig:synthesispbagame}.
  \label{ex:pbasynthesis}
\end{example}
\begin{drawing}
  \caption{
    Specification-PBA for Example \ref{ex:pbasynthesis} (based on the PBA 
    depicted in Figure \ref{fig:almostsureacceptingpba}). Consider 
    $I = J =\set{0,1}$ where the superscript $i$ represents a storage for every
    state (realised by using two states, e.g. $q_{0}^{0}$ and $q_{0}^{1}$) 
    which holds the last read input symbol. The output symbols either mirrors 
    the stored symbol ($i$) or inverts it ($\overline{i}$), while the input 
    $i'$ is always stored within the state. Initially, the output is irrelevant 
    for the transition (indicated by $*$).
  }
  \label{fig:synthesispba}
  \begin{center}
    \includegraphics{tikz/synthesispba.pdf}
  \end{center}
\end{drawing}

\begin{drawing}
  \caption{
    Game graph for a POSG that resolves around the PBA defined in Figure 
    \ref{fig:synthesispba}. \adam{} and \eve{} only observe the layer they play
    in but never the $Q$-component. On the other hand, regarding the evaluation 
    every state with common $Q$-component is treated equally, hence the 
    underlaying PBA only observes the colors. The local storage of the states
    of the underlying PBA are dismissed since the stored input value already 
    uniquely identifies the \enquote{correct} state. Thus, technically we have
    e.g. $q_{0}^{0}$ and $q_{0}^{0}$ but the choice of \adam{} $e$ only allows
    movements to $q_{0}^{e}$, hence we dismissed unreachable states. Similarly,
    we removed the unreachabe $(i, q_{0}, j)$ for the \emph{original} $q_{0}$ 
    state (not for the $q_{0}^{0}, q_{0}^{1}$ states).
  }
  \label{fig:synthesispbagame}
  \begin{center}
    \includegraphics{tikz/synthesispbagame.pdf}
  \end{center}
\end{drawing}

\section{Stochastic Environments}
Another approach is introduced in \cite{SynProbEnv} by considering environments
which do not act antagonistically but probabilistically, i.e. we assume that 
inputs are generated by a probabilistic process. This motivates the concept of 
$\epsilon$-environments. For an $\epsilon > 0$ such an environment generates an
input $i$ with a certain probability which is at any time bound from below by 
$\epsilon$. The form of the strategy that is meant to be synthesised is given
as a $J$-labeled $I$-tansition-system $\mathcal{T}$ of the form
\begin{equation*}
  \mathcal{T} = \tuple{S, s_{0}, \tau, \ell}.
\end{equation*}
Here $S$ is a set of states, $s_{0}$ an inital state and 
$\tau:S\times I\rightarrow S$ describes a deterministic transition function and
$\ell:S\rightarrow J$ a labelling of $S$. Semantically, $\mathcal{T}$ starts in 
$s_{0}$ and reacts to an input $i$ by moving to $z = \tau(s,i)$ and outputting 
$\ell(z)$. Naturally, such a transition system $\mathcal{T}$ models a strategy 
$t:I^{+}\rightarrow J$ by constructing for every 
$u = u_{1}\dots u_{n}\in I^{+}$ the unique sequence 
$s_{0}s_{1}\dots s_{n}\in S^{+}$ such that $s_{i+1} = \tau(s_{i}, u_{i+1}$ for 
$0\leq i<n$ and returning $\ell(s_{n})$. As mentioned in the introduction of 
Section \ref{subsec:ata} alternating tree automata can be used to run on the 
unfolding of such transition systems. Assuming a $\omega$-regular specification 
$\phi$ we may obtain a \ac{DPA} 
$\mathcal{P} = \tuple{Q, q_{0}, \tuple{J\times I}, \delta, \parity}$ accepting 
$\mathcal{l}_{\phi}$. We can attach $\mathcal{P}$ onto a given transition 
system $\mathcal{T}$ in a straightforward manner to obtain a transition system 
with an associated Parity-condition (but dropping the labelling)
\begin{equation*}
  \mathcal{G}_{\mathcal{P}}^{\mathcal{T}} = \tuple{S\times Q, 
    \tuple{s_{0}, q_{0}}, \tau', \parity'}
\end{equation*}
where $\tau'(\tuple{s, q}, i) = \tuple{\tau(s, i), 
\delta(q, \tuple{\ell(s), i})}$ and $\parity'(\tuple{s, q}) = \parity(q)$. For
this transition system and an $\epsilon$-environment $\mathcal{E}$ we can 
identify structural properties in $\mathcal{G}_{\mathcal{P}}^{\mathcal{T}}$ to
determine whether $\mathcal{T}$ satisfies $\phi$ almost-surely respectively 
positively. This structural property is connected with \ac{SCC}. These are 
subsets of nodes $G$ such that there is a path between every two nodes 
$u,v\in G$ (cp. \cite{Tarjan}). Additionally, a leaf-\ac{SCC} is an \ac{SCC} 
$S$ such that there is no other \ac{SCC} reachable from any $v\in S$ (cp. 
\cite[Bottom-\ac{SCC}]{ComplexProbVerification}). Intuitively, it is unlikely 
to not eventually end up in one of these leaf-\acp{SCC} since there is 
infinitely often the possibility to take a non-zero probability to move into 
these and the Borel-Cantelli lemma (Theorem \ref{thm:BorelCantelli}) applies,
hence we state
\begin{lemma}
  \cite[Lemma 1]{SynProbEnv}
  An $J$-labeled $I$-transition-system $\mathcal{T}$ almost-surely (positively)
  satisfies a specification $\phi$ if and only if the highest priority in all
  (some) reachable leaf-\ac{SCC} of $\mathcal{G}_{\mathcal{P}}^{\mathcal{T}}$
  is even, where $\mathcal{P}$ is a \ac{DPA} accepting $\mathcal{L}_{\phi}$.
\end{lemma}
This structual property can be checked by a \ac{APTA}. This again yields by
checking the emptiness of the obtained \ac{APTA} an algorithm for the synthesis
problem of almost-sure (respectively positive) satisfaction of an 
$\omega$-regular $\phi$. Therefore we obtain
\begin{theorem}
  \cite[Theorem 1]{SynProbEnv}
  Given a \ac{DPA} $\mathcal{P}$ there is a \ac{APTA} 
  $\mathcal{A}_{\mathcal{P}}$ ($\mathcal{O}_{\mathcal{P}}$) such that 
  $\mathcal{A}_{\mathcal{P}}$ ($\mathcal{O}_{\mathcal{P}}$) accepts a 
  $J$-labeled $I$-transition-system $\mathcal{T}$ if and only 
  if\footnote{The original theorem only states the if-direction but the 
  corresponding proof deals with the only if-direction as well.} $\mathcal{T}$ 
  satisfies almost-surely (positively) $\mathcal{P}$.

  If $\mathcal{P}$ has $n$ states and $c$ parities then 
  $\mathcal{A}_{\mathcal{P}}$ and $\mathcal{O}_{\mathcal{P}}$ have at most
  $n\cdot\lceil 2 + \frac{c}{2}\rceil + 1$ states.
  \label{thm:probenvsynthesis}
\end{theorem}
\begin{proof}[Proof-Sketch]
  The main argument for this proof is that the search for the leaf-\acp{SCC} 
  can be understood as a two-player-game. One player plays for acceptance 
  (called \acceptor{}) while the other tries to spoil the correctness of the 
  transition system (called \spoiler{}). We describe the case of 
  $\mathcal{A}_{\mathcal{P}}$ but the case $\mathcal{O}_{\mathcal{P}}$ can be 
  constructed analogously by exchanging the player role in the first phase of 
  the game. The game for $\mathcal{T}$ in the $\mathcal{A}_{\mathcal{P}}$ 
  operates in three phases:
  \begin{enumerate}
    \item \spoiler{} chooses one leaf-\ac{SCC} $S$,
    \item \acceptor{} chooses one priority $p$ of a node in $S$,
    \item \spoiler{} tries to find a higher priority than $p$ in $S$.
  \end{enumerate}
  The unrollment of $\mathcal{T}$ yields an $I$-ary $J$-tree. The states of 
  $\mathcal{A}_{\mathcal{P}}$ encode the current state of $\mathcal{P}$ and if
  the game is in the first, second or third phase. If the game is in the third
  phase the chosen priority is also stored in the state. While operating in the
  first phase $\mathcal{A}_{\mathcal{P}}$ dispatches in all directions 
  first-phase states, representing possible choices of \spoiler{} and also in
  one direction a second-phase state; that is a second phase state which is 
  only dispatched into one direction, representing the choice of
  \acceptor{}. This second-phase state may at any point transform to a 
  third-phase state and store the (even) priority of the current 
  state of $\mathcal{P}$ in the state of $\mathcal{A}_{\mathcal{P}}$. This 
  third-phase state again dispatches in all directions and as soon as one state 
  with a higher parity than the stored one appears, moves to a 
  sink-error-state. The first-phase states are given a parity of $0$, the 
  second-phase states of $1$ and the third-phase states of $2$. This allows 
  that for all choices of \spoiler{} (which constantly reproduce themselves) 
  only those that proceed to the second phase actually matter or for the 
  third-phase only the occurence of a higher parity. Since the parity of the 
  second-phase states is odd it is enforced that \acceptor{} eventually chooses 
  one parity to store. Note the similarity to the proof of Proposition
  \ref{prop:atanegation} in formulating the desired winning strategy of one 
  player as actual choices which may use the non-determinism of the automaton 
  while the enemy explores all possible moves. 
\end{proof}
This allows us to solve the associated synthesis problem for $\omega$-regular
specifications and $\epsilon$-environments. By solving emptiness for a 
\acp{APTA}.

On the other hand we consider in the following environments that are modelled 
as \acp{MDP} or \acp{POMDP} and try to synthesis for a given specification a 
strategy to almost-surely or positively satisfy this specification. This 
approach is conceptually different to $\epsilon$-environments since concrete 
probabilities are given and also the interaction of the actor with the 
environment is explicitly incorporated but can be understood as approach to 
annotate the transitions of $\mathcal{T}$ with the probabilities of the 
environment. We formalize the synthesis question with (cp. 
\cite{QualAnaPOMDP,SimpleStochasticParityGames,ComplexProbVerification})
\begin{definition}
  Given a \ac{POMDP} 
  \begin{equation*}
    \mathcal{M} = \tuple{S, s_{0}, A, \tuple{\tau_{a}}_{a\in A}, \sim}
  \end{equation*}
  and a specification $\phi\subseteq S^{\omega}$ such that 
  $\phi\in\mathcal{B}(S)$. The qualitative synthesis problem 
  $\tuple{M, \varphi}$ demands the computation of a strategie 
  $s:\interval{S}_{\sim}^{*}\rightarrow A$ such that $\mu_{s}(\varphi) = 1$.
\end{definition}
We already used results formulated for this question, namely Theorem 
\ref{thm:pomdpstratsynthesis} and Theorem \ref{thm:mdpstratsynthesis}. Again,
we focus on $\omega$-regular $\phi$ (in this case $\phi$ is itself a language
and is not translated to one). Note that the formulation in Theorem 
\ref{thmpomdpstratsynthesis} and Theorem \ref{thm:mdpstratsynthesis} use 
acceptance conditions directly onto the states of the \ac{POMDP} and \ac{MDP}
respectively. Initially, we observe that this is not a real restriction:
In analogy to the constructions in
\cite{ComplexProbVerification,MDPandRegEvents} we deduce
\begin{lemma}
  For any \ac{POMDP} $\mathcal{M} = \tuple{S, s_{0}, A, 
  \tuple{\tau_{a}}_{a\in A}, \sim}$ and $\omega$-regular 
  $\phi\subseteq S^{\omega}$ there is an \ac{POMDP} $\mathcal{M'}$ with an 
  associated Parity-condition $\parity$ such that any strategy $s$ for 
  $\mathcal{M}$ induces a strategy $s'$ for $\mathcal{M'}$ such that 
  $\mu_{s}(\phi) = \mu_{s'}(\Acc(\parity))$ and vice versa.
  \label{lem:POMDPomegareg}
\end{lemma}
\begin{proof}
  For $\phi$ we can obtain a \ac{DPA} 
  $\mathcal{P} = \tuple{Q, S, q_{0}, \delta, \parity}$ which accepts $\phi$.
  The deterministic nature of $\mathcal{P}$ is used to obtain the result by
  constructing
  \begin{equation*}
    \mathcal{M'} = \tuple{S\times Q, \tuple{s_{0}, q_{0}}, A, 
    \tuple{\tau'_{a}}_{a\in A}, \sim', \parity'}
  \end{equation*}
  with
  \begin{align*}
    &\tau'_{a}(\tuple{s, q}, \tuple{z, p}) = \begin{cases}
      \tau_{a}(s, z)&\text{if }p = \delta(q,s),\\
      0&\text{otherwise,}
    \end{cases}\\
    &\parity'(\tuple{s,q}) = \parity(q)
    \text{ and }
    \tuple{s, q}\sim'\tuple{z, p}\text{ iff }s\sim z.
  \end{align*}
  Since $\sim'$ is defined in terms of the first element of every state, we may
  biject $\interval{s}_{\sim}$ with $\interval{\tuple{s, q}}_{\sim'}$ which 
  allows to translate strategies from $\mathcal{M}$ to $\mathcal{M'}$ and vice
  versa and additionally by definition of $\tau_{a}'$ for all $a\in A$ we 
  obtain for any strategy $s'$ for $\mathcal{M'}$ and its corresponding 
  strategy $s$ for $\mathcal{M}$ that
  \begin{equation*}
    \mu_{s'}(\cyl(\tuple{z_{0}, q_{0}}\dots\tuple{z_{n}, q_{n}})) = 
    \begin{cases}
      \mu_{s}(\cyl(z_{0}\dots z_{n}))&\text{for the unique }
        q_{0}\dots q_{n}\text{ of }\mathcal{P}\text{ on }z,\\
      0&\text{otherwise.}
    \end{cases}
  \end{equation*}
  We may deduce that the first component of all valid, i.e. not impossible, 
  plays in $\mathcal{M}'$ uniquely identifies the second component which allows 
  us to only consider the projection to those \enquote{synchronised} plays 
  which can easily bijected to plays in $\mathcal{M}$ and $s$ and $s'$ even 
  induce the same measure on this bijection. We conclude that
  \begin{equation*}
    \mu_{s}(\phi) = \mu_{s'}(\Acc(\parity)).
  \end{equation*}
\end{proof}

If we actually consider in the argument above that $\mathcal{M}$ is an \ac{MDP} 
then the product construction can be considered to be an \ac{MDP} as well since 
the uniqueness of the second component allows to use the same argument. 
Although the strategies space for $\mathcal{M'}$ are richer, we can only 
consider the space of possible plays which again corresponds uniquely to plays 
in $\mathcal{M}$. We obtain
\begin{corollary}
  For an initial \ac{MDP} $\mathcal{M}$ one obtains a corrresponding \ac{MDP} 
  $\mathcal{M}'$ with the same properties as stated in Lemma 
  \ref{lem:POMDPomegareg}.
\end{corollary}
Moreover, if we consider $\phi$ to be recognizable by a \ac{DBA} we state by
the same argument
\begin{corollary}
  For a \ac{DBA}-recognizable $\phi$ and a \ac{POMDP} (\ac{MDP}) $\mathcal{M}$
  the construction from Lemma \ref{lem:POMDPomegareg} yields an \ac{POMDP} 
  (\ac{MDP}) $\mathcal{M'}$ with an associated BÃ¼chi-condition.
  \label{cor:POMDPDBA}
\end{corollary}
Concludingly, since associated BÃ¼chi- or Parity-conditions on
\ac{POMDP} induce $\omega$-regular $\phi\subseteq S^{\omega}$, namely
\begin{equation*}
  \phi = 
  \begin{cases}
    \Acc(F)&\text{for a BÃ¼chi-condition }F,\\
    \Acc(\parity)&\text{for a Parity-condition}\parity,
  \end{cases}
\end{equation*} 
we may consider the two formulations interchangeable. This allows to state that 
\ac{DBA}-recognizable $\phi$ allow for strategy synthesis in \acp{POMDP} (cp.
Theorem \ref{thm:pomdpstratsynthesis}) but for general $\omega$-regular $\phi$ 
it is undecideable to compute strategies for \acp{POMDP}. 

In the following we again examine $\phi$ which are defined in terms of 
\acp{PBA}. We observe that \ac{PBA} capture \ac{DBA} by setting every 
transition function to a Dirac measure on $Q$. Hence, solving the synthesis 
problem for $\phi$ which can be expressed as languages of almost-surely 
accepting \acp{PBA} arguably is a generalisation of Corollary 
\ref{cor:POMDPDBA} because the class of these $\phi$ is incomparable with 
$\omega$-regular languages. We say arguably because we effectively prove this
by reduction to \acp{POMDP} with associated BÃ¼chi-conditions. Nevertheless, we 
examine the following question:
\begin{definition}[PBA-Synthesis Question]
  Given a \ac{POMDP} $\mathcal{M}$ and a \ac{PBA} $\mathcal{P}$ with
  \begin{equation*}
    \mathcal{M} = \tuple{S, s_{0}, A, \tuple{\tau_{a}}_{a\in A}, \sim}
  \text{ and }
    \mathcal{P} = \tuple{Q, q_{0}, S, \delta, F}
  \end{equation*}
  exists a strategy $s:\interval{S}_{\sim}^{*}\rightarrow A$ such that 
  almost-all executions of $\mathcal{A}$ under $s$ are almost-surely accepted 
  by $\mathcal{P}$?
  \label{def:pbastratsynthesis}
\end{definition}
And we answer this question positively. Considering a certain restricted class 
of \acp{MDP}, namely those where for every state ever following state is 
defined by a probability distribution $B$ (regardless of the action chosen by 
the player), then this result can be derived as a corollary from the 
construction examined in Example \ref{ex:pwapbaallpaths}. Considering this 
example but with a context-sensitive weighting of the paths (in contrast to 
the current restrictive notion) allows to consider a movement downwards a 
direction as movement of an \ac{MDP} $\mathcal{M} = \tuple{S, s_{0}, A, 
\tuple{\tau_{a}}_{a\in A}}$. If we set the directions as the set $S$ and 
consider a path weighting function such that given the current position is 
reached by $s_{1}$ and the letter $a$ is read then the movement downwards 
$s_{2}$ is weighted by $\tau_{a}(s_{1}, s_{2})$ where the inital movement 
corresponds to $\tau_{a}(s_{0}, \cdot)$. Then, using the idea of Example 
\ref{ex:pwapbaallpaths} we construct a \ac{PWA} that executes a \ac{PBA} 
$\mathcal{P}$ on the weighted paths reading the directions rather than the 
letters. Conceptually, translating this to a \ac{WDTA} yields that every path 
$s_{1}\rightarrow s_{2}\rightarrow\dots$ is associated with the run-tree of 
$\mathcal{P}$ reading $s_{0}s_{1}s_{2}\dots$ with the probability of the 
underlying strategy (encoded by the tree). Building upon this idea we design 
the following argumentation which bears structural similarities with the one 
presented for the modelling of \acp{PWA} by \acp{WDTA} (cp. Theorem 
\ref{thm:PWAasWDTA}), but in a more involved form.

We fix one strategy $s:\interval{S}_{\sim}^{*}\rightarrow A$ which induces a 
probability space
\begin{equation*}
  \tuple{S^{\omega},\mathcal{B}(S), \mu_{s}}.
\end{equation*}
Furthermore, for any given $\alpha\in S^{\omega}$ the stochastic process of
$\mathcal{P}$ also yields a probability space
\begin{equation*}
  \tuple{Q^{\omega},\mathcal{B}(Q), \mu_{\alpha}}.
\end{equation*}
The analytical complexity is rooted in the dependency of $\mu_{\alpha}$ from
$\alpha$.

We define the following Markov-kernel
\begin{equation*}
  K:S^{\omega}\times\mathcal{B}(Q)\rightarrow\interval{0,1}\text{ with }
    K(\alpha, A) = \mu_{\alpha}(A)
\end{equation*}
for the measurable spaces $\tuple{S^{\omega},\mathcal{B}(S)}$ and 
$\tuple{Q^{\omega},\mathcal{B}(Q)}$. The central inside arises from Lemma 
\ref{lem:almosteverywhere} which allows us to state
\begin{equation*}
  \int_{S^{\omega}}K(\cdot, \Acc(F)) d\mu_{s} 
  = \int_{\alpha\in S^{\omega}}\mu_{\alpha}(\Acc(F))d\mu_{s} = 1 \text{ iff }
    \mu_{s}(K(\cdot,\Acc(F))^{-1}(1)) = 1.
\end{equation*}
This characterises the synthesis question from Definition 
\ref{def:pbastratsynthesis} since $\mu_{s}(K(\cdot,\Acc(F))^{-1}(1))$ is the 
set of executions which are accepted by an almost-sure measure by 
$\mathcal{P}$. Notably, we can assure this statement only under the premise 
that $K(\cdot, \Acc(F))$ is indeed measurable. This is a direct consequence if 
$K$ is a Markov-kernel since $\Acc(F)\in\mathcal{B}(Q)$. We address this 
condition with the following
\begin{lemma}
  $K$ as defined above is a Markov-kernel.
\end{lemma}
\begin{proof}
  With $K(\alpha,\cdot) = \mu_{\alpha}$ it is trivial to state that 
  $K(\alpha,\cdot)$ defines a probability measure for 
  $\tuple{Q^{\omega},\mathcal{B}(Q)}$.

  We observed that the cylindric sets 
  $A\in\mathcal{B}(Q)$, i.e. $A = \cyl(u)$ for some $u\in Q^{*}$, satisfy 
  this requirement, hence we restrict the following argument to those.
  Fundamentally, we observe that by definition of the transition 
  probabilities for a \ac{PBA} we obtain a determinism for the run-tree of 
  $\mathcal{P}$, i.e. for any $u\in S^{n}$ and $\alpha, \beta\in\cyl(u)$ that
  \begin{equation*}
    \mu_{\alpha}(\cyl(v)) = \mu_{\beta}(\cyl(v))\text{ for all }v\in Q^{n}.
  \end{equation*}
  This justifies the use of the notion $\mu_{u}$.  Regarding measurability of 
  function we introduce

  Therefore the measurability of $K(\cdot, \cyl(u))$ is implied if for all 
  $a\in\mathbb{R}$
  \begin{equation*}
    \set{\alpha\in S^{\omega}\mid K(\alpha, \cyl(u))\leq a}\in\mathcal{B}(S).
  \end{equation*}
  Observably,
  \begin{equation*}
    \set{\alpha\in S^{\omega}\mid K(\alpha, \cyl(u))\leq a} = 
      \bigcup\set{
        \cyl(v):u\in S^{\size{u}}\text{ and }\mu_{u}(\cyl(v))\leq a
      }
  \end{equation*}
  implies the necessary membership in $\mathcal{B}(S)$ since $S^{\size{v}}$ 
  is finite.
\end{proof}

We proceed in defining an appropiate \ac{WDTA} to capture precisely those 
strategies which satisfy the synthesis requirement. The concept mirrors the
resulting \ac{WDTA} when we combine the path measure and the run measure for
\acp{PWA} (see Example \ref{ex:pwapbaallpaths}) by build run-trees of a 
\ac{PBA} along the executions. But it is actually not necessary to restrict
ourselves to one execution step of the \ac{PBA} per direction. This 
observation is essential for formulating this result for \acp{POMDP} rather 
than for \acp{MDP} alone.
\begin{definition}[Synthesis WDTA]
  For a \ac{POMDP} $\mathcal{M}$ and a \ac{PBA} $\mathcal{P}$ with
  \begin{equation*}
    \mathcal{M} = \tuple{S, A, \tuple{\tau_{a}}_{a\in A}, s_{0}, \sim}
    \text{ with }
    \mathcal{O} = \set{\interval{s}_{\sim}: s\in S}
    \text{ and }
    \mathcal{P} = \tuple{Q, S, \delta, q_{0}, F}
  \end{equation*} 
  we construct the choiceless \ac{WDTA}
  \begin{equation*}
    \mathcal{A}_{\mathcal{M}}^{\mathcal{P}} = \tuple{
      S\times Q, \tuple{s_{0}, q_{0}}, A, \mathcal{O}, \Delta, S\times F
    }.
  \end{equation*}
  The transitions in $\Delta$ are of the form
  \begin{equation*}
    \tuple{\tuple{s, q}, a, G_{\tuple{s,q}}^{a}}
    \text{ with }
    G_{\tuple{s,q}}^{a}(\tuple{z,p}, o) = \begin{cases}
      \tau_{a}(s, z)\cdot\delta(q, z, p)&\text{if }\interval{z}_{\sim} = o,\\
      0&\text{otherwise}.
    \end{cases}
  \end{equation*}
\end{definition}
Notably, again all trees for this \ac{WDTA} 
$\mathcal{A}_{\mathcal{M}}^{\mathcal{P}}$ are valid strategies for the 
\ac{POMDP} $\mathcal{M}$. We fix one tree (or strategie respectively) $s$. 
For the unique run $r$ of $\mathcal{A}_{\mathcal{M}}^{\mathcal{P}}$ on $s$ we
can observe (analogously to the construction for Theorem 
\ref{thm:POMDPequivWDTA}) that the $S$ component of any state uniquely 
correlates to one $\mathcal{O}$ component and by the definition of 
$G_{\tuple{s, q}}^{a}$ this is the only direction weight can be passed to.
Therefore, we restrict our arguments on the weighted part of the domain of
$r$, namely $\tuple{S\times Q}^{*}$. By definition of the transitions we 
obtain for any word 
$\tuple{s_{0}, q_{0}}\dots\tuple{s_{n}, q_{n}}\in\tuple{S\times Q}^{*}$
\begin{align*}
  \mu_{r}(\tuple{s_{1}, q_{1}}\dots\tuple{s_{n}, q_{n}}) &= 
    G^{s(\epsilon)}(\tuple{s_{1}, q_{1}})\cdot 
    \prod\limits_{i = 1}^{n-1}
      G^{s(\interval{s_{1}\dots s_{n}}_{\sim})}_{\tuple{s_{i}, q_{i}}}(
        s_{i+1}, q_{i+1})\\
  &= \delta(q_{0}, s_{1}, q_{1})\cdot\tau_{s(\epsilon)}(s_{0}, s_{1})
    \prod\limits_{i = 1}^{n-1}
      \delta(q_{i}, s_{i+1}, q_{i+1})\cdot
      \tau_{s(\interval{s_{1}\dots s_{n}}_{\sim})}(s_{i}, s_{i+1})\\
  &= \mu_{s_{1}\dots s_{n}}(\cyl(q_{0}\dots q_{n}))\cdot
    \mu_{s}(\cyl(s_{1}\dots s_{n}))\\
  &= \int_{\cyl(s_{1}\dots s_{n})}K(\cdot, \cyl(q_{0}\dots q_{n}))d\mu_{s}.
\end{align*}
This suggests by the uniqueness of $\mu_{s}\otimes K$ and the extension of
$\mu_{r}$ that these coincide (under renaming of the arguments as allowed by
Lemma \ref{lem:borelinterleaving}). Concludingly, we can observe for the 
acceptance meausure of $\mathcal{A}_{\mathcal{M}}^{\mathcal{P}}$
\begin{equation*}
  \mu_{r}(\Acc\interval{Q}(S\times F))
  = \mu_{s}\otimes K(S^{\omega}, \Acc(F))
  = \int_{\alpha\in S^{\omega}}\mu_{\alpha}(\Acc(F)) d\mu_{s}.
\end{equation*}
This allows us to state that $\mathcal{A}_{\mathcal{M}}^{\mathcal{P}}$ 
accepts $s$ if and only if $s$ is a solution to the synthesis question for 
the \ac{POMDP} $\mathcal{M}$ and the \ac{PBA} $\mathcal{P}$. We may use
Corollary \ref{cor:emptiness} to compute this $s$ and therefore prove
\begin{theorem}[Qualitative PBA Synthesis]
  The synthesis question of an environment $\mathcal{M}$ and a specification
  provided as \ac{PBA} $\mathcal{A}$ with a qualitative acceptance measure
  can be decided.
  \label{thm:pbasynthesis}
\end{theorem}

Although inspired by the arguments of Theorem \ref{thm:PWAasWDTA}, the usage 
of \acp{WDTA} is not essential for the argument above. Equivalently Lemma 
\ref{lem:POMDPomegareg} can be extended towards $\phi$ which
are defineable by almost-surely accepting \acp{PBA} by the natural product 
construction: we consider a \ac{POMDP} $\mathcal{M}$ and a \ac{PBA} 
$\mathcal{P}$ with
\begin{equation*}
  \mathcal{M} = \tuple{S, s_{0}, A, \tuple{\tau_{a}}_{a\in A}, \sim}
  \text{ and }
  \mathcal{P} = \tuple{Q, q_{0}, S, \delta, F}
\end{equation*}
and construct a product \ac{POMDP}
\begin{equation*}
  \mathcal{M}\otimes\mathcal{P} = \tuple{S\times Q, \tuple{s_{0}, q_{0}}, A,
    \tuple{\tau'_{a}}_{a\in A}, \sim', F' = S\times F}
\end{equation*}
with
\begin{equation*}
  \tau'_{a}(\tuple{s, q}, \tuple{z, p}) = \tau_{a}(s, z)\cdot\delta(q, s, p)
  \text{ and }
  \tuple{s, q}\sim'\tuple{z, p}\text{ iff }s\sim z.
\end{equation*}
The correctness argument is analogously to the argument which involve 
\acp{WDTA} above. In this setup \acp{MDP} are also transformed to \ac{POMDP} 
since the construction needs to hide the current state of $\mathcal{P}$ and we
do not have a determinism argument as before since \acp{PBA} have in general
possibly multiple following states. Nevertheless, this yields a \ac{POMDP} with
states $S' = Q\times S$ and allows to compute the corresponding $s$ in
time exponential of $\size{S'}$. Effectively, we get
\begin{corollary}
  If a strategy for the qualitative synthesis problem for a \ac{POMDP} with
  states $S$ and a specification in form of an almost-surely accepting \ac{PBA} 
  with states $Q$ exists it can be computed in time exponential in 
  $\size{Q\times S}$.
\end{corollary}
This is a notable improvement over the argument resolving around \acp{WDTA}
since the associated time complexity there is exponential in
$\size{S}\times\size{Q}\times\size{\interval{S}_{\sim}}$.
