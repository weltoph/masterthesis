\chapter{Synthesis}
\label{chapter:synthesis}
For the general synthesis question we refer to \cite{Church} and formalize it
with 
\begin{definition}[Synthesis Problem]
  Given a logical specification  $\phi(\cdot, \cdot)$ over inputs and 
  outputs from $I^{\omega}$ and $J^{\omega}$ respectively. The synthesis 
  problem requires to compute for any such $\phi$ an algorithm 
  $S:I^{+}\rightarrow J$ such that for every 
  $\alpha_{1}\alpha_{2}\dots\in I^{\omega}$ and every 
  $S(\alpha) = S(\alpha_{1})S(\alpha_{1}\alpha_{2})\dots$ satisfies 
  $\phi(I, S(I))$ or prove that such an $S$ cannot exist (cp. the 
  illustration in Figure \ref{fig:synthesis}).
\end{definition}
\begin{drawing}
  \caption{Illustration of the synthesis question. The aim is to provide an 
  algorithm which \enquote{synthesises} for any specification a strategy or 
  proves that there cannot exist a strategy that satisfies the specification.}
  \label{fig:synthesis}
  \begin{center}
    \includegraphics{tikz/synthesis.pdf}
  \end{center}
\end{drawing}
Naturally, the complexity of this problem is tightly related to the 
expressibility of $\phi$. The comprehensive demand of this question, namely
to generate for all inputs an associated \enquote{good} output, allows for a
game-theoretic formulation. As suggested in \cite{SeqCondStrat} we can consider
the environment as antagonistic and formulate the synthesis question in terms
of strategies, i.e. one player generates inputs while another player generates
outputs. We call these players \inputp{} and \outputp{} respectively. \outputp 
wins if and only if $\phi$ is satisfied for the input- and output-sequences. In 
the following we present known synthesis results for those $\phi$ which allow 
to capture the associated relation as a $\omega$-regular language. 
Subsequently, we pivot towards probabilistic environments and review an 
approach to synthesis algorithms there which are not necessarily surely 
correct but almost-surely satisfy a specification $\phi$. These probabilistic
environments are eventually modelled as \acp{POMDP}. 

\section{Antagonisitic Environments}
In the following we consider an $\omega$-regular class of specifications 
$\phi$ for inputs $I$ and outputs $J$, namely those such that we can define a 
$\omega$-regular language $\mathcal{L}_{\phi}\subseteq 
\tuple{J\times I}^{\omega}$ with
\begin{equation}
  \tuple{j_{0}, i_{0}}\tuple{j_{1}, i_{1}}\dots\in\mathcal{L}_{\phi}
  \text{ iff }
  \phi(i_{0}i_{1}\dots, j_{1}j_{2}\dots)\text{ is true.}
  \label{eq:omegaregularphi}
\end{equation}
Observably, the output symbol $j_{0}$ is irrelevant but included to ease the 
technicalities of the following argument. With the well researched theory of
tree automata the associated synthesis problem for $\omega$-regular 
specifications can be solved rather transparently. The idea is to use trees to 
model the interaction between input and output symbols. The directions of a 
tree model inputs while the symbols in the tree represent outputs. Similar to 
the arguments of the proof of Theorem \ref{thm:POMDPequivWDTA} a tree can 
therefore be understood as strategy and we want to design a \ac{PTA} such that 
a tree is only accepted if all paths are part of $\mathcal{L}_{\phi}$. This can 
be easily modelled (cp. \cite[Lemma 15]{AutoInfObj}) with
\begin{definition}[Synthesis \ac{PTA}]
  For a given \ac{DPA}
  \begin{equation*}
    \mathcal{P} = \tuple{Q, q_{0}, J\times I, \delta, \parity}
  \end{equation*}
  we define a \ac{PTA}
  \begin{equation*}
    \mathcal{A} = \tuple{Q, q_{0}, I, J, \Delta, \parity}
  \end{equation*}
  where $\Delta$ contains transtitions $\tuple{q, j, (p_{i})_{i\in I}}$ with
  $p_{i} = \delta(q, \tuple{j, i})$.
\end{definition}
Notably, $\mathcal{A}$ executes $\mathcal{P}$ on every path and therefore, if 
we choose $\mathcal{P}$ as the \ac{PTA} which precisely accepts 
$\mathcal{L}_{\phi}$, we deduce that $\mathcal{A}$ accepts only those trees 
that satisfy $\phi$ on all paths. This implies that $\mathcal{A}$ accepts those
strategies $t$ which satisfy $\phi$. Hence, constructing (see above) and 
deciding the emptiness (see Theorem \ref{thm:emptinessPTA}) for $\mathcal{A}$ 
yields the desired synthesis algorithm for $\omega$-regular specifications 
$\phi$ and gives
\begin{theorem}
  \cite[Theorem 21, Theorem 22]{AutoInfObj}
  The synthesis problem for $\omega$-regular specifications $\phi$ can be 
  decided.
\end{theorem}
This approach suits the game-theoretic interpretation of the synthesis problem
by identifying \inputp{} with \pathfinder{} while \outputp{} is assigned the 
role of \automaton{} and constructs a fitting tree.
\fxwarning{maybe elaborate on the class of $\omega$-regular specifications 
(LTL, ...)}

In the following we want to consider specifications $\phi$ which are not 
$\omega$-regular but defineable by almost-surely accepting \acp{PBA}. Thus, in
analogy to the formulation \ref{eq:omegaregularphi} above we consider $\phi$ 
such that there is a \ac{PBA} $\mathcal{P}$ which accepts the language 
$\mathcal{L}_{\mathcal{P}}$ with
\begin{equation}
  \tuple{j_{0}, i_{0}}\tuple{j_{1}, i_{1}}\dots\in\mathcal{L}_{\mathcal{P}}
  \text{ iff }
  \phi(i_{0}i_{1}\dots, j_{1}j_{2}\dots)\text{ is true.}
  \label{eq:pbaregularphi}
\end{equation}
The approach to this problem is formalized by introducing a new class of graph
games, called \acp{POSG} (cp. \cite{POSG, PureStratPOSG}). Reconsidering the 
behavior of \acp{POMDP} we can capture their semantic as a game between two 
players on the underlying graph of states and edges $\tuple{s_{1}, s_{2}}$ 
which are induced by non-zero probabilities for the movement from $s_{1}$ to 
$s_{2}$ for some action of the player as follows: at any point the player 
provides an action and the opponent chooses one of the associated edges. The 
player acts \enquote{deterministically} in the sense that for a certain history 
one specific action $a$ is played while the opponent plays probabilistically 
(as defined by $\tau_{a}$). \acp{POSG} expand on this notion by introducing a 
third player. At every position both players independently and simultaniously 
choose an action and then the third player plays by choosing a successor state 
probabilistically. Again we allow for restricted observations for both players
and formalize these notions analogously to \acp{POMDP} but with two players 
participating in the choices at every state:
\begin{definition}[\acl{POSG}]
  A \ac{POSG}-arena $G$ is defined by a set of states $S$ (with an 
  inital state $s_{0}\in S$), actions for both players (called \eve{} and 
  \adam{}) $E$ and $A$ respectively, transition probabilities 
  $\tuple{\tau_{e,a}}_{e\in E, a\in A}$ and equivalence classes $\sim_{E}$ and 
  $\sim_{A}$ restricting the observations of \eve{} and \adam{} respectively. 
  We obtain
  \begin{equation*}
    G = \tuple{S, s_{0}, E, A, \tuple{\tau_{e,a}}_{e\in E, a\in A}, 
    \sim_{E}, \sim_{A}}
  \end{equation*}
  with
  \begin{equation*}
    \tau_{e,a}:S\times S\rightarrow\interval{0,1} \text{ s. t. }
    \tau_{e,a}(s, \cdot)\in\mathcal{D}(S)\text{ for all }a\in A, e\in E.
  \end{equation*}
  A strategy for \eve{} (\adam{}) is defined as 
  $f:\interval{S}_{\sim_{E}}^{*}\rightarrow E$ 
  ($g:\interval{S}_{\sim_{A}}^{*}\rightarrow A$). For any such pair of 
  strategies $f$ and $g$ we obtain a probability space
  \begin{equation*}
    \tuple{S^{\omega}, \mathcal{B}(S), \mu_{f, g}}.
  \end{equation*}
  A \ac{POSG} is defined by an arena $G$ and an associated language
  $\Acc\subseteq S^{\omega}$ forming $\mathcal{G} = \tuple{G, \Acc}$. Notably,
  $\mathcal{G}$ is a zero-sum game, i.e. \eve{} tries to obtain a play in 
  $\Acc$ while \adam{} tries to force plays in $S^{\omega}\setminus\Acc$. In 
  the following we grammatically refer to \eve{} as female and \adam{} as male.
\end{definition}
For any such $\mathcal{G} = \tuple{
S, s_{0}, E, A, \tuple{\tau_{e,a}}_{e\in E, a\in A}, \sim_{E}, \sim_{A}, \Acc}$ 
we can consider various goals for \eve{}, defined by different $\Acc$ and
positive or almost-sure satisfaction. In similar sense as for graph games we
consider a strategy $f$ for \eve{} almost-surely (postively) winning if for all
strategies $g$ of \adam{} we have $\mu_{f,g}(\Acc) = 1$ 
($\mu_{f,g}(\Acc) > 0$). Note that $\Acc$ has to be Borel to ensure 
well-definedness but we consider again $\Acc$ defined in finite means by 
Büchi-, Parity-, Rabin- or Muller-conditions for which this already is 
established. The natural initial observation that \adam{}'s role can be reduced 
to oblivion by only granting him a single action allows to capture the notions
of \acp{POMDP} which entails strong restrictions regarding algorithmic 
approaches, namely we obtain
\begin{corollary}
  \cite{PureStratPOSG, POSG}
  For a given \ac{POSG} $\mathcal{G} = \tuple{G, \Acc}$ the following problems
  are undecideable:
  \begin{itemize}
    \item Exists a positively winning strategy for \eve{} if $\Acc$ is defined 
      as Büchi-, Parity-, Rabin- or Muller-condition?
    \item Exists an almost-surely winning strategy for \eve{} if $\Acc$ is
      defined as Parity-, Rabin- or Muller-condition?
  \end{itemize}
\end{corollary}
\begin{proof}
  These are immediate consequences of the negligibility (not in the sense of
  measurability theory but in the game theoretic sense) of \adam{}'s actions
  and Theorem \ref{thm:emptinesspospba} (or the respective Corollary 
  \ref{cor:posstratpomdp}).
\end{proof}
Due to these harsh restrictions we focus in the following on almost-surely 
winning strategies for \eve{} in \ac{POSG} with Büchi-conditions. Additionally,
we only consider \acp{POSG} where \eve{} and \adam{} are 
\emph{equally informed}, i.e. $\sim_{E} = \sim_{A}$. In this case
we obtain the possibility to compute these strategies for \eve{} by
\begin{theorem}
  \cite[Theorem 6]{POSG} with the included reference to 
  \cite[Lemma 4]{DecProblemsForProbAuto} or \cite[Theorem 5.3]{PureStratPOSG}.
  It is possible to decide if there is a almost-surely winning strategy for 
  \eve{} in a \ac{POSG} $\mathcal{G} = \tuple{G, F}$ where $F$ is a 
  Büchi-condition and $\sim_{E} = \sim_{A}$.

  This decision procedure takes time doubly exponential in $\size{S}$.
\end{theorem}
Since we rely for the time bound on arguments from \cite{PureStratPOSG} which 
is not published at the moment of completion of this thesis we present the 
necessary argumentation in Appendix \ref{app:POSG} to ensure its availability.
Nevertheless, we answer the synthesis question imposed by an almost-surely
accepting \ac{PBA} $\mathcal{P}$ positively for antagonistic environments. The 
idea is to define a \ac{POSG} in which both players only observe an 
input-output game while in the \enquote{background} the stoachastic process of
$\mathcal{P}$ operates and any play is eventually evaluated in terms of 
$\mathcal{P}$. We obtain
\begin{theorem}
  For any \ac{PBA} 
  \begin{equation*}
    \mathcal{P} = \tuple{Q, q_{0}, I\times J, \delta, F'}
  \end{equation*}
  the synthesis problem imposed by $\phi$ as defined by $\mathcal{P}$ as in
  \ref{eq:pbaregularphi} can be decided in time doubly exponential in 
  $\size{I}\cdot \size{Q}\cdot \size{J} + 1$.
\end{theorem}
\begin{proof}
  We define for $\mathcal{P}$ an associated \ac{POSG} such that \eve{} 
  corresponds with \outputp{} while \adam{} plays the role of \inputp{}:
  \begin{definition}[\ac{POSG} for $\mathcal{P}$]
    Set
    \begin{equation*}
      \mathcal{G}_{\mathcal{P}} = \tuple{I\times Q\times J\uplus\set{q_{0}}, J,
        I, \tuple{\tau_{j,i}}_{j\in J,i\in I}, \sim_{E}, \sim_{A}, F}
    \end{equation*}
    with
    \begin{equation*}
      \sim_{E} = \sim_{E} = \set{\tuple{\tuple{i, q, j}, \tuple{i', q', j'}}\in
        \tuple{I\times Q\times J}^{2}\mid i = i', j = j'}
      \text{ and }
      F = I\times F'\times J.
    \end{equation*}
    Moreover, we fix
    \begin{equation*}
      \tau_{j',i'}(\tuple{i, q, j}, \tuple{o, p, u}) = \begin{cases}
        \delta(q, \tuple{i', j'}, p)&\text{if }o = i', u = j',\\
        0&\text{otherwise},
      \end{cases}
    \end{equation*}
    where $q_{0}$ is treated as $\tuple{i, q_{0}, j}$ for any $i\in I, j\in J$.
  \end{definition}
  Central to this proof is the observation that regarding the observations of
  \eve{} and \adam{} $\mathcal{G}_{\mathcal{P}}$ is isomorphic to a 
  deterministic input-output game. This is ensured since for all transitions 
  $\tau_{j,i}$ holds $\supp(\tau_{j, i}(\tuple{i', q, j'}, \cdot)\subseteq
  \set{i}\times Q\set{j}$. Hence, the only probabilistic part of any movement
  is associated with the state component which is observed neither by \eve{} 
  nor by \adam{}. Indeed, this is integral to the argument as expressed in
  \begin{lemma}
    Every two strategies $f$ and $g$ of \eve{} and \adam{} respectively induce
    one unique $\alpha\in\tuple{I\times J}^{\omega}$ in the first and last 
    component of the resulting play. Moreover, $\mu_{f,g}$ when restricted to
    the plays that respect $\alpha$ conincides on the state component with
    $\mu_{\alpha}$ of $\mathcal{P}$.
  \end{lemma}
  \begin{proof}
    The unique $\alpha$ is easily obtained by inductively applying the 
    observation that $\supp(\tau_{j, i}(\tuple{i', q, j'},\cdot)\subseteq
    \set{i}\times Q\set{j}$ for all $i'\in I, q\in Q, j'\in J$. Naturally,
    $\mu_{f,g}$ only carries weighted in the associated sub-algebra of 
    $\mathcal{B}(I\times Q\times J)$ where the first and last component form
    $\alpha$. We can ev
  \end{proof}
\end{proof}

\section{Stochastic Environments}
Another approach is introduced in \cite{SynProbEnv} by considering environments
which do not act antagonistically but probabilistically, i.e. we assume that 
inputs are generated by a probabilistic process. This motivates the concept of 
$\epsilon$-environments. For an $\epsilon > 0$ such an environment generates an
input $i$ with a certain probability which is at any time bound from below by 
$\epsilon$. The form of the strategy that is meant to be synthesised is given
as a $J$-labeled $I$-tansition-system $\mathcal{T}$ of the form
\begin{equation*}
  \mathcal{T} = \tuple{S, s_{0}, \tau, \ell}.
\end{equation*}
Here $S$ is a set of states, $s_{0}$ an inital state and 
$\tau:S\times I\rightarrow S$ describes a deterministic transition function and
$\ell:S\rightarrow J$ a labelling of $S$. Semantically, $\mathcal{T}$ starts in 
$s_{0}$ and reacts to an input $i$ by moving to $z = \tau(s,i)$ and outputting 
$\ell(z)$. Naturally, such a transition system $\mathcal{T}$ models a strategy 
$t:I^{+}\rightarrow J$ by constructing for every 
$u = u_{1}\dots u_{n}\in I^{+}$ the unique sequence 
$s_{0}s_{1}\dots s_{n}\in S^{+}$ such that $s_{i+1} = \tau(s_{i}, u_{i+1}$ for 
$0\leq i<n$ and returning $\ell(s_{n})$. As mentioned in the introduction of 
Section \ref{subsec:ata} alternating tree automata can be used to run on the 
unfolding of such transition systems. Assuming a $\omega$-regular specification 
$\phi$ we may obtain a \ac{DPA} 
$\mathcal{P} = \tuple{Q, q_{0}, \tuple{J\times I}, \delta, \parity}$ accepting 
$\mathcal{l}_{\phi}$. We can attach $\mathcal{P}$ onto a given transition 
system $\mathcal{T}$ in a straightforward manner to obtain a transition system 
with an associated Parity-condition (but dropping the labelling)
\begin{equation*}
  \mathcal{G}_{\mathcal{P}}^{\mathcal{T}} = \tuple{S\times Q, 
    \tuple{s_{0}, q_{0}}, \tau', \parity'}
\end{equation*}
where $\tau'(\tuple{s, q}, i) = \tuple{\tau(s, i), 
\delta(q, \tuple{\ell(s), i})}$ and $\parity'(\tuple{s, q}) = \parity(q)$. For
this transition system and an $\epsilon$-environment $\mathcal{E}$ we can 
identify structural properties in $\mathcal{G}_{\mathcal{P}}^{\mathcal{T}}$ to
determine whether $\mathcal{T}$ satisfies $\phi$ almost-surely respectively 
positively. This structural property is connected with \ac{SCC}. These are 
subsets of nodes $G$ such that there is a path between every two nodes 
$u,v\in G$ (cp. \cite{Tarjan}). Additionally, a leaf-\ac{SCC} is an \ac{SCC} 
$S$ such that there is no other \ac{SCC} reachable from any $v\in S$ (cp. 
\cite[Bottom-\ac{SCC}]{ComplexProbVerification}). Intuitively, it is unlikely 
to not eventually end up in one of these leaf-\acp{SCC} since there is 
infinitely often the possibility to take a non-zero probability to move into 
these, hence we state
\begin{lemma}
  \cite[Lemma 1]{SynProbEnv}
  An $J$-labeled $I$-transition-system $\mathcal{T}$ almost-surely (positively)
  satisfies a specification $\phi$ if and only if the highest priority in all
  (some) reachable leaf-\ac{SCC} of $\mathcal{G}_{\mathcal{P}}^{\mathcal{T}}$
  is even, where $\mathcal{P}$ is a \ac{DPA} accepting $\mathcal{L}_{\phi}$.
\end{lemma}
This structual property can be checked by a \ac{APTA}. This again yields by
checking the emptiness of the obtained \ac{APTA} an algorithm for the synthesis
problem of almost-sure (respectively positive) satisfaction of an 
$\omega$-regular $\phi$. Therefore we obtain
\begin{theorem}
  \cite[Theorem 1]{SynProbEnv}
  Given a \ac{DPA} $\mathcal{P}$ there is a \ac{APTA} 
  $\mathcal{A}_{\mathcal{P}}$ ($\mathcal{O}_{\mathcal{P}}$) such that 
  $\mathcal{A}_{\mathcal{P}}$ ($\mathcal{O}_{\mathcal{P}}$) accepts a 
  $J$-labeled $I$-transition-system $\mathcal{T}$ if and only 
  if\footnote{The original theorem only states the if-direction but the 
  corresponding proof deals with the only if-direction as well.} $\mathcal{T}$ 
  satisfies almost-surely (positively) $\mathcal{P}$.

  If $\mathcal{P}$ has $n$ states and $c$ parities then 
  $\mathcal{A}_{\mathcal{P}}$ and $\mathcal{O}_{\mathcal{P}}$ have at most
  $n\cdot\lceil 2 + \frac{c}{2}\rceil + 1$ states.
  \label{thm:probenvsynthesis}
\end{theorem}
\begin{proof}[Sketch]
  The main argument for this proof is that the search for the leaf-\acp{SCC} 
  can be understood as a two-player-game. One player plays for acceptance 
  (called \acceptor{}) while the other tries to spoil the correctness of the 
  transition system (called \spoiler{}). We describe the case of 
  $\mathcal{A}_{\mathcal{P}}$ but the case $\mathcal{O}_{\mathcal{P}}$ can be 
  constructed analogously by exchanging the player role in the first phase of 
  the game. The game for $\mathcal{T}$ in the $\mathcal{A}_{\mathcal{P}}$ 
  operates in three phases:
  \begin{enumerate}
    \item \spoiler{} chooses one leaf-\ac{SCC} $S$,
    \item \acceptor{} chooses one priority $p$ of a node in $S$,
    \item \spoiler{} tries to find a higher priority than $p$ in $S$.
  \end{enumerate}
  The unrollment of $\mathcal{T}$ yields an $I$-ary $J$-tree. The states of 
  $\mathcal{A}_{\mathcal{P}}$ encode the current state of $\mathcal{P}$ and if
  the game is in the first, second or third phase. If the game is in the third
  phase the chosen priority is also stored in the state. While operating in the
  first phase $\mathcal{A}_{\mathcal{P}}$ dispatches in all directions 
  first-phase states, representing possible choices of \spoiler{} and also in
  one direction a second-phase state; that is a state which only dispatches a
  second phase state into one direction, representing the possible choices of
  \acceptor{}. This second-phase state may at any point transform to a 
  third-phase state and by this encodes the (even) priority of the current 
  state of $\mathcal{P}$ in the state of $\mathcal{A}_{\mathcal{P}}$. This 
  third-phase state again dispatches in all directions and as soon as one state 
  with a higher parity than the stored one appears, moves to a 
  sink-error-state. The first-phase states are given a parity of $0$, the 
  second-phase states of $1$ and the third-phase states of $2$. This allows 
  that for all choices of \spoiler{} (which constantly reproduce themselves) 
  only those that proceed to the second phase actually matter or for the 
  third-phase only the occurence of a higher parity. Since the parity of the 
  second-phase states is odd it is enforced that \acceptor{} eventually chooses 
  one parity to store. Note the similarity to the proof of Proposition
  \ref{prop:atanegation} in formulating the desired winning strategy of one 
  player as actual choices which may use the non-determinism of the automaton 
  while the enemy explores all possible moves. Also, we omit the precise 
  definition of $\mathcal{A}_{\mathcal{P}}$ here since its rather involved 
  technicalities do not translate well to the chosen formalism for alternating 
  automata of this paper.
\end{proof}

This allows us to solve the associated synthesis problem for $\omega$-regular
specifications and $\epsilon$-environments. In the following we consider 
environments that are modelled as \acp{MDP} or \acp{POMDP} and try to synthesis
for a given specification a strategy to almost-surely or positively satisfy 
this specification. This approach is conceptually different to 
$\epsilon$-environments since concrete probabilities are given and also the 
interaction of the actor with the environment is explicitly incorporated but 
can be understood as approach to annotate the transitions of $\mathcal{T}$
with the probabilities of the environment.

We move towards synthesis in environments which are explicitly modelled in 
terms of \acp{MDP} and \acp{POMDP}. Then we formalize the synthesis question 
with (cp. \cite{QualAnaPOMDP, SimpleStochasticParityGames, 
ComplexProbVerification})
\begin{definition}
  Given a \ac{POMDP} 
  \begin{equation*}
    \mathcal{M} = \tuple{S, s_{0}, A, \tuple{\tau_{a}}_{a\in A}, \sim}
  \end{equation*}
  and a specification $\phi\subseteq S^{\omega}$ such that 
  $\phi\in\mathcal{B}(S)$. The qualitative synthesis problem 
  $\tuple{M, \varphi}$ demands the computation of a strategie 
  $s:\interval{S}_{\sim}^{*}\rightarrow A$ such that $\mu_{s}(\varphi) = 1$.
\end{definition}
We already used results formulated for this question, namely Theorem 
\ref{thm:pomdpstratsynthesis} and Theorem \ref{thm:mpdstratsynthesis}. Again,
we focus on $\omega$-regular $\phi$ (in this case $\phi$ is itself a language
and is not translated to one). If we additional assume that 
$\size{\interval{s}_{\sim}} = 1$ for all $s\in S$, i.e. $\mathcal{M}$ 
degenerates to an \ac{MDP}, similar arguments as for $\epsilon$-environments 
above may be used. In analogy to 
\cite[Proposition 4.2.3.]{ComplexProbVerification} we deduce
\begin{lemma}
  For any \ac{POMDP} $\mathcal{M} = \tuple{S, s_{0}, A, 
  \tuple{\tau_{a}}_{a\in A}, \sim}$ and $\omega$-regular 
  $\phi\subseteq S^{\omega}$ there is an \ac{POMDP} $\mathcal{M'}$ with an 
  associated Parity-condition $\parity$ such that any strategy $s$ for 
  $\mathcal{M}$ induces a strategy $s'$ for $\mathcal{M'}$ such that 
  $\mu_{s}(\phi) = \mu_{s'}(\Acc(\parity))$ and vice versa.
  \label{lem:POMDPomegareg}
\end{lemma}
\begin{proof}
  For $\phi$ we can obtain a \ac{DPA} 
  $\mathcal{P} = \tuple{Q, S, q_{0}, \delta, \parity}$ which accepts $\phi$.
  The deterministic nature of $\mathcal{P}$ is used to obtain the result by
  constructing
  \begin{equation*}
    \mathcal{M'} = \tuple{S\times Q, \tuple{s_{0}, q_{0}}, A, 
    \tuple{\tau'_{a}}_{a\in A}, \sim', \parity'}
  \end{equation*}
  with
  \begin{align*}
    &\tau'_{a}(\tuple{s, q}, \tuple{z, p}) = \begin{cases}
      \tau_{a}(s, z)&\text{if }p = \delta(q,s),\\
      0&\text{otherwise,}
    \end{cases}\\
    &\parity'(\tuple{s,q}) = \parity(q)
    \text{ and }
    \tuple{s, q}\sim'\tuple{z, p}\text{ iff }s\sim z.
  \end{align*}
  Since $\sim'$ is defined in terms of the first element of every state, we may
  biject $\interval{s}_{\sim}$ with $\interval{\tuple{s, q}}_{\sim'}$ which 
  allows to translate strategies from $\mathcal{M}$ to $\mathcal{M'}$ and vice
  versa and additionally by definition of $\tau_{a}'$ for all $a\in A$ we 
  obtain for any strategy $s'$ for $\mathcal{M'}$ and its corresponding 
  strategy $s$ for $\mathcal{M}$ that
  \begin{equation*}
    \mu_{s'}(\cyl(\tuple{z_{0}, q_{0}}\dots\tuple{z_{n}, q_{n}})) = 
    \begin{cases}
      \mu_{s}(\cyl(z_{0}\dots z_{n}))&\text{for the unique }
        q_{0}\dots q_{n}\text{ of }\mathcal{P}\text{ on }z,\\
      0&\text{otherwise.}
    \end{cases}
  \end{equation*}
  We may deduce that the first component of all valid, i.e. not impossible, 
  plays in $\mathcal{M}'$ uniquely identifies the second component which allows 
  us to only consider the projection to those \enquote{synchronised} plays 
  which can easily bijected to plays in $\mathcal{M}$ and $s$ and $s'$ even 
  induce the same measure on this bijection. We conclude that
  \begin{equation*}
    \mu_{s}(\phi) = \mu_{s'}(\Acc(\parity)).
  \end{equation*}
\end{proof}

If we actually consider in the argument above that $\mathcal{M}$ is an \ac{MDP} 
then the product construction can be considered to be an \ac{MDP} as well since 
the uniqueness of the second component allows to use the same argument. 
Although the strategies space for $\mathcal{M'}$ are richer, we can only 
consider the space of possible plays which again corresponds uniquely to plays 
in $\mathcal{M}$. We obtain
\begin{corollary}
  For an initial \ac{MDP} $\mathcal{M}$ one obtains a corrresponding \ac{MDP} 
  $\mathcal{M}'$ with the same properties as stated in Lemma 
  \ref{lem:POMDPomegareg}.
\end{corollary}
Moreover, if we consider $\phi$ to be recognizable by a \ac{DBA} we obtain by
the same argument
\begin{corollary}
  For a \ac{DBA}-recognizable $\phi$ and a \ac{POMDP} (\ac{MDP}) $\mathcal{M}$
  the construction from Lemma \ref{lem:POMDPomegareg} yields an \ac{POMDP} 
  (\ac{MDP}) $\mathcal{M'}$ with an associated Büchi-condition.
  \label{cor:POMDPDBA}
\end{corollary}
Concludingly, if we consider that associated Büchi- or Parity-conditions on
\ac{POMDP} induce $\omega$-regular $\phi\subseteq S^{\omega}$ we conclude that
the two formulations are interchangeable. This allows to conclude that 
\ac{DBA}-recognizable $\phi$ allow for strategy synthesis in \acp{POMDP} (cp.
Theorem \ref{thm:pomdpstratsynthesis}) but for general $\omega$-regular $\phi$ 
it is undecideable to compute strategies for \acp{POMDP}. Since we can model 
\acp{POMDP} as \acp{WDTA} (see Theorem \ref{thm:POMDPequivWDTA}) we can 
construct for a \ac{POMDP} 
$\mathcal{M} = \tuple{S, s_{0}, A, \tuple{\tau_{a}}_{a\in A}, \sim}$ and an 
$\omega$-regular $\phi\subseteq S^{\omega}$ which is accepted by \ac{DPA}
$\mathcal{P} = \tuple{Q, q_{0}, S, \delta, \parity}$ a \ac{WDTA} such that the
accepted trees are strategies $s$ for which $\mu_{s}(\phi) = 1$ holds. This
\ac{WDTA} can be obtained by the construction of Theorem 
\ref{thm:POMDPequivWDTA} applied on $\mathcal{M'}$ from above and associating a 
Parity-condition which mirrors $\parity_{\mathcal{P}}$ on the $Q_{\mathcal{P}}$
component. If we want to use this construction to solve the synthesis problem 
we obtain a cylclic argument since the emptiness check for the obtained 
\ac{WDTA} is formulated via strategy synthesis for \acp{POMDP}.

In the following we consider $\phi$ which are defined in terms of \acp{PBA}. 
We observe that \ac{PBA} capture \ac{DBA} by setting every transition function 
to a Dirac measure on $Q$. Hence, solving the synthesis problem for $\phi$ 
which can be expressed as languages of almost-surely accepting \acp{PBA} indeed 
is a proper generalisation of Corollary \ref{cor:POMDPDBA} because the class of 
these $\phi$ is incomparable with $\omega$-regular languages. We examine the 
following question:
\begin{definition}[PBA-Synthesis Question]
  Given a \ac{POMDP} $\mathcal{M}$ and a \ac{PBA} $\mathcal{P}$ with
  \begin{equation*}
    \mathcal{M} = \tuple{S, s_{0}, A, \tuple{\tau_{a}}_{a\in A}, \sim}
  \text{ and }
    \mathcal{P} = \tuple{Q, q_{0}, S, \delta, F}
  \end{equation*}
  exists a strategy $s:\interval{S}_{\sim}^{*}\rightarrow A$ such that 
  almost-all executions of $\mathcal{A}$ under $s$ are accepted by 
  $\mathcal{P}$?
  \label{def:synthesis}
\end{definition}
Considering an almost-sure acceptance condition on $\mathcal{P}$ we can answer
this question positively with
\begin{theorem}[Qualitative PBA Synthesis]
  The synthesis question of an environment $\mathcal{M}$ and a specification
  provided as \ac{PBA} $\mathcal{A}$ with a qualitative acceptance measure
  can be decided.
  \label{thm:pbasynthesis}
\end{theorem}
Considering a certain restricted class of \acp{MDP}, namely those where for 
every state ever following state is defined by a probability distribution $B$
(regardless of the action chosen by the player), then this result can be 
derived as a corollary from the construction examined in Example 
\ref{ex:pwapbaallpaths}. Although the following construction bears structural
similarities with the one presented there, the arguments used here are a little 
more involved.

\begin{proof}
  We fix one strategy $s:\interval{S}_{\sim}^{*}\rightarrow A$ which induces a 
  probability space
  \begin{equation*}
    \tuple{S^{\omega},\mathcal{B}(S), \mu_{s}}.
  \end{equation*}
  Furthermore, for any given $\alpha\in S^{\omega}$ the stochastic process of
  $\mathcal{P}$ also yields a probability space
  \begin{equation*}
    \tuple{Q^{\omega},\mathcal{B}(Q), \mu_{\alpha}}.
  \end{equation*}
  The analytical complexity is rooted in the dependency of $\mu_{\alpha}$ from
  $\alpha$. We approach this dependency in terms of \emph{Markov-kernels}. We
  define (analogously to \cite[Definition 8.25]{Klenke})
  \begin{definition}[Markov-Kernel]
    For two measurable spaces $\tuple{\Omega_{1},\mathcal{F}_{1}}$ and 
    $\tuple{\Omega_{2},\mathcal{F}_{2}}$ a function
    \begin{equation*}
      K:\Omega_{1}\times\mathcal{F}_{2}\rightarrow\interval{0,1}
    \end{equation*}
    is called a Markov-kernel if
    \begin{enumerate}
      \item $K(\cdot, A)$ is measurable in $\mathcal{F_{1}}$ for all 
        $A\in\mathcal{F}_{2}$,
      \item $K(\omega, \cdot)$ is a probability measure on 
        $\tuple{\Omega_{2},\mathcal{F}_{2}}$ for every $\omega\in\Omega_{1}$.
    \end{enumerate}
  \end{definition}
  We define the following Markov-kernel
  \begin{equation*}
    K:S^{\omega}\times\mathcal{B}(Q)\rightarrow\interval{0,1}\text{ with }
      K(\alpha, A) = \mu_{\alpha}(A)
  \end{equation*}
  for the measurable spaces $\tuple{S^{\omega},\mathcal{B}(S)}$ and 
  $\tuple{Q^{\omega},\mathcal{B}(Q)}$. The central inside arises from Lemma 
  \ref{lem:almosteverywhere} which allows us to state
  \begin{equation*}
    \int_{S^{\omega}}K(\cdot, \Acc(F)) d\mu_{s} 
    = \int_{\alpha\in S^{\omega}}\mu_{\alpha}(\Acc(F))d\mu_{s} = 1 \text{ iff }
      \mu_{s}(K(\cdot,\Acc(F))^{-1}(1)) = 1.
  \end{equation*}
  This characterises the synthesis question from Definition \ref{def:synthesis}
  since $\mu_{s}(K(\cdot,\Acc(F))^{-1}(1))$ is the set of executions which are
  accepted by an almost-sure measure by $\mathcal{P}$. Notably, we can assure 
  this statement only under the premise that $K(\cdot, \Acc(F))$ is indeed 
  measurable. This is a direct consequence if $K$ is a Markov-kernel since 
  $\Acc(F)\in\mathcal{B}(Q)$. We address this condition with the following
  \begin{lemma}
    $K$ as defined above is a Markov-kernel.
  \end{lemma}
  \begin{proof}
    With $K(\alpha,\cdot) = \mu_{\alpha}$ it is trivial to state that 
    $K(\alpha,\cdot)$ defines a probability measure for 
    $\tuple{Q^{\omega},\mathcal{B}(Q)}$.

    \cite[Remark 8.26]{Klenke} states that it is sufficient to check the second 
    condition only for sets in a family $\mathcal{E}$ if $\mathcal{E}$ is 
    closed under intersection and contains a sequence of sets 
    $\tuple{E_{i}}_{i\in\mathbb{N}}$ such that $\cup_{i\in\mathbb{N}}E_{i}$ is
    equal to the ground-set. We observed that the cylindric sets 
    $A\in\mathcal{B}(Q)$, i.e. $A = \cyl(u)$ for some $u\in Q^{*}$, satisfy 
    this requirement, hence we restrict the following argument to those.
    Fundamentally, we observe that by definition of the transition 
    probabilities for a \ac{PBA} we obtain a determinism for the run-tree of 
    $\mathcal{P}$, i.e. for any $u\in S^{n}$ and $\alpha, \beta\in\cyl(u)$ that
    \begin{equation*}
      \mu_{\alpha}(\cyl(v)) = \mu_{\beta}(\cyl(v))\text{ for all }v\in Q^{n}.
    \end{equation*}
    This justifies the use of the notion $\mu_{u}$.  Regarding measurability of 
    function we introduce
    \begin{theorem}
      \cite[Theorem 9.2]{Bauer}
      For a measurable space $\tuple{\Omega, \mathcal{F}}$ and a function 
      $f:\Omega\rightarrow\interval{0,1}$ the $\mathcal{F}$-measurability of
      $f$ is equivalent to one of the following conditions
      \begin{enumerate}
        \item for all $a\in\interval{0,1}$ holds 
          $\set{p\in\Omega\mid f(p) < a}\in\mathcal{F}$,
        \item for all $a\in\interval{0,1}$ holds 
          $\set{p\in\Omega\mid f(p) \leq a}\in\mathcal{F}$,
        \item for all $a\in\interval{0,1}$ holds 
          $\set{p\in\Omega\mid f(p) > a}\in\mathcal{F}$,
        \item for all $a\in\interval{0,1}$ holds 
          $\set{p\in\Omega\mid f(p) \geq a}\in\mathcal{F}$.
      \end{enumerate}
    \end{theorem}
    Therefore the measurability of $K(\cdot, \cyl(u))$ is implied if for all 
    $a\in\mathbb{R}$
    \begin{equation*}
      \set{\alpha\in S^{\omega}\mid K(\alpha, \cyl(u))\leq a}\in\mathcal{B}(S).
    \end{equation*}
    Observably,
    \begin{equation*}
      \set{\alpha\in S^{\omega}\mid K(\alpha, \cyl(u))\leq a} = 
        \bigcup\set{
          \cyl(v):u\in S^{\size{u}}\text{ and }\mu_{u}(\cyl(v))\leq a
        }
    \end{equation*}
    implies the necessary membership in $\mathcal{B}(S)$ since $S^{\size{v}}$ 
    is finite.
  \end{proof}
  Having this Markov-kernel $K$ allows us to use the following
  \begin{theorem}
    \cite[Korollar 14.23]{Klenke}
    For a probability space $\tuple{\Omega_{1}, \mathcal{F}_{1}, \mu}$, a
    measurable space $\tuple{\Omega_{2}, \mathcal{F}_{2}}$ and a Markov-kernel
    $K:\Omega_{1}\times\mathcal{F}_{2}$ there exists a unique probability 
    measure $\mu\otimes K$ on $\tuple{\Omega_{1}\times \Omega_{2}, 
    \mathcal{F}_{1}\times\mathcal{F}_{2}}$ with
    \begin{equation*}
      \mu\otimes K(A_{1}, A_{2}) = \int_{A_{1}} K(\omega, A_{2})d\mu
      \text{ for all }A_{1}\in\mathcal{F}_{1}, A_{2}\in\mathcal{F}_{2}.
    \end{equation*}
  \end{theorem}
  
  We proceed in defining an appropiate \ac{WDTA} to capture precisely those 
  strategies which satisfy the synthesis requirement. The concept mirrors the
  resulting \ac{WDTA} when we combine the path measure and the run measure for
  \acp{PWA} (see Example \ref{ex:pwapbaallpaths}) by build run-trees of a 
  \ac{PBA} along the executions. But it is actually not necessary to restrict
  ourselves to one execution step of the \ac{PBA} per direction. This 
  observation is essential for formulating this result for \acp{POMDP} rather 
  than for \acp{MDP} alone.
  \begin{definition}[Synthesis WDTA]
    For a \ac{POMDP} $\mathcal{M}$ and a \ac{PBA} $\mathcal{P}$ with
    \begin{equation*}
      \mathcal{M} = \tuple{S, A, \tuple{\tau_{a}}_{a\in A}, s_{0}, \sim}
      \text{ with }
      \mathcal{O} = \set{\interval{s}_{\sim}: s\in S}
      \text{ and }
      \mathcal{P} = \tuple{Q, S, \delta, q_{0}, F}
    \end{equation*} 
    we construct the choiceless \ac{WDTA}
    \begin{equation*}
      \mathcal{A}_{\mathcal{M}}^{\mathcal{P}} = \tuple{
        S\times Q, \tuple{s_{0}, q_{0}}, A, \mathcal{O}, \Delta, S\times F
      }.
    \end{equation*}
    The transitions in $\Delta$ are of the form
    \begin{equation*}
      \tuple{\tuple{s, q}, a, G_{\tuple{s,q}}^{a}}
      \text{ with }
      G_{\tuple{s,q}}^{a}(\tuple{z,p}, o) = \begin{cases}
        \tau_{a}(s, z)\cdot\delta(q, z, p)&\text{if }\interval{z}_{\sim} = o,\\
        0&\text{otherwise}.
      \end{cases}
    \end{equation*}
  \end{definition}
  Notably, again all trees for this \ac{WDTA} 
  $\mathcal{A}_{\mathcal{M}}^{\mathcal{P}}$ are valid strategies for the 
  \ac{POMDP} $\mathcal{M}$. We fix one tree (or strategie respectively) $s$. 
  For the unique run $r$ of $\mathcal{A}_{\mathcal{M}}^{\mathcal{P}}$ on $s$ we
  can observe (analogously to the construction for Theorem 
  \ref{thm:POMDPequivWDTA}) that the $S$ component of any state uniquely 
  correlates to one $\mathcal{O}$ component and by the definition of 
  $G_{\tuple{s, q}}^{a}$ this is the only direction weight can be passed to.
  Therefore, we restrict our arguments on the weighted part of the domain of
  $r$, namely $\tuple{S\times Q}^{*}$. By definition of the transitions we 
  obtain for any word 
  $\tuple{s_{0}, q_{0}}\dots\tuple{s_{n}, q_{n}}\in\tuple{S\times Q}^{*}$
  \begin{align*}
    \mu_{r}(\tuple{s_{1}, q_{1}}\dots\tuple{s_{n}, q_{n}}) &= 
      G^{s(\epsilon)}(\tuple{s_{1}, q_{1}})\cdot 
      \prod\limits_{i = 1}^{n-1}
        G^{s(\interval{s_{1}\dots s_{n}}_{\sim})}_{\tuple{s_{i}, q_{i}}}(
          s_{i+1}, q_{i+1})\\
    &= \delta(q_{0}, s_{1}, q_{1})\cdot\tau_{s(\epsilon)}(s_{0}, s_{1})
      \prod\limits_{i = 1}^{n-1}
        \delta(q_{i}, s_{i+1}, q_{i+1})\cdot
        \tau_{s(\interval{s_{1}\dots s_{n}}_{\sim})}(s_{i}, s_{i+1})\\
    &= \mu_{s_{1}\dots s_{n}}(\cyl(q_{0}\dots q_{n}))\cdot
      \mu_{s}(\cyl(s_{1}\dots s_{n}))\\
    &= \int_{\cyl(s_{1}\dots s_{n})}K(\cdot, \cyl(q_{0}\dots q_{n}))d\mu_{s}.
  \end{align*}
  This suggests by the uniqueness of $\mu_{s}\otimes K$ and the extension of
  $\mu_{r}$ that these coincide (under renaming of the arguments). It is left
  to examine this renaming for $\mu_{r}$ since $\mu_{r}$ is defined on 
  $\mathcal{B}(S\times Q)$ while $\mu_{s}\otimes K$ is defined on 
  $\mathcal{B}(S)\times\mathcal{B}(Q)$. Not suprisingly, we have
  \begin{lemma}
    $\mathcal{B}(S\times Q)$ and $\mathcal{B}(S)\times\mathcal{B}(Q)$ are 
    equivalent up to renaming.
  \end{lemma}
  \begin{proof}
    From Theorem \ref{thm:productgen} we know that 
    $\mathcal{B}(S)\times\mathcal{B}(Q)$ is generated by $\cyl(u)\times\cyl(v)$ 
    for all $u\in S^{*}$ and $v\in Q^{*}$. We show that we may 
    \enquote{balance} these generating sets (cp. Lemma \ref{lem:balancedruns}). 
    W.l.o.g. we assume $\size{u} < \size{v}$. From $m = \size{v} - \size{u}$ we 
    generate the set $E = \set{u\cdot y:y\in S^{m}}$. Since $S$ is finite so is 
    $E$ and we may use the generating sets $\cyl(u')\times\cyl(v)$ for all 
    $u'\in E$ to obtain the same set as $\cyl(u)\times\cyl(v)$. Hence, we may 
    restrict our generating sets to balanced cylindric sets. We may biject 
    tuple $\tuple{s_{1}\dots s_{n}, q_{1}\dots q_{n}}$ to 
    $\tuple{s_{1}, q_{1}}\dots \tuple{s_{n}, q_{n}}$ (even up to infinity) and
    obtain a bijection between the generating sets for $\mathcal{B}(S\times Q)$
    and $\mathcal{B}(S)\times\mathcal{B}(Q)$ which survives the construction of
    all elements in the algebra. This allows us to transform the both algebras
    into each other and additionally shows that $\mu_{s}\otimes K$ indeed
    coincides with $\mu_{r}$.
  \end{proof}
  Concludingly, we can observe for the acceptance meausure of 
  $\mathcal{A}_{\mathcal{M}}^{\mathcal{P}}$ 
  \begin{equation*}
    \mu_{r}(\Acc\interval{Q}(S\times F))  
    = \mu_{s}\otimes K(S^{\omega}, \Acc(F))
    = \int_{\alpha\in S^{\omega}}\mu_{\alpha}(\Acc(F)) d\mu_{s}.
  \end{equation*}
  This allows us to state that $\mathcal{A}_{\mathcal{M}}^{\mathcal{P}}$ 
  accepts $s$ if and only if $s$ is a solution to the synthesis question for 
  the \ac{POMDP} $\mathcal{M}$ and the \ac{PBA} $\mathcal{P}$. We may use
  Corollary \ref{cor:emptiness} to compute this $s$.
\end{proof}
Although inspired by the arguments of Theorem \ref{thm:PWAasWDTA}, the usage 
of \acp{WDTA} is not essential for the argument above. Equivalently Lemma 
\ref{lem:POMDPomegareg} can be extended towards $\phi$ which
are defineable by almost-surely accepting \acp{PBA} by the natural product 
construction: we consider a \ac{POMDP} $\mathcal{M}$ and a \ac{PBA} 
$\mathcal{P}$ with
\begin{equation*}
  \mathcal{M} = \tuple{S, s_{0}, A, \tuple{\tau_{a}}_{a\in A}, \sim}
  \text{ and }
  \mathcal{P} = \tuple{Q, q_{0}, S, \delta, F}
\end{equation*}
and construct a product \ac{POMDP}
\begin{equation*}
  \mathcal{M}\otimes\mathcal{P} = \tuple{S\times Q, \tuple{s_{0}, q_{0}}, A,
    \tuple{\tau'_{a}}_{a\in A}, \sim', F' = S\times F}
\end{equation*}
with
\begin{equation*}
  \tau'_{a}(\tuple{s, q}, \tuple{z, p}) = \tau_{a}(s, z)\cdot\delta(q, s, p)
  \text{ and }
  \tuple{s, q}\sim'\tuple{z, p}\text{ iff }s\sim z.
\end{equation*}
The correctness argument is analogously to the argument which involve 
\acp{WDTA} above. In this setup \acp{MDP} are also transformed to \ac{POMDP} 
since the construction needs to hide the current state of $\mathcal{P}$ and we
do not have a determinism argument as before since \acp{PBA} have in general
possibly multiple following states.
