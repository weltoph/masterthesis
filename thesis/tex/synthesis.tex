\chapter{Synthesis}
\label{chapter:synthesis}
The synthesis problem is formulated in \cite{Church} as the question if for a 
given logical formula, we call this specification, we can derive an algorithm
which behavior is \enquote{good} in the sense of the formula. We formalize this
question in the following
\begin{definition}[Synthesis Problem]
  Given a logical specification  $\phi(\cdot, \cdot)$ over inputs and
  outputs from $I^{\omega}$ and $J^{\omega}$ respectively. The synthesis
  problem requires to compute for any $\phi$ an algorithm
  $S:I^{+}\rightarrow J$ such that for every
  $\alpha_{1}\alpha_{2}\dots\in I^{\omega}$ and every
  $S(\alpha) = S(\alpha_{1})S(\alpha_{1}\alpha_{2})\dots$ satisfies
  $\phi(I, S(I))$ or prove that such an $S$ cannot exist (cp. the
  illustration in Figure \ref{fig:synthesis}).
\end{definition}
\begin{drawing}
  \caption{Illustration of the synthesis question. The aim is to provide an 
  algorithm which \enquote{synthesises} for any specification a strategy or 
  proves that there cannot exist a strategy that satisfies the specification.}
  \label{fig:synthesis}
  \begin{center}
    \includegraphics{tikz/synthesis.pdf}
  \end{center}
\end{drawing}
Naturally, the complexity of this problem is tightly related to the 
expressiveness of $\phi$. The comprehensive demand of this question, namely
to generate for all inputs a \enquote{good} output, allows for a
game-theoretic formulation. As suggested in \cite{SeqCondStrat} we can consider
the environment as antagonistic and formulate the synthesis question in terms
of strategies, i.e. one player generates inputs while another player generates
outputs. We call these players \inputp{} and \outputp{} respectively. The game
unfolds by \inputp{} sequentially choosing inputs $i_{1}i_{2}\dots$ and 
\outputp{} reacting by $j_{1}j_{2}\dots$. Thus, a play
\begin{center}
  \begin{tabular}{cccc}
    $i_{1}$ & $i_{2}$ & $i_{3}$ & \dots\\
    $j_{1}$ & $j_{2}$ & $j_{3}$ & \dots
  \end{tabular}
\end{center}
forms and \outputp{} wins if and only if 
$\phi(i_{1}i_{2}\dots,j_{1}j_{2}\dots)$ evaluates to true. Strategies of 
\outputp{} are usually described as functions $f:I^{+}\rightarrow J$ such that
\outputp{} plays at position $n>0$ the output-symbol 
$f(i_{1}\dots i_{n}) = j_{n}$. In this sense we are interested in winning 
strategies of \outputp{}. Following, we present known synthesis results 
for those $\phi$ which allow to capture the associated relation as a 
$\omega$-regular language. Subsequently, we pivot towards specifications given
as almost-surely accepting \acp{PBA}. Afterwards, we consider environments for
which we assume probabilistic behavior. These environments allow to state the
synthesis problem for almost-sure satisfaction of $\phi$. At last, we model
probabilistic environments more explicit as \acp{POMDP}. We try to compute
strategies for these that almost-surely satisfy given specifications.

\section{Antagonisitic Environments}
Initially, we consider an $\omega$-regular class of specifications
$\phi$ for inputs $I$ and outputs $J$. Hence, we assume the existence of an
$\omega$-regular language $\mathcal{L}_{\phi}\subseteq
\tuple{J\times I}^{\omega}$ with
\begin{equation}
  \tuple{j_{0}, i_{0}}\tuple{j_{1}, i_{1}}\dots\in\mathcal{L}_{\phi}
  \text{ if and only if }
  \phi(i_{0}i_{1}\dots, j_{1}j_{2}\dots)\text{ is true.}
  \label{eq:omegaregularphi}
\end{equation}
Notably, the output symbol $j_{0}$ is irrelevant but included to ease the
technicalities of the following argument. With the well-researched theory of
tree automata the associated synthesis problem for $\omega$-regular
specifications can be solved transparently. In fact, it is one of the
initial motivations to study tree automata \cite{AutoInfObj}. The idea is to
use trees to model the interaction between input and output symbols. The
directions of a tree model inputs while the symbols in the tree represent
outputs. Similar to the arguments of the proof of Theorem
\ref{thm:POMDPequivWDTA}, a tree models a strategy. We design a \ac{PTA} such
that a tree is accepted if and only if all paths are part of
$\mathcal{L}_{\phi}$. We model this in analogy to \cite[Lemma 15]{AutoInfObj}
with
\begin{definition}[Synthesis \ac{PTA}]
  For a given \ac{DPA}
  \begin{equation*}
    \mathcal{P} = \tuple{Q, q_{0}, J\times I, \delta, \parity}
  \end{equation*}
  we define a \ac{PTA}
  \begin{equation*}
    \mathcal{A} = \tuple{Q, q_{0}, I, J, \Delta, \parity}
  \end{equation*}
  where $\Delta$ contains transtitions $\tuple{q, j, (p_{i})_{i\in I}}$ with
  $p_{i} = \delta(q, \tuple{j, i})$.
\end{definition}
Notably, $\mathcal{A}$ executes $\mathcal{P}$ on every path and therefore, if
we choose $\mathcal{P}$ as the \ac{DPA} which precisely accepts
$\mathcal{L}_{\phi}$, we deduce that $\mathcal{A}$ accepts only those trees
that satisfy $\phi$ on all paths. This implies that $\mathcal{A}$ accepts those
strategies $t$ which satisfy $\phi$. Hence, constructing (see above) and
deciding the emptiness (see Theorem \ref{thm:emptinessPTA}) for $\mathcal{A}$
yields the desired synthesis algorithm for $\omega$-regular specifications
$\phi$ and gives
\begin{theorem}
  \cite[Theorem 21, Theorem 22]{AutoInfObj}
  The synthesis problem for $\omega$-regular specifications $\phi$ is
  decidable.

  If a strategy exists and $\phi$ is captured by a \ac{DPA}
  \begin{equation*}
    \mathcal{P} = \tuple{Q, q_{0}, J\times I, \delta, \parity}
  \end{equation*}
  then we can compute such a strategy in time in 
  $\mathcal{O}(\size{\parity(Q)}\cdot\size{Q\times Q}\cdot\tuple{
    \frac{\size{Q}}{d}}^{d})$ with 
  $d = \lfloor \frac{\size{\parity(Q)}}{2} \rfloor$.
  \label{thm:omeregsynthesis}
\end{theorem}
This approach suits the game-theoretic interpretation of the synthesis problem
well. Consider the associated emptiness-game to the defined \ac{PTA}
$\mathcal{A}$. Since $\mathcal{A}$ shows deterministic behavior, we express
\eve{}'s strategy by choosing a letter rather than a transition. The transition
is uniquely identified by the letter due to $\mathcal{A}$'s determinism. Also,
\adam{}'s role is always captured by choosing a direction the game moves to.
Therefore, \eve{}'s and \adam{}'s correspond to the behavior of \outputp{}
and \inputp{} respectively while the \ac{DPA} that is associated with $\phi$ is
executed on every play of the input-output game.

In the following, we consider specifications $\phi$ which are not
$\omega$-regular but definable by almost-surely accepting \acp{PBA}. In
analogy to the formulation (\ref{eq:omegaregularphi}) above, we assume for
$\phi$ the existence of an almost-surely accepting \ac{PBA} $\mathcal{P}$
such that
\begin{equation}
  \tuple{j_{0}, i_{0}}\tuple{j_{1}, i_{1}}\dots\text{ is accepted by }
  \mathcal{P} \text{ if and only if }
  \phi(i_{0}i_{1}\dots, j_{1}j_{2}\dots)\text{ is true.}
  \label{eq:pbaregularphi}
\end{equation}
Specifically, we emphasize that probabilistic behavior is not considered
anywhere else but the specification. Notably, we consider deterministic
strategies for \outputp{}.

We model our approach in close connection to the game-theoretic interpretation
of Theorem \ref{thm:omeregsynthesis}. This entails introducing a new class of
graph games, called \acp{POSG} (cp. \cite{POSG, PureStratPOSG}). We draw
motivation from the behavior of \acp{POMDP} and introduce a proper
generalisation. \acp{POMDP} essentially are graph-games between \eve{} and a
second player, called \random{}. The game unfolds by \eve{} specifying with her
action a set of possible successors and \random{} choosing one of these
successors. However, although \eve{} may base her choice on the history of the
play \random{} is restricted to randomized positional strategies only (encoded
in the transition probabilities). Therefore, \random{} is reffered to as a
half-player and \acp{POMDP} as $1\frac{1}{2}$-player games \cite{POSG}.

We introduce \ac{POSG} as $2\frac{1}{2}$-player games by introducing a
\enquote{full}-player \adam{} as enemy of \eve{}. The game unfolds in very
similar fashion to \acp{POMDP} but at every position \eve{} \emph{and} \adam{}
simultaneously and independently choose an action and \random{} reacts by a
randomized positional strategy. We formalize this in
\begin{definition}[\acl{POSG}]
  A \ac{POSG}-arena $G$ is defined by a set of states $S$ (with an 
  inital state $s_{0}\in S$), actions for \eve{} and \adam{} as $E$ and $A$ 
  respectively, transition probabilities $\tuple{\tau_{e,a}}_{e\in E, a\in A}$ 
  and equivalence classes $\sim_{E}$ and $\sim_{A}$ restricting the 
  observations of \eve{} and \adam{} respectively. We obtain
  \begin{equation*}
    G = \tuple{S, s_{0}, E, A, \tuple{\tau_{e,a}}_{e\in E, a\in A}, 
    \sim_{E}, \sim_{A}}
  \end{equation*}
  with
  \begin{equation*}
    \tau_{e,a}:S\times S\rightarrow\interval{0,1} \text{ s. t. }
    \tau_{e,a}(s, \cdot)\in\mathcal{D}(S)\text{ for all }a\in A, e\in E.
  \end{equation*}
  A strategy for \eve{} (\adam{}) is defined as 
  $f:\interval{S}_{\sim_{E}}^{*}\rightarrow E$ 
  ($g:\interval{S}_{\sim_{A}}^{*}\rightarrow A$). For any such pair of 
  strategies $f$ and $g$ we obtain a probability space
  \begin{equation*}
    \tuple{S^{\omega}, \mathcal{B}(S), \mu_{f, g}}.
  \end{equation*}
  A \ac{POSG} is defined by an arena $G$ and an associated language
  $\Acc\subseteq S^{\omega}$ forming $\mathcal{G} = \tuple{G, \Acc}$. Notably,
  $\mathcal{G}$ is a zero-sum game, i.e. \eve{} tries to obtain a play in 
  $\Acc$ while \adam{} tries to force plays in $S^{\omega}\setminus\Acc$.
\end{definition}
We restrict $\Acc$ to be defined as Parity-, Rabin-, Muller-
or Büchi-condition which directly ensures its measurability. In similar sense
as for graph games we consider a strategy $f$ for \eve{} almost-surely
(postively) winning if for all strategies $g$ of \adam{} we have
$\mu_{f,g}(\Acc) = 1$ ($\mu_{f,g}(\Acc) > 0$). The natural initial observation
that \adam{}'s role can be reduced to oblivion by only granting him a single
action allows to capture the notions of \acp{POMDP}. This entails strong
restrictions regarding algorithmic approaches for computing strategies for
\eve{}.
\begin{corollary}
  \cite{PureStratPOSG, POSG}
  For a given \ac{POSG} $\mathcal{G} = \tuple{G, \Acc}$ the following problems
  are undecidable:
  \begin{itemize}
    \item Exists a positively winning strategy for \eve{} if $\Acc$ is defined 
      as Büchi-, Parity-, Rabin- or Muller-condition?
    \item Exists an almost-surely winning strategy for \eve{} if $\Acc$ is
      defined as Parity-, Rabin- or Muller-condition?
  \end{itemize}
\end{corollary}
\begin{proof}
  These are immediate consequences of the negligibility (not in the sense of
  measurability theory but in the game-theoretic sense) of \adam{}'s actions
  and Theorem \ref{thm:emptinesspospba} (or the respective Corollary 
  \ref{cor:posstratpomdp}).
\end{proof}
In order to reduce the complexity of our arguments we only consider \acp{POSG}
where \eve{} and \adam{} are \emph{equally informed}, i.e.
$\sim_{E} = \sim_{A}$. Similar to \acp{POMDP}, almost-surely winning strategies
for \eve{} in \ac{POSG} with Büchi-conditions are \enquote{simple} enough to
allow for computation of winning strategies.
\begin{theorem}
  \cite[Theorem 6]{POSG}\cite[Theorem 5.3]{PureStratPOSG}\footnote{
    Since it was unclear if the publication of this paper preceeded the
    completion of this thesis, we included the relevant arguments in Appendix
    \ref{app:POSG} to ensure their availability. Especially, since we rely on
    the contained arguments for the claimed complexity bound.
  }
  It is possible to decide if there is an almost-surely winning strategy for 
  \eve{} in a \ac{POSG} $\mathcal{G} = \tuple{G, F}$ where $F$ is a 
  Büchi-condition and $\sim_{E} = \sim_{A}$.

  This decision procedure takes time doubly exponential in $\size{S}$.
  \label{thm:StratPOSG}
\end{theorem}
This allows us to answer the synthesis question imposed by an almost-surely
accepting \ac{PBA} $\mathcal{P}$ as specification positively for antagonistic
environments. The idea is to define a \ac{POSG} in which both players only
observe an input-output game while the stoachastic process of $\mathcal{P}$
unfolds in the \enquote{background}. Any play is eventually evaluated in terms
of acceptance of $\mathcal{P}$. Formally, for a fixed almost-surely accepting
\ac{PBA}
\begin{equation*}
  \mathcal{P} = \tuple{Q, q_{0}, I\times J, \delta, F'}
\end{equation*}
we define
\begin{definition}[\ac{POSG} for $\mathcal{P}$]
  Set
  \begin{equation*}
    \mathcal{G}_{\mathcal{P}} = \tuple{I\times Q\times J\uplus\set{q_{0}}, J,
      I, \tuple{\tau_{j,i}}_{j\in J,i\in I}, \sim_{E}, \sim_{A}, F}
  \end{equation*}
  with
  \begin{equation*}
    \sim = \sim_{E} = \sim_{A} = \set{\tuple{\tuple{i, q, j}, 
    \tuple{i', q', j'}}\in \tuple{I\times Q\times J}^{2}\mid i = i', j = j'}
  \end{equation*}
  Moreover, we fix $F = I\times F'\times J$ and
  \begin{equation*}
    \tau_{j',i'}(\tuple{i, q, j}, \tuple{o, p, u}) = \begin{cases}
      \delta(q, \tuple{i', j'}, p)&\text{if }o = i', u = j',\\
      0&\text{otherwise},
    \end{cases}
  \end{equation*}
  where $q_{0}$ is treated as $\tuple{i, q_{0}, j}$ for any $i\in I, j\in J$.
\end{definition}
Here \eve{} corresponds with \outputp{} while \adam{} plays the role of
\inputp{}. Central to this argument is that regarding the observations of
\eve{} and \adam{} $\mathcal{G}_{\mathcal{P}}$ presents as input-output game.
Setting $S = I\times Q\times J$ we observe by definition of $\sim$ that we can
partition $S$ into $\set{\interval{\tuple{i, *, o}}_{\sim}:i\in I, o\in J}$
where $\interval{\tuple{i, *, o}}_{\sim}$ describes the equivalence class
$\set{\tuple{i, q, o}:q\in Q}$. By definition of all $\tau_{j,i}$ we obtain
$\supp(\tau_{j,i}(s, \cdot))\subseteq\interval{\tuple{i,*,j}}_{\sim}$. Hence,
every strategy for \eve{} (\adam{}) presents as function
$f:\tuple{I\times J}^{*}\rightarrow J$ 
($g:\tuple{I\times J}^{*}\rightarrow I$). The only stochastic process in this
game is associated with the state component which is observed neither by 
\eve{} nor by \adam{}. This allows us to deduce that any pair of 
strategies $f$ and $g$ for \eve{} and \adam{} respectively induce one unique
word $\alpha_{f}^{g}\in\tuple{I\times J}^{\omega}$. Moreover, we can consider
a subset of $\mathcal{B}(I\times Q\times J)$ which is induced by 
$\alpha_{f}^{g} = \tuple{i_{1}, j_{1}}\tuple{i_{2}, j_{2}}\dots$. Namely, we 
define two sets
\begin{align*}
  F &= \bigcap_{k>0}\bigcup_{
    \substack{
      p_{1}\dots p_{k}\in Q^{k}\\
      u_{1}\dots u_{k}\in J^{k}
    }
  }\cyl(\tuple{i_{1}, p_{1}, u_{1}}\dots\tuple{i_{k}, p_{k}, u_{k}})\\
  G &= \bigcap_{k>0}\bigcup_{
    \substack{
      p_{1}\dots p_{k}\in Q^{k}\\
      u_{1}\dots u_{k}\in I^{k}
    }
  }\cyl(\tuple{u_{1}, p_{1}, j_{1}}\dots\tuple{u_{k}, p_{k}, j_{k}}).
\end{align*}
By definition $F$ and $G$ are measurable sets in
$\mathcal{B}(I\times Q\times J)$ such that the $J$-component respectively the
$I$-component agrees with $\alpha_{f}^{g}$. Moreover, by definition of
$\tau_{i, j}$ for all $i\in I, j\in J$ we deduce that
\begin{equation}
  \mu_{f,g}(C) = 0\text{ for all }
  C\notin\restrictTo{\mathcal{B}(I\times Q\times J)}{F\cap G}.
  \label{eq:weightinFG}
\end{equation}
The central idea of this proof is formulated in
\begin{lemma}
  $\tuple{Q^{\omega}, \mathcal{B}(Q), \mu_{\alpha_{f}^{g}}}$ can be
  isomorphically embedded into
  \begin{equation*}
    \tuple{\tuple{I\times Q\times J}^{\omega}, \mathcal{B}(I\times Q\times J),
    \mu_{f,g}}.
  \end{equation*}
  \label{lem:fginpba}
\end{lemma}
\begin{proof}
  We propose the following bijection
  \begin{equation*}
    \inpout:Q^{\omega}\rightarrow\restrictTo{\mathcal{B}(I\times Q\times J)}
      {F\cap G}\text{ with }
    \inpout(q_{1}q_{2}\dots) = \tuple{i_{1}, q_{1}, j_{1}}
      \tuple{i_{2}, q_{2}, j_{2}}\dots.
  \end{equation*}
  We observe that $\restrictTo{\mathcal{B}(I\times Q\times J)}{F\cap G}$ can
  be generated by all cylindric sets
  \begin{equation*}
    \cyl(\tuple{i_{1}, p_{1}, j_{1}}\dots\tuple{i_{n}, p_{n}, j_{n}})
    \cap F\cap G \text{ for }p_{1}\dots p_{n}\in Q^{*}. 
  \end{equation*}
  Notably, it holds 
  \begin{equation*}
    \io(\cyl(p_{1}\dots p_{n})) = \cyl(\tuple{i_{1}, p_{1}, j_{1}}\dots
  \tuple{i_{n}, p_{n}, j_{n}})\cap F\cap G.
  \end{equation*}
  Hence, we biject the generating $\mathcal{B}(Q)$ and 
  $\restrictTo{\mathcal{B}(I\times Q\times J)}{F\cap G}$ sets and obtain
  similar to the proof of Lemma \ref{lem:liftisomorphism} the measurability of
  $\inpout$ as well as $\inpout^{-1}$.

  We show that $\mu_{f,g}$ coincides with
  $\mu_{\alpha_{f}^{g}}\circ\inpout^{-1}$
  on $\restrictTo{\mathcal{B}(I\times Q\times J)}{F\cap G}$ which induces the
  required embedding by Equation \ref{eq:weightinFG}. For a fixed sequence
  $p_{1}\dots p_{n}\in Q^{*}$ we have
  \begin{align*}
    \mu_{\alpha_{f}^{g}}(\cyl(p_{1}\dots p_{n})) 
    &= \delta(q_{0}, \tuple{i_{1}, j_{1}}, p_{1})
      \prod\limits_{1\leq k < n}\delta(p_{k}, \tuple{i_{k+1}, j_{k+1}}, 
        p_{k+1})\\
    &= \tau_{j_{1}, i_{1}}(q_{0}, \tuple{i_{1}, p_{1}, j_{1}})
      \prod\limits_{1\leq k < n}\tau_{j_{k}, i_{k}}(\tuple{i_{k}, p_{k}, 
        j_{k}},\tuple{i_{k+1}, p_{k+1}, j_{k+1}})\\
    &= \mu_{f, g}(\underbrace{\cyl(\tuple{i_{1}, p_{1}, j_{1}}
      \dots\tuple{i_{n}, p_{n}, j_{n}})\cap F\cap G}_{
        = \io(\cyl(p_{1}\dots p_{n}))
      }).
  \end{align*}
  Hence, by unique extension of $\mu_{\alpha_{f}^{g}}$ and $\mu_{f,g}$ the
  claim follows.
\end{proof}

This leads us into characterising almost-surely winning strategies for \eve{}
in $\mathcal{G}_{\mathcal{P}}$ in
\begin{lemma}
  A strategy $f$ in $\mathcal{G}_{\mathcal{P}}$ is almost-surely winning for
  \eve{} if and only if $f$ synthesizes an algorithm for the associated 
  specification $\phi_{\mathcal{P}}$.
\end{lemma}
\begin{proof}
  Initially, we observe that for a fixed strategy $f$ every input
  $\beta = \beta_{0}\beta_{1}\dots\in I^{\omega}$ describes one strategy of 
  \adam{} by setting $g(u) = \beta_{\size{u}}$. On the other hand, we obtain
  for every possible strategy $g$ one sequence of inputs, namely the 
  $I$-projection of $\alpha_{f}^{g}$. Hence, the strategy space of \adam{}
  coincides with all possible input-sequences. 

  Moreover, using Equation \ref{eq:weightinFG} and Lemma \ref{lem:fginpba} we
  state
  \begin{align*}
    \mu_{\alpha_{f}^{g}}(\Acc(F'))
    &= \mu_{\alpha_{f}^{g}}(\inpout(\Acc(F'))) &\\
    &= \mu_{f,g}(\Acc(F)\cap F\cap G) &\text{Lemma \ref{lem:fginpba}}\\
    &= \mu_{f,g}(\Acc(F)) &\text{Equation (\ref{eq:weightinFG})}.
  \end{align*}

  Therefore, given an almost-surely winning strategy $f$ for \eve{} we get
  for every $g$ that $\mu_{f,g}(\Acc(F)) = 1$. Hence, 
  $\mu_{\alpha_{f}^{g}}(\Acc(F')) = 1$ and therefore, $\alpha_{f}^{g}$ is
  accepted by $\mathcal{P}$. This means that every possible input-sequence
  $\beta$ is met with an output-sequence $\gamma$ such that
  $\phi_{\mathcal{P}}(\beta, \gamma)$ evaluates to true.

  If on the other hand $f$ is not almost-surely winning for \eve{} there is a
  riposte $g$ of \adam{} such that $\mu_{f,g}(\Acc(F)) < 1$. Hence,
  $\mu_{\alpha_{f}^{g}}(\Acc(F')) < 1$ and therefore the non-acceptance of
  $\alpha_{f}^{g}$ by $\mathcal{P}$. This implies that \adam{} can generate an
  input-sequence $\beta$ such that \eve{} generates the output-sequence
  $\gamma$ but $\phi_{\mathcal{P}}(\beta, \gamma)$ evaluates to false.
\end{proof}

By this characterisation of winning strategies of \eve{} in 
$\mathcal{G}_{\mathcal{P}}$ we immediately may conclude
\begin{theorem}
  For any almost-surely accepting \ac{PBA} 
  \begin{equation*}
    \mathcal{P} = \tuple{Q, q_{0}, I\times J, \delta, F'}
  \end{equation*}
  the synthesis problem for the specification $\phi$ imposed by $\mathcal{P}$
  (as in (\ref{eq:pbaregularphi})) is decidable. If a strategy exists it can
  be computed in time doubly exponential in
  $\size{I}\cdot \size{Q}\cdot \size{J} + 1$.
  \label{thm:pbastratpomdpsynthesis}
\end{theorem}
\begin{proof}
  Using Theorem \ref{thm:StratPOSG} on $\mathcal{G}_{\mathcal{P}}$ gives the
  desired decision procedure.
\end{proof}

This result actually is intriguing in the sense that we consider a
probabilistic specification but obtain a \emph{deterministic} algorithm which
surely shows desired behavior. We consider the following
\begin{example}
  Reconsider the \ac{PBA} examined in Example \ref{ex:almostsureacceptingpba}.
  We alter this \ac{PBA} slightly to obtain a specification which is defined in
  terms of an \ac{PBA} by replacing $a$-elements by those occurences where the
  ouput differs from the last input and $b$-elements by occurences where the 
  output mirrors the input. The initial output is dismissed (as suggested by
  (\ref{eq:pbaregularphi})). The resulting almost-surely accepting \ac{PBA} is
  illustrated in Figure \ref{fig:synthesispba}. And the derived input-output 
  game is shown in Figure \ref{fig:synthesispbagame}.
  \label{ex:pbasynthesis}
\end{example}
\begin{drawing}
  \caption{
    Specification-PBA for Example \ref{ex:pbasynthesis} (based on the PBA 
    depicted in Figure \ref{fig:almostsureacceptingpba}). Consider 
    $I = J =\set{0,1}$ where the superscript $i$ represents a storage for every
    state (realised by using two states, e.g. $q_{0}^{0}$ and $q_{0}^{1}$) 
    which holds the last read input symbol. The output symbols either mirrors 
    the stored symbol ($i$) or inverts it ($\overline{i}$), while the input 
    $i'$ is always stored within the state. Initially, the output is irrelevant 
    for the transition (indicated by $*$).
  }
  \label{fig:synthesispba}
  \begin{center}
    \includegraphics{tikz/synthesispba.pdf}
  \end{center}
\end{drawing}

\begin{drawing}
  \caption{
    Game graph for a POSG that resolves around the PBA defined in Figure 
    \ref{fig:synthesispba}. \adam{} and \eve{} only observe the layer they play
    in but never the $Q$-component. On the other hand, regarding the evaluation 
    every state with common $Q$-component is treated equally, hence the 
    underlaying PBA only observes the colors. The local storage of the states
    of the underlying PBA are dismissed since the stored input value already 
    uniquely identifies the \enquote{correct} state. Thus, technically we have
    e.g. $q_{0}^{0}$ and $q_{0}^{0}$ but the choice of \adam{} $e$ only allows
    movements to $q_{0}^{e}$, hence we dismissed unreachable states. Similarly,
    we removed the unreachabe $(i, q_{0}, j)$ for the \emph{original} $q_{0}$ 
    state (not for the $q_{0}^{0}, q_{0}^{1}$ states).
  }
  \label{fig:synthesispbagame}
  \begin{center}
    \includegraphics{tikz/synthesispbagame.pdf}
  \end{center}
\end{drawing}

\section{Stochastic Environments}
Another approach is introduced in \cite{SynProbEnv} by considering environments
which do not act antagonistically but probabilistically, i.e. we assume that
inputs are generated by a probabilistic process. We explore the usage of
alternating tree automata to address this problem. Specifically, their close
connection to games is essential to the following considerations. We formulate
the concept of $\epsilon$-environments. For an $\epsilon > 0$ such an
environment generates an input $i$ with a certain probability which respects at
any time $\epsilon$ as lowerbound. The form of the strategy that is meant to be
synthesised is given as a $J$-labeled $I$-tansition-system $\mathcal{T}$ of the
form
\begin{equation*}
  \mathcal{T} = \tuple{S, s_{0}, \tau, \ell}.
\end{equation*}
Here $S$ is a set of states, $s_{0}$ an inital state and
$\tau:S\times I\rightarrow S$ describes a deterministic transition function and
$\ell:S\rightarrow J$ a labelling of $S$. Semantically, $\mathcal{T}$ starts in
$s_{0}$ and reacts to an input $i$ by moving to $z = \tau(s,i)$ and outputting
$\ell(z)$. Naturally, such a transition system $\mathcal{T}$ models a strategy
$t:I^{+}\rightarrow J$ by constructing for every
$u = u_{1}\dots u_{n}\in I^{+}$ the unique sequence
$s_{0}s_{1}\dots s_{n}\in S^{+}$ such that $s_{i+1} = \tau(s_{i}, u_{i+1})$ for
$0\leq i<n$ and returning $\ell(s_{n})$. As mentioned in the introduction of
Section \ref{subsec:ata} alternating tree automata can be used to run on the
unfolding of such transition systems. Assuming a $\omega$-regular specification 
$\phi$ we may obtain a \ac{DPA}
$\mathcal{P} = \tuple{Q, q_{0}, \tuple{J\times I}, \delta, \parity}$ accepting
$\mathcal{L}_{\phi}$. We can attach $\mathcal{P}$ onto a given transition
system $\mathcal{T}$ in a straightforward manner to obtain a transition system
with an associated Parity-condition (but dropping the labelling)
\begin{equation*}
  \mathcal{G}_{\mathcal{P}}^{\mathcal{T}} = \tuple{S\times Q,
    \tuple{s_{0}, q_{0}}, \tau', \parity'}
\end{equation*}
where $\tau'(\tuple{s, q}, i) = \tuple{\tau(s, i),
\delta(q, \tuple{\ell(s), i})}$ and $\parity'(\tuple{s, q}) = \parity(q)$. For
this transition system and an $\epsilon$-environment $\mathcal{E}$ we can
identify structural properties in $\mathcal{G}_{\mathcal{P}}^{\mathcal{T}}$ to
determine whether $\mathcal{T}$ satisfies $\phi$ almost-surely respectively
positively. This structural property is connected with \ac{SCC}. These are
subsets of nodes $G$ such that there is a path between every two nodes
$u,v\in G$ (cp. \cite{Tarjan}). Additionally, a leaf-\ac{SCC} is an \ac{SCC}
$S$ such that there is no other \ac{SCC} reachable from any $v\in S$ (cp.
\cite[Bottom-\ac{SCC}]{ComplexProbVerification}). Intuitively, it is unlikely
to not eventually end up in a leaf-\acp{SCC} since there is infinitely often
the possibility to take a non-zero probability into smaller \acp{SCC}. Hence we
state
\begin{lemma}
  \cite[Lemma 1]{SynProbEnv}
  An $J$-labeled $I$-transition-system $\mathcal{T}$ almost-surely (positively)
  satisfies a specification $\phi$ if and only if the highest priority in all
  (some) reachable leaf-\ac{SCC} of $\mathcal{G}_{\mathcal{P}}^{\mathcal{T}}$
  is even, where $\mathcal{P}$ is a \ac{DPA} accepting $\mathcal{L}_{\phi}$.
  \label{lem:structuralprobability}
\end{lemma}
This structual property can be checked by a \ac{APTA}. This again yields an
algorithm for the synthesis problem of almost-sure (respectively positive)
satisfaction of an $\omega$-regular $\phi$ by checking emptiness of the
obtained \ac{APTA}. Therefore, we obtain
\begin{theorem}
  \cite[Theorem 1]{SynProbEnv}
  Given a \ac{DPA} $\mathcal{P}$ there is a \ac{APTA} 
  $\mathcal{A}_{\mathcal{P}}$ ($\mathcal{O}_{\mathcal{P}}$) such that 
  $\mathcal{A}_{\mathcal{P}}$ ($\mathcal{O}_{\mathcal{P}}$) accepts a 
  $J$-labeled $I$-transition-system $\mathcal{T}$ if and only 
  if\footnote{The original theorem only states the if-direction but the 
  corresponding proof deals with the only if-direction as well.} $\mathcal{T}$ 
  satisfies almost-surely (positively) $\mathcal{P}$.

  If $\mathcal{P}$ has $n$ states and $c$ parities then 
  $\mathcal{A}_{\mathcal{P}}$ and $\mathcal{O}_{\mathcal{P}}$ have at most
  $n\cdot\lceil 2 + \frac{c}{2}\rceil + 1$ states.
  \label{thm:probenvsynthesis}
\end{theorem}
\begin{proof}[Proof-Sketch]
  The main argument for this proof is that the search for the leaf-\acp{SCC}
  can be understood as a two-player-game. One player plays for acceptance
  (called \acceptor{}) while the other tries to spoil the correctness of the
  transition system (called \spoiler{}). We describe the case of
  $\mathcal{A}_{\mathcal{P}}$ but the case $\mathcal{O}_{\mathcal{P}}$ can be
  constructed analogously by exchanging the player role in the first phase of
  the game. The game for $\mathcal{T}$ in the $\mathcal{A}_{\mathcal{P}}$
  operates in three phases:
  \begin{enumerate}
    \item \spoiler{} chooses one leaf-\ac{SCC} $S$,
    \item \acceptor{} chooses one priority $p$ of a node in $S$,
    \item \spoiler{} tries to find a higher priority than $p$ in $S$.
  \end{enumerate}
  The unrollment of $\mathcal{T}$ yields an $I$-ary $J$-tree. The states of
  $\mathcal{A}_{\mathcal{P}}$ encode the current state of $\mathcal{P}$ and if
  the game is in the first, second or third phase. If the game is in the third
  phase the chosen priority is also stored in the state. While operating in the
  first phase $\mathcal{A}_{\mathcal{P}}$ dispatches in all directions
  first-phase states, representing possible choices of \spoiler{} and also in
  one direction a second-phase state; that is a second phase state which is
  only dispatched into one direction, representing the choice of
  \acceptor{}. This second-phase state may transform at any point to a
  third-phase state and store the (even) priority of the current
  state of $\mathcal{P}$ in the state of $\mathcal{A}_{\mathcal{P}}$. This
  third-phase state again dispatches in all directions and as soon as one state
  with a higher parity than the stored one appears, moves to a
  sink-error-state. The first-phase states are given a parity of $0$, the
  second-phase states of $1$ and the third-phase states of $2$. This allows
  that for all choices of \spoiler{} (which constantly reproduce themselves)
  only those that proceed to the second phase actually matter or for the
  third-phase only the occurence of a higher parity. Since the parity of the
  second-phase states is odd it is enforced that \acceptor{} eventually chooses
  one parity to store. Note the similarity to the proof of Proposition
  \ref{prop:atanegation} in formulating the desired winning strategy of one
  player as actual choices which may use the non-determinism of the automaton
  while the \spoiler{} explores all possible moves.
\end{proof}
This allows us to solve the associated synthesis problem for $\omega$-regular
specifications and $\epsilon$-environments. By solving emptiness for a 
\acp{APTA}.

On the other hand, we consider in the following environments that are
represented by \acp{MDP} or \acp{POMDP} and try to synthesis for a given
specification a strategy to almost-surely or positively satisfy this
specification. This approach is conceptually different to
$\epsilon$-environments since concrete probabilities are given and also the
interaction of the actor with the environment is explicitly modelled. We
formalize the synthesis question with (cp. \cite{QualAnaPOMDP,%
SimpleStochasticParityGames, ComplexProbVerification})
\begin{definition}
  Given a \ac{POMDP}
  \begin{equation*}
    \mathcal{M} = \tuple{S, s_{0}, A, \tuple{\tau_{a}}_{a\in A}, \sim}
  \end{equation*}
  and a specification $\phi\subseteq S^{\omega}$ such that
  $\phi\in\mathcal{B}(S)$. The qualitative synthesis problem
  $\tuple{M, \phi}$ demands the computation of a strategie
  $s:\interval{S}_{\sim}^{*}\rightarrow A$ such that $\mu_{s}(\phi) = 1$.
\end{definition}
Theorem \ref{thm:pomdpstratsynthesis} and Theorem \ref{thm:mdpstratsynthesis}
already formulated positive results for this question. Again, we focus on
$\omega$-regular $\phi$ (in this case $\phi$ is itself a language
and is not translated to one). Note that the formulation in Theorem 
\ref{thm:pomdpstratsynthesis} and Theorem \ref{thm:mdpstratsynthesis} use 
acceptance conditions directly onto the states of the \ac{POMDP} and \ac{MDP}
respectively. Initially, we observe that these formulations are interchangable:
In analogy to the constructions in \cite{ComplexProbVerification,%
MDPandRegEvents} we fix a \ac{POMDP}
\begin{equation*}
  \mathcal{M} = \tuple{S, s_{0}, A, \tuple{\tau_{a}}_{a\in A}, \sim}
\end{equation*}
and a $\omega$-regular $\phi\subseteq S^{\omega}$. Let
$\mathcal{P} = \tuple{Q, S, q_{0}, \delta, \parity}$ be a \ac{DPA} which
accepts $\phi$. We construct
\begin{equation*}
  \mathcal{M}\otimes\mathcal{P} = \tuple{S\times Q, \tuple{s_{0}, q_{0}}, A, 
  \tuple{\tau'_{a}}_{a\in A}, \sim', \parity'}
\end{equation*}
with
\begin{align*}
  &\tau'_{a}(\tuple{s, q}, \tuple{z, p}) = \begin{cases}
    \tau_{a}(s, z)&\text{if }p = \delta(q,s),\\
    0&\text{otherwise,}
  \end{cases}\\
  &\parity'(\tuple{s,q}) = \parity(q)
  \text{ and }
  \tuple{s, q}\sim'\tuple{z, p}\text{ iff }s\sim z.
\end{align*}
We observe that the definition of $\sim'$ allows to identify
$\interval{\tuple{s,q}}_{\sim'}$ with $\interval{s}_{\sim}$ and therefore, the
strategy spaces for $\mathcal{M}$ and $\mathcal{M}\otimes\mathcal{P}$ coincide.
Central to the following argument is the following
\begin{lemma}
  For any strategy $s:\interval{S}_{\sim}^{*}\rightarrow A$ the resulting
  probability space $\tuple{S^{\omega}, \mathcal{B}(S), \mu_{s}}$ can be
  isomorphically embedded into 
  $\tuple{\tuple{S\times Q}^{\omega}, \mathcal{B}(S\times Q), \mu_{s}'}$.
  \label{lem:embedphiintopomdp}
\end{lemma}
\begin{proof}
  We define the following function $f:S^{\omega}\rightarrow
  \tuple{S\times Q}^{\omega}$ with
  \begin{equation*}
    f(s_{1}s_{2}\dots) = \tuple{s_{1}, q_{1}}\tuple{s_{2}, q_{2}}\dots
    \text{ such that }
    \delta(q_{i-1}, s_{i-1}) = q_{i}\text{ for all }i>0.
  \end{equation*}
  Moreover, we consider the two isomorphic probability spaces
  \begin{equation*}
    \tuple{S^{\omega}, \mathcal{B}(S), \mu_{s}}
  \end{equation*} and 
  \begin{equation*}
    \tuple{f(S^{\omega}), \restrictTo{\mathcal{B}(S\times Q)}{f(S^{\omega})},
      \mu_{s}\circ f^{-1}}
  \end{equation*}
  by the isomorphism $f$. By definition of $\tau_{a}'$ for
  all $a\in A$ and inductive reasoning, we observe
  \begin{equation*}
    \mu_{s}'(\cyl(\tuple{s_{1}, q_{1}}\dots\tuple{s_{n}, q_{n}})) = 
    \begin{cases}
      \prod\limits_{0\leq i<n}\tau_{s(s_{1}\dots s_{i})}(s_{i}, s_{i+1})
        &\substack{\text{for the unique parital run }\\q_{0}\dots q_{n}
          \text{ of }\mathcal{P}\text{ on }s_{0}\dots s_{n}},\\
      0&\text{otherwise}.
    \end{cases}
  \end{equation*}
  Hence, it is easy to see that on the generating sets of
  $\restrictTo{\mathcal{B}(S\times Q)}{f(S^{\omega})}$ the measures $\mu_{s}'$
  and $\mu_{s}\circ f$ coincide. Therefore, the claim follows by unique
  extension of $\mu_{s}'$ and $\mu_{s}\circ f^{-1}$.
\end{proof}
This leads to
\begin{theorem}
  The problems to compute a strategy for a \ac{POMDP} with states $S$ which
  almost-surely (positively) satisfies an $\omega$-regular strategy
  $\phi\subseteq S^{\omega}$ and to compute a strategy for a \ac{POMDP} which
  almost-surely (positively) satisfies an associated Parity-condition are
  effectively reducable to each other.
  \label{thm:POMDPomegareg}
\end{theorem}
\begin{proof}
  It is easy to obtain from an associated Parity-condition an $\omega$-regular
  language by simply considering $\Acc(\parity)$ for which the measures
  coincide.

  For the converse, we consider $\mathcal{M}\otimes\mathcal{P}$ and use Lemma
  \ref{lem:embedphiintopomdp}. Moreover, we observe that
  $f(\phi) = \Acc(\parity)\cap f(S^{\omega})$ which entails
  $\mu_{s}(\phi) = \mu_{s}'(\Acc(\parity))$.
\end{proof}

If we consider the construction $\mathcal{M}\otimes\mathcal{P}$ for a \ac{MDP}
$\mathcal{M}$ we observe by the uniqueness of the associated state sequences
that the argumentation of Lemma \ref{lem:embedphiintopomdp} still applies if we
consider $\mathcal{M}\otimes\mathcal{P}$ to be a \ac{MDP} as well. This allows
to state
\begin{corollary}
  The problems to compute a strategy for a \ac{MDP} with states $S$ which
  almost-surely (positively) satisfies an $\omega$-regular strategy
  $\phi\subseteq S^{\omega}$ and to compute a strategy for a \ac{MDP} which
  almost-surely (positively) satisfies an associated Parity-condition are
  effectively reducable to each other.
  \label{thm:MDPomegareg}
\end{corollary}
Moreover, if we consider $\phi$ to be recognizable by a \ac{DBA} we state by
the same argument
\begin{corollary}
  The problems to compute a strategy for a \ac{POMDP} with states $S$ which
  almost-surely (positively) satisfies a \ac{DBA}-recognizable $\phi\subseteq
  S^{\omega}$ and to compute a strategy for a \ac{POMDP} which almost-surely
  (positively) satisfies an associated Büchi-condition are effectively
  reducable to each other.
  \label{cor:POMDPDBA}
\end{corollary}
We note here that by the results of Theorem \ref{thm:pomdpstratsynthesis} and
Theorem \ref{thm:mdpstratsynthesis} it is possible to synthesis strategies for
positive and almost-sure satisfaction of $\omega$-regular $\phi$ in \acp{MDP}
and almost-sure satisfaction for \ac{DBA}-recognizable $\phi$ in \acp{POMDP}.
The conceptual idea of Lemma \ref{lem:structuralprobability} is essential for
the algorithm of Theorem \ref{thm:mdpstratsynthesis} by identifying strategies
which move into \acp{SCC} which are winning for \eve{}
\cite{QuanStochParityGames}. On the other hand, we observe that for \acp{POMDP}
and almost-sure satisfaction we are restricted to \ac{DBA}-recognizable
specifications by the undecidability results of Corollary
\ref{cor:posstratpomdp}. However, we consider $\phi$ which are defined in terms
of almost-surely accepting \acp{PBA}. By Proposition \ref{prop:pbasubsumesdba}
we know that almost-surely accepting \acp{PBA} subsumes the expressiveness of
\acp{DBA}. Hence, solving the synthesis problem for $\phi$ which can be
expressed as languages of almost-surely accepting \acp{PBA} is a generalisation
of Corollary \ref{cor:POMDPDBA} by the stronger expressiveness of almost-surely
accepting \acp{PBA} over \acp{DBA}. Formally, we examine the following
problem:
\begin{definition}[PBA-Synthesis Question]
  Given a \ac{POMDP} $\mathcal{M}$ and a \ac{PBA} $\mathcal{P}$ with
  \begin{equation*}
    \mathcal{M} = \tuple{S, s_{0}, A, \tuple{\tau_{a}}_{a\in A}, \sim}
  \text{ and }
    \mathcal{P} = \tuple{Q, q_{0}, S, \delta, F}.
  \end{equation*}
  Does a strategy $s:\interval{S}_{\sim}^{*}\rightarrow A$ exist such that
  almost-all executions of $\mathcal{A}$ under $s$ are almost-surely accepted
  by $\mathcal{P}$?
  \label{def:pbastratsynthesis}
\end{definition}
Considering a certain restricted class of \acp{MDP}, namely those where for
every state ever following state is defined by a probability distribution $B$
(regardless of the action chosen by the player), then this result can be
derived as a corollary from the construction examined in Example
\ref{ex:pwapbaallpaths}. This construction is the main inspiration of the
following argument. Mainly, we unroll the run-trees of \ac{PBA} along state
sequences of an \ac{MDP}. Recalling that in Theorem \ref{thm:omeregsynthesis}
the inputs are identifies with the directions along a tree, this idea presents
very similar. We strengthen our result to apply for \acp{POMDP} by merging
directions of equivalent observation.

For the rest of the section, we fix one \ac{POMDP} $\mathcal{M}$ and a \ac{PBA}
$\mathcal{P}$ with
\begin{equation*}
  \mathcal{M} = \tuple{S, s_{0}, A, \tuple{\tau_{a}}_{a\in A}, \sim}
\text{ and }
  \mathcal{P} = \tuple{Q, q_{0}, S, \delta, F}.
\end{equation*}
Additionally, we consider one strategy $s:\interval{S}_{\sim}^{*}\rightarrow A$
which induces a probability space for $\mathcal{M}$
\begin{equation*}
  \tuple{S^{\omega},\mathcal{B}(S), \mu_{s}}.
\end{equation*}
Furthermore, for any given $\alpha\in S^{\omega}$ the stochastic process of
$\mathcal{P}$ also yields a probability space
\begin{equation*}
  \tuple{Q^{\omega},\mathcal{B}(Q), \mu_{\alpha}}.
\end{equation*}
We approach the mathematical analysis of this problem by defining the following
Markov-kernel
\begin{equation*}
  K:S^{\omega}\times\mathcal{B}(Q)\rightarrow\interval{0,1}\text{ with }
    K(\alpha, A) = \mu_{\alpha}(A)
\end{equation*}
for the measurable spaces $\tuple{S^{\omega},\mathcal{B}(S)}$ and
$\tuple{Q^{\omega},\mathcal{B}(Q)}$. Initially, we observe
\begin{lemma}
  $K$ as defined above is a Markov-kernel.
\end{lemma}
\begin{proof}
  With $K(\alpha,\cdot) = \mu_{\alpha}$ it is trivial to state that
  $K(\alpha,\cdot)$ defines a probability measure for
  $\tuple{Q^{\omega},\mathcal{B}(Q)}$.

  By Lemma \ref{lem:markovkernelgeneratingsets} it suffices to check that
  $K(\cdot, B)$ is $\mathcal{B}(S)$-measurable only for cylindric sets $B$,
  i.e. $B = \cyl(u)$ for some $u\in S^{*}$.

  We observe that by definition of the transition probabilities for a \ac{PBA}
  we obtain a determinism for the run-tree of $\mathcal{P}$. This means that
  for any $u\in S^{n}$ and $\alpha, \beta\in\cyl(u)$ holds
  \begin{equation*}
    \mu_{\alpha}(\cyl(v)) = \mu_{\beta}(\cyl(v))\text{ for all }v\in
      \cup_{1\leq i\leq n}Q^{i}.
  \end{equation*}
  This justifies the use of the notion $\mu_{u}$ for the probabilities of all
  cylindric sets $A = \cyl(v)$ for all $v\in Q^{*}$ with
  $\size{v}\leq\size{u}$. By Theorem \ref{thm:measurabilitybyintervals} the
  measurability of $K(\cdot, \cyl(u))$ is implied if for all $a\in\mathbb{R}$
  \begin{equation*}
    \set{\alpha\in S^{\omega}\mid K(\alpha, \cyl(u))\leq a}\in\mathcal{B}(S).
  \end{equation*}
  This follows from the representation as
  \begin{equation*}
    \set{\alpha\in S^{\omega}\mid K(\alpha, \cyl(u))\leq a} = 
      \bigcup\set{
        \cyl(v):v\in S^{\size{u}}\text{ with }\mu_{v}(\cyl(u))\leq a
      }
  \end{equation*}
  since $S^{\size{v}}$ is finite. Concludingly, we obtain that $K$ is indeed a
  Markov-kernel.
\end{proof}

Observing that
\begin{equation*}
  K(\cdot,\Acc(F))^{-1}(1) = \set{
    \alpha\in S^{\omega}\mid\mu_{\alpha}(\Acc(F)) = 1
  }
\end{equation*}
is the set of executions which are almost-surely accepted by $\mathcal{P}$,
allows us to state for $K$ and Lemma \ref{lem:almosteverywhere}
\begin{equation*}
  \int_{S^{\omega}}K(\cdot, \Acc(F)) d\mu_{s}
  = \int_{\alpha\in S^{\omega}}\mu_{\alpha}(\Acc(F))d\mu_{s} = 1 \text{ iff }
    \mu_{s}(K(\cdot,\Acc(F))^{-1}(1)) = 1.
\end{equation*}
Hence, a strategy $s$ is an answer to the synthesis question of Definition
\ref{def:pbastratsynthesis} if and only if
$\int_{S^{\omega}}K(\cdot, \Acc(F)) d\mu_{s} = 1$.
Using Theorem \ref{thm:kernelmeasure} allows us to refine this notion further.
Considering the probability space $\tuple{S^{\omega}\times Q^{\omega},
\mathcal{B}(S)\otimes\mathcal{B}(Q), \mu_{s}\otimes K}$, we obtain that
\begin{equation*}
  \int_{S^{\omega}}K(\cdot, \Acc(F)) d\mu_{s} = 
    \tuple{\mu_{s}\otimes K}(S^{\omega}, \Acc(F)).
\end{equation*}
Concludingly giving
\begin{lemma}
  The strategy $s$ is an answer to an instance of the synthesis question of
  Definition \ref{def:pbastratsynthesis} if and only if
  \begin{equation*}
    \tuple{\mu_{s}\otimes K}(S^{\omega}, \Acc(F)) = 1.
  \end{equation*}
  \label{lem:pbysynthesisbymuK}
\end{lemma}

We proceed by defining a choiceless \ac{WDTA} which captures this product
space:
\begin{definition}[Synthesis WDTA]
  For a \ac{POMDP} $\mathcal{M}$ and a \ac{PBA} $\mathcal{P}$ with
  \begin{equation*}
    \mathcal{M} = \tuple{S, A, \tuple{\tau_{a}}_{a\in A}, s_{0}, \sim}
    \text{ with }
    \mathcal{O} = \set{\interval{s}_{\sim}: s\in S}
    \text{ and }
    \mathcal{P} = \tuple{Q, S, \delta, q_{0}, F}
  \end{equation*} 
  we construct the choiceless \ac{WDTA}
  \begin{equation*}
    \mathcal{A}_{\mathcal{M}}^{\mathcal{P}} = \tuple{
      S\times Q, \tuple{s_{0}, q_{0}}, A, \mathcal{O}, \Delta, S\times F
    }.
  \end{equation*}
  The transitions in $\Delta$ are of the form
  \begin{equation*}
    \tuple{\tuple{s, q}, a, G_{\tuple{s,q}}^{a}}
    \text{ with }
    G_{\tuple{s,q}}^{a}(\tuple{z,p}, o) = \begin{cases}
      \tau_{a}(s, z)\cdot\delta(q, z, p)&\text{if }\interval{z}_{\sim} = o,\\
      0&\text{otherwise}.
    \end{cases}
  \end{equation*}
\end{definition}
Similar to the construction in Section \ref{sec:modellingpomdp}, all trees for
this \ac{WDTA} $\mathcal{A}_{\mathcal{M}}^{\mathcal{P}}$ are valid strategies
for the \ac{POMDP} $\mathcal{M}$ and vice versa. For one tree $s$ we fix the
unique run $r$ of $\mathcal{A}_{\mathcal{M}}^{\mathcal{P}}$ on $s$.
We formulate the following essential
\begin{lemma}
  The probability space $\tuple{S^{\omega}\times Q^{\omega},
  \mathcal{B}(S)\otimes\mathcal{B}(Q), \mu_{s}\otimes K}$ can be isomorphically
  embedded into $\tuple{\tuple{\tuple{S\times Q}\times O}^{\omega},
  \mathcal{B}(\tuple{S\times Q}\times O), \mu_{r}}$.
  \label{lem:embedmuK}
\end{lemma}
\begin{proof}
  Initially, we consider an isomorphism $b$ between
  $\tuple{S^{\omega}\times Q^{\omega}, \mathcal{B}(S)\otimes\mathcal{B}(Q),
  \mu_{s}\otimes K}$ and $\tuple{\tuple{S\times Q}^{\omega},
  \mathcal{B}(S\times Q), \mu_{s}\otimes K\circ b^{-1}}$. Therefore, we define
  \begin{equation*}
    b:S^{\omega}\times Q^{\omega}\rightarrow\tuple{S\times Q}^{\omega}
    \text{ with }b(\alpha_{1}\alpha_{2}\dots, \beta_{1}\beta_{2}\dots) = 
      \tuple{\alpha_{1}, \beta_{1}}\tuple{\alpha_{2}, \beta_{2}}\dots.
  \end{equation*}
  Lemma \ref{lem:productborelalgebras} states that
  $\mathcal{B}(S)\otimes\mathcal{B}(Q)$ is generated by balanced cylindric
  sets. Considering two words $u = a_{1}\dots a_{n}\in A^{*}$ and
  $v = b_{1}\dots b_{n}\in B^{*}$, allows to observe that
  \begin{equation*}
    b(\cyl(u)\times\cyl(v)) = \cyl(\tuple{a_{1}, b_{1}}\dots
      \tuple{a_{n}, b_{n}}).
  \end{equation*}
  Therefore, we get the required measurability for $b$ and $b^{-1}$ by
  construction of measurable sets in the Borel-algebras. Hence, the claimed
  isomorphism follows by definition of the measure
  $\mu_{s}\otimes K\circ b^{-1}$.

  Using Lemma \ref{lem:liftisomorphism} with the function
  $\obs:S\times Q\rightarrow O$ such that $\obs(s, q) = \interval{s}_{\sim}$
  yields an isomorphic embedding of
  \begin{equation*}
    \tuple{S^{\omega}\times Q^{\omega}, 
      \mathcal{B}(S)\otimes\mathcal{B}(Q), \mu_{s}\otimes K}
  \end{equation*}
  into 
  \begin{equation*}
    \tuple{\tuple{\tuple{S\times Q}\times O}^{\omega}, \mathcal{B}(
    \tuple{S\times Q}\times O), \mu_{s}\otimes K\circ b^{-1}\circ\lift_{\obs}^{-1}}.
  \end{equation*}
  Hence, it suffices to show that
  $\mu_{s}\otimes K\circ b^{-1}\circ\lift_{\obs}^{-1}$ coincides with $\mu_{r}$
  on all cylindric sets $\cyl(\tuple{\tuple{s_{1}, q_{1}}, o_{1}}\dots
  \tuple{\tuple{s_{n}, q_{n}}, o_{n}})$. Inductive reasoning on all
  generators in $\mathcal{G}(\mathcal{A}_{\mathcal{M}}^{\mathcal{P}})$ shows
  that weight only moves along paths such that the $O$-component agrees with
  the observation of the $S$-component. Therefore, we state if 
  $o_{i} = \interval{s_{i}}_{\sim}$ for all $1\leq i\leq n$
  \begin{align*}
    \mu_{r}(&\cyl(\tuple{\tuple{s_{1}, q_{1}}, o_{1}}
      \dots\tuple{\tuple{s_{n}, q_{n}}, o_{n}})) \\
    &= G^{s(\epsilon)}_{\tuple{s_{0}, q_{0}}}(
      \tuple{\tuple{s_{1}, q_{1}}, o_{1}})\cdot 
      \prod\limits_{i = 1}^{n-1}G^{s(o_{1}\dots o_{i})}_{\tuple{s_{i}, q_{i}}}(
        \tuple{s_{i+1}, q_{i+1}}, o_{i+1})\\
    &= \delta(q_{0}, s_{1}, q_{1})\cdot\tau_{s(\epsilon)}(s_{0}, s_{1})
      \prod\limits_{i = 1}^{n-1}
        \delta(q_{i}, s_{i+1}, q_{i+1})\cdot
        \tau_{s(o_{1}\dots o_{n})}(s_{i}, s_{i+1})\\
    &= \mu_{s_{1}\dots s_{n}}(\cyl(q_{0}\dots q_{n}))\cdot
      \mu_{s}(\cyl(s_{1}\dots s_{n}))\\
    &= \int_{\cyl(s_{1}\dots s_{n})}K(\cdot, \cyl(q_{0}\dots q_{n}))d\mu_{s}.
  \end{align*}
  By the observation that
  \begin{equation*}
    \cyl(\tuple{\tuple{s_{1}, q_{1}}, o_{1}}
    \dots\tuple{\tuple{s_{n}, q_{n}}, o_{n}}) = 
    \lift_{\obs}\circ b(\cyl(s_{1}\dots s_{n}), \cyl(q_{1}\dots q_{n}))
  \end{equation*}
  and the uniqueness of $\mu_{s}\otimes K$ and the extension of $\mu_{r}$, the
  claim follows.
\end{proof}

Concludingly, we state
\begin{theorem}[Qualitative PBA Synthesis]
  The synthesis question of an environment $\mathcal{M}$ and a specification
  provided as almost-surely accepting \ac{PBA} $\mathcal{A}$ is decidable.
  \label{thm:pbasynthesis}
\end{theorem}
\begin{proof}
  We claim that constructing $\mathcal{A}_{\mathcal{M}}^{\mathcal{P}}$ and
  deciding its emptiness (Corollary \ref{cor:emptiness}) yields the required
  decision procedure. Therefore, we observe
  \begin{equation*}
    \tuple{\lift_{\obs}\circ b}(S^{\omega}, \Acc(F)) = 
      (\Acc\interval{S\times Q}(S\times F))
      \cap(\lift_{\obs}\circ b)(S^{\omega}, Q^{\omega})
  \end{equation*}
  which implies  for the unique run $r$ on a tree $t$ that
  \begin{equation*}
    \mu_{r}(\Acc\interval{S\times Q}(S\times F))
    = \mu_{s}\otimes K(S^{\omega}, \Acc(F)).
  \end{equation*}
  Hence, with Lemma \ref{lem:pbysynthesisbymuK} we have that 
  $\mathcal{A}_{\mathcal{M}}^{\mathcal{P}}$ almost-surely accepts $t$ if and
  only if $t$ solves the synthesis question imposed by $\mathcal{M}$ and
  $\mathcal{P}$.
\end{proof}

Although inspired by the construction of Theorem \ref{thm:PWAasWDTA}, the usage 
of \acp{WDTA} is not essential for the argument above. Equivalently Theorem
\ref{thm:POMDPomegareg} can be extended towards $\phi$ which
are defineable by almost-surely accepting \acp{PBA} by the natural product
construction: we consider a \ac{POMDP} $\mathcal{M}$ and a \ac{PBA}
$\mathcal{P}$ with
\begin{equation*}
  \mathcal{M} = \tuple{S, s_{0}, A, \tuple{\tau_{a}}_{a\in A}, \sim}
  \text{ and }
  \mathcal{P} = \tuple{Q, q_{0}, S, \delta, F}
\end{equation*}
and construct a product \ac{POMDP}
\begin{equation*}
  \mathcal{M}\otimes\mathcal{P} = \tuple{S\times Q, \tuple{s_{0}, q_{0}}, A,
    \tuple{\tau'_{a}}_{a\in A}, \sim', F' = S\times F}
\end{equation*}
with
\begin{equation*}
  \tau'_{a}(\tuple{s, q}, \tuple{z, p}) = \tau_{a}(s, z)\cdot\delta(q, s, p)
  \text{ and }
  \tuple{s, q}\sim'\tuple{z, p}\text{ iff }s\sim z.
\end{equation*}
This argument removes the use of $\lift_{\obs}$ in the proof of Lemma
\ref{lem:embedmuK} and renders for any strategy $s$ which are transferable by
the choice of $\sim'$ the probability spaces for $\mathcal{M}$ with measure
$\mu_{s}\otimes K$ and $\mathcal{M}\otimes\mathcal{P}$ with measure $\mu_{s}$
isomorphic. The correctness argument is analogous to the argument which involve
\acp{WDTA} above. In this setup \acp{MDP} are also transformed to \acp{POMDP}
since the construction needs to hide the current state of $\mathcal{P}$.
Specifically, \acp{PBA} have in general possibly multiple following states in
their run-tree. Nevertheless, this yields a \ac{POMDP} with
states $S' = Q\times S$ and allows to compute the corresponding $s$ in
time exponential of $\size{S'}$. Effectively, we get
\begin{corollary}
  If a strategy for the qualitative synthesis problem for a \ac{POMDP} with
  states $S$ and a specification in form of an almost-surely accepting \ac{PBA} 
  with states $Q$ exists it can be computed in time exponential in 
  $\size{Q\times S}$.
\end{corollary}
This is a notable improvement over the argument resolving around \acp{WDTA}
since the associated time complexity there is exponential in
$\size{S}\times\size{Q}\times\size{\interval{S}_{\sim}}$ (cp. Corollary 
\ref{cor:emptiness}).
