Replacing non-deterministic choices by probabilistic ones in \acp{NBA} yields
a new class of word automata, namely \aclp{PBA} (cp. \cite{RecOmeLangProbAuto,%
DecProblemsForProbAuto,Groesser}). A \ac{PBA} essentially is an \ac{NBA} where
the non-deterministic oracle acts probabilistically. Therefore, we define
analogously to \cite{Groesser}
\begin{definition}[Probabilistic Büchi Automata]
  A \ac{PBA} $\mathcal{A}$ over a finite alphabet $\Sigma$ is defined by a
  tuple $\tuple{Q, \Sigma, \delta, q_{0}, F}$ where $Q$ is a finite state set,
  $q_{0}\in Q$ the initial state,
    $\delta:Q\times\Sigma\times Q\rightarrow \interval{0,1}$
  a transition probability function such that for all pairs $q\in Q$ and
  $\sigma\in\Sigma$ we have $\sum_{p\in Q}\delta(q,\sigma,p) = 1$
  and $F\subseteq Q$ is the set of final states.
\end{definition}
Conceptually, a \ac{PBA} $\mathcal{P}$ processes an input word similarly as 
other word automata by sequentially reading the letters of the input word and 
moving along its states. Provided the current state is $q$ and the next letter 
of the input word is $a$ then $\mathcal{P}$ consults $\delta$ to determine its 
next state. Specifically, $\mathcal{P}$ chooses a state $p$ with probability
$\delta(q,a,p)$. Naturally, any run of $\mathcal{P}$ starts in its initial
state $q_{0}$. Considering one fixed input word $\alpha$ the \ac{PBA} 
$\mathcal{P}$ provides a process which produces corresponding state sequences 
with certain probabilities (see Figure \ref{fig:pbaruns} for an illustration).
\begin{drawing}
  \caption{Illustration of the stochastic process of a \ac{PBA} $\mathcal{P}$
  with two states $q_{0}, q_{1}$ on a word $\alpha\in\Sigma^{\omega}$ with
  transition probabilities defined by $\delta$.}
  \label{fig:pbaruns}
  \begin{center}
    \includegraphics{tikz/pbaruns.pdf}
  \end{center}
\end{drawing}
Its acceptance is defined by the notion of how probable the produced state
sequences are to satisfy the associated Büchi-condition $F$. For a \ac{PBA} 
$\mathcal{P} = \tuple{Q, q_{0}, \delta, F}$ we are interested in a probability 
space that is induced by the run of $\mathcal{P}$ on the base set $Q^{\omega}$ 
while reading the input word $\alpha$. For the cylindric sets $\cyl(u)$ for any
$u\in Q^{*}$ (see Figure \ref{fig:cylinder} for an illustration) we obtain the
probability to stay within this cylinder while reading a finite prefix of the
input word.
\begin{drawing}
  \caption{All infinite sequences of states $\set{q_{1},\dots, q_{k}}$ can be
  organised in a tree. In this tree the set $\cyl(u_{1}\dots u_{n})$ are all 
  possible prolongations of the initial sequence $u_{1}\dots u_{n}$ as 
  illustrated by the blue path and attached cylinder.}
  \label{fig:cylinder}
  \begin{center}
  % \resizebox{\textwidth}{!}{
    \includegraphics{tikz/cylinder.pdf}
  % }
  \end{center}
\end{drawing}
Let $v = u_{0}\dots u_{n}$ be such a finite prefix of $\alpha$.
For any sequence $q_{1}q_{2}\dots q_{n}$ the run of $\mathcal{P}$
on $\alpha$ stays within $\cyl(q_{1}\dots q_{n})$ with the probability to
move along the path $q_{0}q_{1}\dots q_{n}$ while reading $u_{1}\dots u_{n}$.
This is the product of the probabilities to move from $q_{i-1}$ to $q_{i}$
while reading $u_{i}$ for $1\leq i\leq n$: 
$\prod_{1\leq i\leq n}\delta(q_{i-1},u_{i},q_{i})$. 

Given an input word $\alpha$ and using the Borel-algebra $\mathcal{B}(Q)$ and 
the probability for staying in a cylinder for $\alpha$ allows to use Theorem
\ref{thm:measureext} to fix a probability space
\begin{equation*}
  \tuple{Q^{\omega}, \mathcal{B}(Q), \mu_{\alpha}}.
\end{equation*}
In which the acceptance of $\alpha$ is encoded by the probability of the set
\begin{equation*}
  \Acc(F) = \set{
    \alpha\in Q^{\omega}\mid\alpha\text{ satisfies the Büchi-condition }F}.
\end{equation*}
Therefore, it is necessary to show that this set indeed is measureable. This is
known from e.g. \cite[Chapter 4.1.1.]{Groesser} but we present a proof here
which follows \cite[Proposition 6]{RandAutoInfTrees} since this argument can be
easily presented and is re-used later in a more involved context.
\begin{lemma}[Measurability]
  The set $\Acc(F)$ for a Büchi-condition $F\subseteq Q$ is measurable in 
  $\mathcal{B}(Q)$.
  \label{lem:measureabilityAcceptance}
\end{lemma}
\begin{proof}
  In order to show the measureability of $\Acc(F)$ we formulate it at as
  Boolean combination of cylinders inducing its membership in the
  Borel-algebra by the closure properties of a $\sigma$-algebra.
  Initially, we start with a co-Büchi-condition (recall Example \ref{ex:fina}),
  i.e. those words which eventually do not visit a target set $T$ anymore. More 
  precisely, such a set $T$ defines the accepted language as
  \begin{equation*}
    \Acc_{\cobuechi}(T) = Q^{*}\tuple{Q\setminus T}^{\omega}.
  \end{equation*}
  We claim that
  \begin{equation}
    \Acc_{\cobuechi}(T) = \bigcup\limits_{u\in Q^{*}}(
    \cyl(u)\setminus\bigcup\limits_{v\in u\cdot Q^{*}T}\cyl(v))
    \label{eq:measureability}
  \end{equation}
  which renders $\Acc_{\cobuechi}(T)$ measurable as countable union of 
  measurable sets. For $\beta\in\Acc_{\cobuechi}(T)$ we know that there is 
  eventually no occurence of $T$ anymore. This induces that there is one finite
  prefix $u\sqsubseteq\beta$ such that any prolongation of $u$ in $\beta$ does
  not contain a state of $T$, hence it holds that
  $\beta\notin\bigcup\limits_{v\in u\cdot Q^{*}T}\cyl(v)$. Consequently, 
  $\beta$ is element of the right hand side of Equation
  \ref{eq:measureability}. On the other hand if
  $\beta\notin\Acc_{\cobuechi}(T)$ we know that for every finite prefix
  $u\sqsubseteq\beta$ there is a (finite) prolongation
  $u\sqsubseteq v\sqsubseteq\beta$ such that $v\in u\cdot Q^{*}T$. This $v$ 
  removes $\beta$ from $\cyl(u)$. This gives that $\beta$ is not element of the 
  right hand side of Equation \ref{eq:measureability} which proves the 
  announced equality. For any Büchi-condition $F\subseteq Q$ we use its duality 
  to the co-Büchi-condition $T = Q\setminus F$, i.e.
  \begin{equation*}
    \Acc_{\buechi}(F) = Q^{\omega}\setminus\Acc_{\cobuechi}(T),
  \end{equation*}
  to obtain the measureability of $\Acc(F)$ by the closure of $\mathcal{B}(Q)$
  under complementation and the proven measureability of $\Acc_{\cobuechi}(T)$.
\end{proof}

Since we explicitly defined \acp{PBA} with Büchi-conditions this suffices to
show their definition to be useful. But it is a natural escalation to consider
more elaborate acceptance conditions, e.g. Muller-, Parity- or
Rabin-conditions. We show the measureability of those sets here as well, since
it is a easy consequence of Lemma \ref{lem:measureabilityAcceptance} (cp. again
\cite[Proposition 6]{RandAutoInfTrees}).
\begin{corollary}
  For a Muller-condition, a Parity-condition and a Rabin-condition
  defined by $\mathcal{F}\subseteq\Pot(Q)$, $\parity$, 
  $R = \set{\tuple{E_{0}, F_{0}},\dots,\tuple{E_{n}, F_{n}}}$ respectively, the 
  sets $\Acc(\mathcal{F})$, $\Acc(\parity)$ and $\Acc(R)$ are measureable in 
  $\mathcal{B}(Q)$.
  \label{cor:borelAcceptance}
\end{corollary}
\begin{proof}
  Since Rabin- and Parity-conditions can be expressed by fitting 
  Muller-conditions it suffices to show the measureability of any 
  $\Acc(\mathcal{F})$ for a Muller-condition $\mathcal{F}\subseteq\Pot(Q)$.
  Fix one Muller-condition $\mathcal{F} = \set{F_{1},\dots,F_{n}}$. We claim
  that for one $F = \set{f_{1},\dots, f_{k}}\in\mathcal{F}$
  \begin{equation*}
    \Acc_{\muller}(\set{F}) = \tuple{
      \bigcap\limits_{1\leq i\leq k}\Acc_{\buechi}(\set{f_{i}})}\setminus
      \Acc_{\cobuechi}(Q\setminus F).
  \end{equation*}
  The individual Büchi-conditions on $f_{i}$ for $1\leq i\leq k$ ensure that 
  every of these states is visited infinitely often while the 
  co-Büchi-condition on all other states ensure that they are only visited
  finitely often rendering the $\Inf$-set to be $F$. By simply setting
  \begin{equation*}
    \Acc_{\muller}(\mathcal{F}) = \bigcup\limits_{F\in\mathcal{F}}(
    \Acc_{\muller}(\set{F}))
  \end{equation*}
  we obtain the measureability of $\Acc_{\muller}(\mathcal{F})$ by the closure
  properties of the $\sigma$-algebra $\mathcal{B}(Q)$.
\end{proof}

This finally allows us to define the semantics of a \ac{PBA} $\mathcal{P}$
formally with
\begin{definition}[Probabilistic Büchi Automaton - Acceptance]
  A \ac{PBA} $\mathcal{P} = \tuple{Q, \Sigma, \delta, q_{0}, F}$ positively 
  (almost-surely) accepts a word $\alpha\in\Sigma^{\omega}$ if
  $\mu_{\alpha}(\Acc(F)) > 0$ ($\mu_{\alpha}(\Acc(F)) = 1$).
\end{definition}
With Corollary \ref{cor:borelAcceptance} we may define analogously
\ac{PPA}, \ac{PMA} and \ac{PRA}. All probabilistic word automata can be
separated into positively and almost-surely accepting. We want to provide a
small discussion of the theory regarding \acp{PBA}. Therefore, we present an
example of a \ac{PBA} which allows us to get a feel for the behavior while also
providing a witness to separate the expressiveness of $\omega$-regular
languages and languages positively accepted by \acp{PBA}.
\begin{drawing}
  \caption{A \ac{PBA} accepting under positive acceptance a
  non-$\omega$-regular language depicted by the same notions as finite word
  automata before. Omitted transitions (for example a $b$-transition from state
  $q_{0}$) implicitly lead to a non-accepting sink state.}
  \label{fig:posacceptingpba}
  \begin{center}
    \resizebox{0.35\textwidth}{!}{%
      \includegraphics{tikz/posacceptingpba.pdf}
    }
  \end{center}
\end{drawing}
\begin{example}
  \cite{RecOmeLangProbAuto}
  We examine the \ac{PBA} $\mathcal{P}$ as defined in Figure 
  \ref{fig:posacceptingpba}. The accepted language is 
  \begin{equation*}
    \mathcal{L}_{>0} = \set{a^{k_{1}}ba^{k_{2}}b\dots:k_{i}>0\text{ for all }
    i>0\text{ and } \prod_{i>0}(1-\tuple{\frac{1}{2}}^{k_{i}}) > 0}.
  \end{equation*}
  This can be explained the following way: intially $\mathcal{P}$ starts in 
  $q_{0}$, thus the whole \emph{probability mass} lays within $q_{0}$. Every
  read $a$ dissipates half of the mass in $q_{0}$ to $q_{1}$ while the mass in
  $q_{1}$ stays in $q_{1}$. Every read $b$ discards all mass in $q_{0}$ while
  moving all mass in $q_{1}$ to $q_{0}$. Thus, reading $a$ gradually saves away
  probability mass into $q_{1}$ and $b$ restarts this process. Note that any 
  word ending in $a^{\omega}$ is not accepted since an infinite dissipatation 
  leaves no mass in $q_{0}$ behind but only the mass visiting $q_{0}$ 
  infinitely often is considered accepting. Thus, we need to have some 
  probability mass which moves infinitely often through the dissipatation step 
  but gradually, due to the loss of mass, steps need to \enquote{save} more 
  mass in order to not let it diminish too fast.
  \label{ex:posacceptingpba}
\end{example}
As stated by the caption in Figure \ref{fig:posacceptingpba} the \ac{PBA}
$\mathcal{P}$ from Example \ref{ex:posacceptingpba} accepts a not
$\omega$-regular language. This gives
\begin{lemma}
  Follows from the proof of \cite[Theorem 4]{RecOmeLangProbAuto}.
  The language
  \begin{equation*}
    \set{a^{k_{1}}ba^{k_{2}}b\dots:k_{i}>0\text{ for all }i>0\text{ and }
    \prod_{i>0}(1-\tuple{\frac{1}{2}}^{k_{i}}) > 0}
  \end{equation*}
  can be positively accepted by a \ac{PBA} but is not $\omega$-regular.
  \label{lem:posaccpba>omegareg}
\end{lemma}
\begin{proof}
  From Theorem \ref{thm:nbaemptiness} we know that every $\omega$-regular 
  language contains an ultimately periodic word. We argue that no ultimately 
  periodic word is part of the language. Since any word ending in $a^{\omega}$ 
  is not part of the language (as argued in Example \ref{ex:posacceptingpba}) 
  any ultimatively periodic word that might be part of the language contains at 
  least one $b$ in its period $v$. But this induces that the sequences of $a$ 
  are bound by a natural number $k$ yielding that for this word
  \begin{equation*}
    \prod_{i>0}(1-\tuple{\frac{1}{2}}^{k_{i}}) \leq
    \underbrace{\prod_{i>0}(1-\tuple{\frac{1}{2}}^{k})}_{
      \text{infinite product of a constant }0\leq c<1} = 0.
  \end{equation*}
  Hence, every ultimatively periodic word is not accepted by $\mathcal{P}$
  rendering its language not $\omega$-regular.
\end{proof}

Furthermore, we quote
\begin{lemma}
  \cite[Lemma 5]{RecOmeLangProbAuto} For any \ac{NBA} $\mathcal{A}$ exists a
  positively accepting \ac{PBA} $\mathcal{P}$ which recognizes the same
  language.
\end{lemma}
And therefore we may conclude that positively accepting \acp{PBA} are more
expressive than $\omega$-regular automata:
\begin{theorem}
  \cite[Theorem 4]{RecOmeLangProbAuto}
  The class of languages that can be accepted by a \ac{PBA} strictly contains
  the class of $\omega$-regular languages.
\end{theorem}
Additionally, we know that the class of languages that are positively accepted 
by a \ac{PBA} forms a Boolean algebra. This is captured in
\begin{theorem}
  \cite[Chapter 4.3.]{Groesser}
  The class of languages that can be accepted by a \ac{PBA} form a Boolean 
  algebra. The transformations can be effectively constructed.
  \label{thm:pbaboolalgebra}
\end{theorem}
\begin{proof}[Proof-sketch]
  A union operator is very easily obtained by the following idea: given two
  \acp{PBA} $\mathcal{P}_{1},\mathcal{P}_{2}$ with initial states $q^{1}_{0},
  q^{2}_{0}$ respectively, then we can construct a \ac{PBA} $\mathcal{P}$ which
  effectively uses a initial distribution 
  $\iota:Q^{1}\cup Q^{2}\rightarrow\interval{0,1}$ such that 
  $\iota(q^{1}_{0}) = \iota(q^{2}_{0}) = \frac{1}{2}$ while $\iota(p) = 0$ for
  any other state $p$. By introducing a new initial state $q_{0}$ and 
  \enquote{skipping over} $q^{1}_{0},q^{2}_{0}$ in the first step, i.e.
  setting
  \begin{equation*}
    \delta(q_{0},\sigma, p) = \frac{1}{2}\cdot\delta^{i}(q^{i}_{0},\sigma, p)
    \text{ with }
    i = \begin{cases}
      1&\text{if }p\in Q^{1},\\
      2&\text{if }p\in Q^{2}
    \end{cases}
  \end{equation*}
  we can emulate such an initial distribution $\iota$. This yields that the 
  resulting $\mathcal{P}$ accepts $\alpha$ with a probability
  $\frac{1}{2}\cdot\mu^{1}_{\alpha}(\Acc(F^{1})) + 
  \frac{1}{2}\cdot\mu^{2}_{\alpha}(\Acc(F^{2}))$ which is greater than $0$ if
  and only if at least one of the probabilities is greater than $0$.

  Complementation requires a rather involved operation which we do not present 
  here. Nevertheless, we mention an intermediate step: for every \ac{PBA}
  $\mathcal{P}$ we can construct a \ac{PRA} $\mathcal{R}$ such that
  $\mathcal{R}$ acceptes the same languages as $\mathcal{P}$. Moreover,
  $\mathcal{R}$ induces a binary probability measure on its acceptance
  condition, i.e. for its Rabin-condition $R$ we have
  $\mu_{\alpha}(\Acc(R))\in\set{0,1}$. The main idea of its construction is to
  sample partial runs of the original \ac{PBA} and keeping track of those that
  are accepting. These partial runs can be then \enquote{glued together}.
  Therefore, we state here
  \begin{theorem}
    \cite[Theorem 4.3.2]{Groesser}
    For each \ac{PBA} $\mathcal{P}$ there exists a \ac{PRA} $\mathcal{R}$ that 
    accepts the same language, but for every word the acceptance measure for
    $\mathcal{R}$ is either $0$ or $1$.
    \label{thm:pbatopra}
  \end{theorem}
  Since we soon see that \acp{PBA} with almost-sure acceptance are strictly
  less expressive than \acp{PBA} with positive acceptance we note the 
  correspondance to Theorem \ref{thm:omegaregularexp} in the
  sense that more expressive acceptance conditions allow for a 
  \enquote{stuctural} difference, which in this case is the acceptance measure
  (in contrast to determinsm before). Also, we note that all \enquote{strong}
  conditions again coincide which is easily obtained by using \acp{LAR} which
  we prove for a more general model in Chapter \ref{chapter:treeautomata}.
  Nevertheless, we state here
  \begin{theorem}
    The expressiveness for \ac{PRA}, \ac{PMA} and \ac{PPA} coincides for
    positive (almost-sure) acceptance measures.
    \label{thm:probautoequiv}
  \end{theorem}
\end{proof}

The gain in expressiveness for \ac{PBA} with positive acceptance over 
$\omega$-regular languages is unfortunately accompanied by some undesired 
effects. Notably, while emptiness for a \ac{NBA} can be decided (see Theorem 
\ref{thm:nbaemptiness}) we have that given a \ac{PBA} $\mathcal{P}$ it is 
undecideable to find if there is any word positively accepted by $\mathcal{P}$.
\begin{theorem}
  \cite[Theorem 2]{DecProblemsForProbAuto}
  The emptiness problem for positively accepting \ac{PBA} is undecideable.
  \label{thm:emptinesspospba}
\end{theorem}
By Theorem \ref{thm:pbatopra} and Theorem \ref{thm:probautoequiv} we obtain
undecideability of emptiness for probabilistic word automata with 
almost-sure accpetance of more expressiv acceptance conditions. Moreover, since 
Büchi-conditions can be emulated by Muller-, Rabin- and Parity-conditions we
get
\begin{corollary}
  The emptiness problem for \acp{PRA}, \acp{PPA} and \acp{PMA} is undecideable
  for positive and almost-sure acceptance.
  \label{cor:emptinessstrongalmostsureprob}
\end{corollary}
However, this is different for almost-sure acceptance of Büchi-conditions.
Notably, we have
\begin{theorem}
  \cite[Theorem 6]{DecProblemsForProbAuto}
  The emptiness problem for \ac{PBA} with almost-sure acceptance is decideable.
  \label{thm:emptinessalmostsurepba}
\end{theorem}
Again, we consider an example for a \ac{PBA} with almost-sure acceptance:
\begin{example}
 \cite{DecProblemsForProbAuto}
  Let $\mathcal{P}$ be a \ac{PBA} as defined in Figure 
  \ref{fig:almostsureacceptingpba}. The language accepted by $\mathcal{P}$ is
  \begin{equation*}
    L_{\lambda} = \set{a^{k_{1}}ba^{k_{2}}b\dots\mid k_{i}>0\text{ for }i>0
    \text{ and }\prod\limits_{i>0}\tuple{1-\lambda^{k_{i}}} = 0}.
  \end{equation*}
  Every $a$-sequence $w\in\set{a}^{*}$ models an experiment which determines 
  how probable it is to stay in $q_{2}$, namely $\lambda^{\size{w}}$. Every 
  experiment is concluded with the occurence of a single $b$. Naturally, the 
  probability to \enquote{fail} such an experiment is $1-\lambda^{\size{w}}$. 
  Due to the equivalent behaviour of $q_{3}$ and $q_{0}$ all these experiments 
  are independent and therefore, consistenly failing these experiments with 
  $a$-sequences of length $k_{1}, k_{2},\dots$ starting from the $m$-th 
  experiment happens with probability
  \begin{equation*}
    p_{m} = \prod\limits_{i>m}(1-\lambda^{k_{i}})
    \text{ which implies }
    \prod\limits_{i>0}(1-\lambda^{k_{i}}) = 
    \underbrace{\prod\limits_{m\geq i>0}(1-\lambda^{k_{i}})}_{=c_{m}}
    \cdot p_{m}.
  \end{equation*}
  Since $c_{m} > 0$ implies $c_{m}\cdot p_{m} = 0$ if and only if 
  $p_{m} = 0$ we observe
  % Every non-accepting run $\pi$ consistently fails from one experiment onwards.
  % This allows to conclude with asymptotic equvialence of $p_{m}$ and 
  % $c_{m}\cdot p_{m}$ and $\sigma$-additivity of a probability measure that the 
  % probability of non-accepting runs is
  \begin{equation*}
    p_{m} = 0 \text{ for all }m > 0\text{ if and only if }
      \prod\limits_{i>0}(1-\lambda^{k_{i}}) = 0.
  \end{equation*}
  In order to accept almost-surely the set of non-accepting runs needs to be
  \emph{negligible}, i.e. carrying a probability of $0$.  Thus, indeed 
  $\mathcal{P}$ accepts $L_{\lambda}$.

  If $\lambda$ is set to $\frac{1}{2}$, the resulting language 
  $\mathcal{L}_{=1}$ is - to a certain degree - dual to the language in Example 
  \ref{ex:posacceptingpba} (without considering all words ending in 
  $a^{\omega}$ or those words starting in $b$ or ommitting an 
  \enquote{$a$-phase}). This duality is rooted in structural similarities. 
  Examining the \emph{Separation} part, it mirrors the $a$-transitions of the 
  \ac{PBA} in Figure \ref{fig:posacceptingpba}. But an occurences of $b$ does 
  not discard the probability mass in $q_{2}$ ($q_0$, respectively) but saves
  it in an accepting state and re-introduces into the circulation (as seen in 
  the \emph{Disposal} part).
  \label{ex:almostsureacceptingpba}
\end{example}
\begin{drawing}
  \caption{A \ac{PBA} which accepts a non-$\omega$-regular language under
  almost-sure acceptance. We conceptually separate it into two regions, namely
  the \enquote{Separation} and \enquote{Disposal} region (highlighted by the
  green or red box respectively).}
  \label{fig:almostsureacceptingpba}
  \begin{center}
    \resizebox{0.4\textwidth}{!}{%
      \includegraphics{tikz/almostsureacceptingpba.pdf}
    }
  \end{center}
\end{drawing}
Considering Example \ref{ex:almostsureacceptingpba} it is a natural question if
the choice of $\lambda$ matters. Quoting the following
\begin{lemma}
  \cite[Lemma 1]{DecProblemsForProbAuto}
  For each $n\in\mathbb{N}_{>1}$ there exists a sequence $\tuple{k_{i}}_{i>0}$
  such that
  \begin{equation*}
    \prod_{i>0}(1-\lambda^{k_{i}}) > 0 \text{ if and only if }
    \lambda<\frac{1}{n},
  \end{equation*}
  \label{lem:measureinpba}
\end{lemma}
allows us to answer this question positively. Choosing $\lambda_{1}$ and
$\lambda_{2}$ differently, we can find $n$ such that 
$\lambda_{1} < \frac{1}{n} < \lambda_{2}$ and then the languages of 
$\mathcal{P}$ with $\lambda_{1}$ and $\lambda_{2}$ do not agree on the sequence
given by Lemma \ref{lem:measureinpba} for $n$ since $\lambda_{1}$ renders
this sequence non-accepting in $\mathcal{P}$ while $\lambda_{2}$ renders it
accepting (as described in \cite{DecProblemsForProbAuto}).

Regarding the relationship of $\omega$-regularity to languages which are 
accepted by a \ac{PBA} with almost-sure acceptance we find that both classes
are incomparable. We examine both directions of possible inclusions. Firstly,
as noted in Figure \ref{fig:almostsureacceptingpba} the defined \ac{PBA} 
$\mathcal{P}$ almost-surely accepts a non-$\omega$-regular language, hence
\begin{lemma}
  There is a non-$\omega$-regular language that is accepted by any \ac{PBA} 
  with almost-sure acceptance.
  \label{lem:pbanotomegareg}
\end{lemma}
\begin{proof}
  As expected, we use the language $\mathcal{L}_{=1}$ from Example 
  \ref{ex:almostsureacceptingpba} to witness this claim. In Example 
  \ref{ex:almostsureacceptingpba} we already mentioned the 
  \enquote{almost duality} of this language to $\mathcal{L}_{>0}$ from Example
  \ref{ex:posacceptingpba}. By defining
  \begin{equation*}
    \mathcal{L}_{\omega} = \set{
      \alpha_{1}\alpha_{2}\dots\in\set{a,b}^{\omega}\middle|
      \text{s.t. }
      \begin{aligned}
        &\alpha_{1} = b&\text{or }\\
        &\alpha_{i} = \alpha_{i+1} = b&\text{for one }i>0\text{ or }\\
        &\alpha_{i} = \alpha_{i+1} = \dots = b&\text{for one }i>0\text{ holds}
      \end{aligned}
    },
  \end{equation*}
  we can state that $\set{a,b}^{\omega}\setminus\mathcal{L}_{>0} = 
    \mathcal{L}_{=1}\cup\mathcal{L}_{\omega}$.  $\mathcal{L}_{\omega}$ can be 
  separated into its individual parts where each part is $\omega$-regular and 
  so is $\mathcal{L}_{\omega}$ by closure under union for $\omega$-regular 
  languages. Thus, assuming $\mathcal{L}_{=1}$ $\omega$-regularity renders 
  $\mathcal{L}_{=1}\cup\mathcal{L}_{\omega}$ $\omega$-regular and by closure 
  under complement of $\omega$-regular languages also $\mathcal{L}_{>0}$ 
  which is a contradiction to Lemma \ref{lem:posaccpba>omegareg}. Therefore, 
  we state that $\mathcal{L}_{=1}$ is not $\omega$-regular.
\end{proof}

On the other hand, we get
\begin{lemma}
  \cite[Theorem 4.4.9 (b)]{Groesser}
  There is an $\omega$-regular language that cannot be accepted by any 
  \ac{PBA} with almost-sure acceptance.
  \label{lem:omegaregnotpba}
\end{lemma}
\begin{proof}
  We examine the $\omega$-regular language $\mathcal{L}$ over the alphabet
  $\set{a,b}$ of those words that contain only finitely many $a$ (cp. Example
  \ref{ex:fina}). By similar arguments as for \ac{DBA} we can derive the
  impossibility to accept this language with an almost-sure accepting 
  \ac{PBA}. To provoke a contradiction we assume the existence of a \ac{PBA}
  $\mathcal{P} = \tuple{Q, q_{0}, \set{a,b}, \delta, F}$ which accepts 
  $\mathcal{L}$. W.l.o.g. we can assume that all states in $Q$ are reachable
  from $q_{0}$ and hence reading $b^{\omega}$ starting in any state must 
  yield an acceptance measure of $1$ for $\Acc(F)$. Moreover, every state $p$ 
  must allow to read an accepting state with a positive probability 
  $\epsilon_{p}$ after a sequence of $b^{n_{p}}$; if we take the maximum of 
  all the lengths of these sequences $n = \max\set{n_{p}:p\in Q}$ we know 
  that every state must visit with positive probability (at least) 
  $\epsilon = \min\set{\epsilon_{p}:p\in Q}$ an accepting state after reading 
  $b^{n}$. This implies that for every state that is possible after a 
  sequence $\tuple{b^{n}a}^{k}$ (for $k = 1, 2, \dots$) it is probable to 
  read another accepting state within the next $b^{n}a$ sequence. Hence, 
  fixing $A_{k}$ as the observation that in the $k$-th reading of $b^{n}a$ 
  from every state at least once a final state is visited allows to use 
  Theorem \ref{thm:BorelCantelli} for the sequence $\tuple{A_{k}}_{k > 0}$ 
  and yields an almost-sure probability for reading infinitely many states in 
  $F$ for runs of $\mathcal{P}$. Formally, we set
  \begin{equation*}
    A_{k} = Q^{\tuple{n + 1}^{k}}\cdot\bigcup_{1\leq i\leq n} Q^{i - 1}F\cdot 
      Q^{n - i + 1} Q^{\omega},
  \end{equation*}
  i.e. the occurence of at least one state $F$ in the $k$-th occurence of 
  $b^{n}a$. We observe that
  \begin{equation*}
    \bigcap_{i > 0}\bigcup_{j > i}A_{j} = \Acc(F),
  \end{equation*}
  since there must not be an index from which onwards $F$ never again occurs.
  The pairwise independence of all $A_{k}$ for $k > 0$ follows from the 
  history-independence of the probability functions of the individual 
  states\footnote{This property of history-independence of the probability 
  distributions is called \emph{Markov}-property (cp. e.g. 
  \cite[Page 8]{Groesser} or \cite[Chapter 17]{Klenke}).}.
\end{proof}

And by combination of Lemma \ref{lem:omegaregnotpba} and Lemma 
\ref{lem:pbanotomegareg} we get
\begin{theorem}
  \cite[Theorem 4, (b), (c)]{DecProblemsForProbAuto}
  The classes of $\omega$-regular languages and languages accepted by a 
  \ac{PBA} with almost-sure acceptance are incomparable.
  \label{thm:regalmostsureincomparable}
\end{theorem}
Considering this theorem and that using Dirac distributions at every state 
emulate determinstic choices the following result is transparent:
\begin{proposition}
  \cite[Proof of Theorem 4.4.9 (d)]{Groesser}
  The class of languages recognizable by \acp{PBA} with almost-sure acceptance
  strictly includes the class of languages recognizable by \acp{DBA}.
  \label{prop:pbasubsumesdba}
\end{proposition}
This entails by the observation that $\set{a,b}^{*}b^{\omega}$ cannot be 
recognized by a \ac{PBA} with almost-sure acceptance but the set of all words 
that contain infinitely many $a$ is (since it is \ac{DBA} recognizable)
\begin{proposition}
  \cite[Theorem 4.4.9 (d)]{Groesser}
  The class of languages recognizable with \acp{PBA} with almost-sure 
  acceptance is not closed under complementation.
  \label{prop:pba=1complement}
\end{proposition}
However, the union construction for positively accepting \acp{PBA} can be used
to obtain an intersection operator for almost-surely accepting \acp{PBA}.
\begin{proposition}
  \cite[Consequence of Section 4.3.]{Groesser}
  The class of languages recognizable with \acp{PBA} with almost-sure
  acceptance is closed under intersection.
\end{proposition}
\begin{proof}
  For the union operator for positively accepting \acp{PBA} we observed that
  \begin{equation*}
    \mu(\Acc(F)) = \frac{1}{2}\cdot\mu^{1}_{\alpha}(\Acc(F^{1})) +
      \frac{1}{2}\cdot\mu^{2}_{\alpha}(\Acc(F^{2}))
  \end{equation*}
  for $F = F_{1}\cup F_{2}$.
  Naturally, this entails
  \begin{equation*}
    \mu(\Acc(F)) = 1 \text{ if and only if } 
      \mu^{1}_{\alpha}(\Acc(F^{1})) = 1 
      \text{ and }
      \mu^{2}_{\alpha}(\Acc(F^{2})) = 1.
  \end{equation*}
  Hence, the claim follows.
\end{proof}

\subsection{Markov Decision Processes}
In the following we introduce \acp{MDP}, a model of interaction between a 
probabilistic domain and an actor within this domain. We call this actor \eve{} 
and treat her grammatically as female. The actions of \eve{} impact the 
behavior of the domain and depending on the behavior of the domain she
may adapt her behavior. It shares significant structural similarities to 
\acp{PBA} but allows for a rather different interpretation. Nevertheless, we
reuse various concepts from \acp{PBA} to define \acp{MDP}. The following 
definitions follow \cite{RandAutoInfTrees}:
\begin{definition}[Markov Decision Process]
  A \acl*{MDP} is modelled as tuple
  $\tuple{S, A, \tuple{\tau_{a}}_{a\in A}, s_{0}}$ where $S$ is a set of states
  and $A$ a set of actions. Given an action $a\in A$ the corresponding
  transition function $\tau_{a}:S\times S\rightarrow \interval{0,1}$ satisfies
  for every $q\in S$ that $\sum_{p\in S}\tau_{a}\tuple{q,p} = 1$.
  $s_{0}$ is the initial state. Additionally, we define a few helpful
  auxillary notions:
  \begin{description}
    \item [Plays] We consider all infinite sequences of states
      valid plays. All plays implicitly start in $s_{0}$ and are gathered in
      $\plays = S^{\omega}$.
    \item [Strategy] We define $f:S^{*}\rightarrow A$ as strategy for
      a \ac{MDP}. 
  \end{description}
  \label{def:mdp}
\end{definition}
A strategy $f$ for an \ac{MDP} $\mathcal{M} = \tuple{S, A, 
\tuple{\tau_{a}}_{a\in A}, s_{0}}$ induces a probability measure $\mu_{f}$ on 
the Borel-algebra $\mathcal{B}(S)$. Formally, we use the unique extension (in 
the sense of Theorem \ref{thm:measureext}) of the measure $\mu_{f}$ from
\begin{equation*}
  \mu_{f}(\cyl(s_{1}\dots s_{n})) = \tau_{f(\epsilon)}(s_{0}, s_{1})
    \prod_{1\leq i < n}\tau_{f(s_{1}\dots s_{i})}(s_{i}, s_{i+1}).
\end{equation*}
\acp{PBA} can be interpreted as \acp{MDP} where the decisions in every state
are induced by a word $\alpha = \alpha_{0}\alpha_{1}\dots\in\Sigma^{\omega}$
rather than a player. Any \ac{PBA} $\mathcal{P}$ can be interpreted as \ac{MDP}
and for any $\alpha$ we can define a corresponding strategy
$\varphi_{\alpha}:Q^{*}\rightarrow\Sigma$ with
$\varphi_{\alpha}(w) = \alpha_{\size{w}}$. On the other hand, strategies for
\acp{MDP} allow for a more refined interaction between \eve{} and the
environment. Notably, \eve{} might react for plays of equal length differently
based on which state she currently resides in, e.g.
\begin{example}
  We interpret the \ac{PBA} pictured in Figure \ref{fig:posacceptingpba} as
  \ac{MDP} $\mathcal{M}$. Furthermore, we challenge \eve{} with the task to
  visit states in $F$ infinitely often. She trivially has a strategy $f$
  that allows her to satisfy this task. Initially, she starts in $q_{0}$ and 
  therefore plays $f(\epsilon) = a$ and in the resulting plays she uses
  \begin{equation*}
    f(p_{1}\dots p_{n}) = \begin{cases}
      b&\text{if }p_{n} = q_{1},\\
      a&\text{if }p_{n} = q_{0}.
    \end{cases}
  \end{equation*}
  \eve{} is not restricted (as words are) to be \enquote{consistent} 
  regarding the length of the play. A word has exactly one letter at each 
  position while \eve{} may provide different actions (or letters) after
  the same length of the play depending on the state she currently resides in
  (or even the current history of the play). \eve{}'s strategy can therefore be
  encoded as a tree where the root is her initial move and moving down edges 
  which are labelled with her observations leads to nodes which contain her 
  decisions regarding that partial play.
  \label{ex:pbaasmdp}
\end{example}
We want to examine \eve{}'s behavior given she does not observe the precise 
state of the game, but only some information. Conceptually, we color the state
of the game and only reveal to \eve{} the color of the current state but not 
the precise state. This leads to the following definition of \acp{POMDP}. A 
\ac{POMDP} is a \ac{MDP} $\mathcal{M}$ with an associated equivalence relation 
$\sim$ which relates equally colored states. Hence, the equivalence relation 
models the restriction of \eve{} to observe the state of $\mathcal{M}$. For 
every $s\in S_{\mathcal{M}}$ we define its color by its equivalence class 
regarding $\sim$: $[s]_{\sim} = \set{r\in S\mid r \sim s}$ and
$\interval{S}_{\sim}$ as set of all these equivalence classes. A
strategy for a \ac{POMDP} $\tuple{\mathcal{M}, \sim}$ is defined as
$f:(\interval{S}_{\sim})^{*}\rightarrow A$.
\begin{example}
  Again, consider a \ac{PBA} $\mathcal{P}$ and interpret it as an \ac{MDP}
  $\mathcal{M}$ we observed that every word $\alpha$ induces a corresponding
  strategy $f_{\alpha}$. But not every strategy induces a word because
  strategies on $\mathcal{M}$ may choose depending on the state of the play
  different letters for plays of the same length which creates an inconsistency
  with respect to an - hypothetical - associated word (cp. Example 
  \ref{ex:pbaasmdp}). We add to $\mathcal{M}$ an equivalence relation
  $\sim = S \times S$ (as suggested in \cite{DecProblemsForProbAuto}), hence 
  there is exactly one equivalence class.
  Firstly, we observe that $f_{\alpha}$ is still a valid strategy for the
  resulting \ac{POMDP} $\mathcal{N} = \tuple{\mathcal{M}, \sim}$. Secondly,
  since there is exactly one equivalence class every strategy for $\mathcal{N}$
  observes at any time only the length of the history. Hence, we can provide an
  equivalent strategy of the form $f:\mathbb{N}\rightarrow \Sigma$. This
  in turn means that every strategy in $\mathcal{N}$ induces a word
  $f(0)f(1)\dots$ in $\Sigma^{\omega}$. Furthermore, the measure of one
  strategy $f$ and an associated word $\alpha_{f}$ coincide, i.e. the language
  of $\mathcal{P}$ can be understood as strategy space for $\mathcal{N}$ and
  vice versa.
  \label{ex:pbaaspomdp}
\end{example}
The definitions of \acp{MDP} and \acp{POMDP} are for now probabilistic 
transition systems and strategies induce a behavior of such a transition 
system. To model goals or task for the player to satisfy we again use 
Büchi-, Rabin-, Parity- and Muller-conditions (cp. Example \ref{ex:pbaasmdp}). 
We can then ask if \eve{} has a strategy to positively or almost-surely satisfy 
the associated condition in an \ac{MDP} or \ac{POMDP}. The interpretation of
\acp{PBA} as uniformly colored \acp{POMDP} described in Example
\ref{ex:pbaaspomdp} directly induces some undecideability results, namely
\begin{corollary}
  \cite[Corollary 3 (a)]{DecProblemsForProbAuto}
  \cite[Theorem 5]{QualAnaPOMDP}
  The question whether a strategy for a \ac{POMDP} exists that either 
  positively or almost-surely satisfies a Rabin-, Parity- or Muller-condition
  is undecideable. Moverover, the question whether a strategy for a \ac{POMDP}
  that positively satisfies a Büchi-condition exists is also undecidable.
  \label{cor:posstratpomdp}
\end{corollary}
\begin{proof}
  Any algorithm to compute a strategy for a \ac{POMDP} that positively 
  satisfies a Büchi-condition immediately solves the emptiness problem for
  \acp{PBA} with positive acceptance which is undecideable by Theorem 
  \ref{thm:emptinesspospba}. The same argument holds for almost-sure and
  positive acceptance of Rabin-, Muller- or Parity-conditions and Corollary
  \ref{cor:emptinessstrongalmostsureprob}.
\end{proof}

On the other hand, there are some positive results regarding computation of 
strategies for \acp{MDP} and for almost-sure satisfaction of Büchi-conditions
in \acp{POMDP}:
\begin{theorem}
  \cite[Theorem 5]{QualAnaPOMDP}
  It is possible to compute a strategy for a \ac{POMDP} that almost-surely
  satisfies an associated Büchi-condition. 

  This strategy can be computed in
  time exponential in the number of states of the \ac{POMDP} and in general
  cannot be computed in less time.
  \label{thm:pomdpstratsynthesis}
\end{theorem}
and
\begin{theorem}
  \cite[Theorem 1.1]{QuanStochParityGames}
  It is possible to compute a strategy for a \ac{MDP} that almost-surely or
  positively satisfies an associated Büchi- or Parity-condition.

  This can be done in time polynomial in the number of states of the \ac{MDP}.
  \label{thm:mdpstratsynthesis}
\end{theorem}
The problem of obtaining such strategies is explored in more detail in Chapter
\ref{chapter:synthesis}. For now we are content with the existence of these 
decision procedures. Additionally, note that Theorem 
\ref{thm:pomdpstratsynthesis} induces a maximal complexity for deciding the 
emptiness problem for almost-surely accepting \acp{PBA} (Theorem 
\ref{thm:emptinessalmostsurepba}).
